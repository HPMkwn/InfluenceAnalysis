{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing_CrowdFlower_using_Ekphrasis_Tool.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "R_umo9F1H0MN",
        "rXOB2pDmH66g"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPbr1jYHcDzyJuNmsPNDegl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harrymkwn/InfluenceAnalysis/blob/master/Preprocessing_CrowdFlower_using_Ekphrasis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_umo9F1H0MN"
      },
      "source": [
        "#Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goGbL3dAM6gk"
      },
      "source": [
        "!pip3 install ekphrasis\n",
        "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
        "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
        "from ekphrasis.dicts.emoticons import emoticons\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re, sys, os, csv\n",
        "import io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhofUGYYIsiZ",
        "outputId": "ed4a5a53-0fe6-48f2-ea32-9e782f44dd38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import words\n",
        "nltk.download('words')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiKMvBL4I0l7"
      },
      "source": [
        "from nltk.metrics.distance import (edit_distance,jaccard_distance)\n",
        "from nltk.util import ngrams"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kFr4gBh9bXk",
        "outputId": "2277b6ec-5999-4701-9d2b-1f5e4046ddb2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXOB2pDmH66g"
      },
      "source": [
        "#Methods for Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVt2gmXsNISv"
      },
      "source": [
        "emoticons_additional = {\n",
        "    '(^・^)': '<happy>', ':‑c': '<sad>', '=‑d': '<happy>', \":'‑)\": '<happy>', ':‑d': '<laugh>',\n",
        "    ':‑(': '<sad>', ';‑)': '<happy>', ':‑)': '<happy>', ':\\\\/': '<sad>', 'd=<': '<annoyed>',\n",
        "    ':‑/': '<annoyed>', ';‑]': '<happy>', '(^�^)': '<happy>', 'angru': 'angry', \"d‑':\":\n",
        "        '<annoyed>', \":'‑(\": '<sad>', \":‑[\": '<annoyed>', '(�?�)': '<happy>', 'x‑d': '<laugh>',\n",
        "}\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH71uqi0NBSY",
        "outputId": "5110e2cf-f548-4706-8fdb-10174a14bdb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "text_processor = TextPreProcessor(\n",
        "    # terms that will be normalized\n",
        "    normalize=['url', 'email', 'percent', 'money', 'phone', 'user',\n",
        "               'time', 'url', 'date', 'number'],\n",
        "    # terms that will be annotated\n",
        "    annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",\n",
        "              'emphasis', 'censored'},\n",
        "    fix_html=True,  # fix HTML tokens\n",
        "    # corpus from which the word statistics are going to be used \n",
        "    # for word segmentation \n",
        "    segmenter=\"twitter\",\n",
        "    # corpus from which the word statistics are going to be used \n",
        "    # for spell correction\n",
        "    corrector=\"twitter\",\n",
        "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
        "    unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
        "    spell_correct_elong=True,  # spell correction for elongated words\n",
        "    # select a tokenizer. You can use SocialTokenizer, or pass your own\n",
        "    # the tokenizer, should take as input a string and return a list of tokens\n",
        "    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
        "    # list of dictionaries, for replacing tokens extracted from the text,\n",
        "    # with other expressions. You can pass more than one dictionaries.\n",
        "    dicts=[emoticons, emoticons_additional]\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ekphrasis/classes/tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n",
            "  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Word statistics files not found!\n",
            "Downloading... done!\n",
            "Unpacking... done!\n",
            "Reading twitter - 1grams ...\n",
            "generating cache file for faster loading...\n",
            "reading ngrams /root/.ekphrasis/stats/twitter/counts_1grams.txt\n",
            "Reading twitter - 2grams ...\n",
            "generating cache file for faster loading...\n",
            "reading ngrams /root/.ekphrasis/stats/twitter/counts_2grams.txt\n",
            "Reading twitter - 1grams ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ekphrasis/classes/exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
            "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXfSSwceOKJj"
      },
      "source": [
        "def tokenize(text):\n",
        "    text = \" \".join(text_processor.pre_process_doc(text))\n",
        "    return text"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a3NXUDoCZ-z"
      },
      "source": [
        "def tweet_label(label):\n",
        "    if label == \"empty\":return 0 # neutral\n",
        "    elif label == \"sadness\":return 2 # sad\n",
        "    elif label == \"enthusiasm\":return 1 # happy\n",
        "    elif label == \"neutral\":return 0 # neutral\n",
        "    elif label == \"worry\":return 2 # sad\n",
        "    elif label == \"surprise\":return 1 # happy\n",
        "    elif label == \"love\":return 1 # happy\n",
        "    elif label == \"fun\":return 1 # happy\n",
        "    elif label == \"hate\":return 3 #hate\n",
        "    elif label == \"happiness\":return 1 # happy\n",
        "    elif label == \"boredom\":return 0 # neutral\n",
        "    elif label == \"relief\":return 1 # happy\n",
        "    elif label == \"anger\":return 3 #anger"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-pvOn3pIM4P"
      },
      "source": [
        "#cleaning Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrQxoFG_MlGD"
      },
      "source": [
        "crowdFlower = pd.read_csv('/content/gdrive/MyDrive/InfluenceAnalysis/crowdFlower/crowdFlower.csv',names = ['emotion','tweets'],skiprows = 1,header=None)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD9NJA4EyW2x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6c200716-bc14-4866-8ebd-7cdc643dd817"
      },
      "source": [
        "crowdFlower.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>empty</td>\n",
              "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sadness</td>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sadness</td>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@dannycastillo We want to trade with someone w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      emotion                                             tweets\n",
              "0       empty  @tiffanylue i know  i was listenin to bad habi...\n",
              "1     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
              "2     sadness                Funeral ceremony...gloomy friday...\n",
              "3  enthusiasm               wants to hang out with friends SOON!\n",
              "4     neutral  @dannycastillo We want to trade with someone w..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "A7MKOKkrM_XP",
        "outputId": "b609c509-3254-4d0b-b670-fbf1f3223885"
      },
      "source": [
        "try :\n",
        "  crowdFlower.drop(['tweet_id','author'],axis=1,inplace=True)\n",
        "except : \n",
        "  print(\"already removed\")\n",
        "crowdFlower.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "already removed\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>empty</td>\n",
              "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sadness</td>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sadness</td>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@dannycastillo We want to trade with someone w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      emotion                                             tweets\n",
              "0       empty  @tiffanylue i know  i was listenin to bad habi...\n",
              "1     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
              "2     sadness                Funeral ceremony...gloomy friday...\n",
              "3  enthusiasm               wants to hang out with friends SOON!\n",
              "4     neutral  @dannycastillo We want to trade with someone w..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABJTBW2aNfJn"
      },
      "source": [
        "crowdFlower.to_csv('/content/gdrive/MyDrive/InfluenceAnalysis/crowdFlower/crowdFlower.csv',index=None)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NChdxDoCEjdG"
      },
      "source": [
        "crowdFlower['tweets'] = crowdFlower['tweets'].apply(lambda tweet : tokenize(tweet))\n",
        "crowdFlower['emotion'] = crowdFlower['emotion'].apply(lambda label : tweet_label(label))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCRz8CO_FIGy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "622509d1-cb38-4c61-d686-fcc420677827"
      },
      "source": [
        "crowdFlower.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>&lt;user&gt; i know i was listenin to bad habit earl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>layin n bed with a headache ugh &lt;elongated&gt; . ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>funeral ceremony . &lt;repeated&gt; gloomy friday . ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>wants to hang out with friends &lt;allcaps&gt; soon ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>&lt;user&gt; we want to trade with someone who has h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   emotion                                             tweets\n",
              "0        0  <user> i know i was listenin to bad habit earl...\n",
              "1        2  layin n bed with a headache ugh <elongated> . ...\n",
              "2        2  funeral ceremony . <repeated> gloomy friday . ...\n",
              "3        1  wants to hang out with friends <allcaps> soon ...\n",
              "4        0  <user> we want to trade with someone who has h..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4hU4_Q5yuwi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "092873d9-36d7-4768-aaf7-76b93ab4744e"
      },
      "source": [
        "crowdFlower['emotion'].value_counts()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    15299\n",
              "2    13624\n",
              "0     9644\n",
              "3     1433\n",
              "Name: emotion, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl_VO60YHkJA"
      },
      "source": [
        "crowdFlower.to_csv('/content/gdrive/MyDrive/InfluenceAnalysis/crowdFlower/cF_clean_Ekphrasis_combined.csv')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buHgjFh3Idto"
      },
      "source": [
        "#Spelling Correction Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euZZUzcgI-Jv"
      },
      "source": [
        "def jaccard(word,gram_number):\n",
        "  \n",
        "  try:\n",
        "    if dictionary[word]==1:\n",
        "      return word\n",
        "  except KeyError:\n",
        "    spellings = spelling_series[spelling_series.str.startswith(word[:2])]\n",
        "\n",
        "    distances = []\n",
        "    if len(word) >=3: \n",
        "      distances = [(jaccard_distance(set(ngrams(word,3)),set(ngrams(x,3))),x) for x in spellings]\n",
        "    elif len(word) == 2:\n",
        "      distances = [(jaccard_distance(set(ngrams(word,2)),set(ngrams(x,2))),x) for x in spellings]\n",
        "    \n",
        "    closet = (\"0\",word)\n",
        "    if len(distances)!=0:\n",
        "      closet = min(distances)\n",
        "    return closet[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZWZynY_JCzV"
      },
      "source": [
        "def correct_spelling(word):\n",
        "  return str(jaccard(word,3))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y7zLb4rJEoI"
      },
      "source": [
        "def correct_spelling_tweet(tweet):\n",
        "\n",
        "  words = tweet.split()\n",
        "  for i in range(len(words)):\n",
        "    words[i] = correct_spelling(words[i])\n",
        "\n",
        "  return \" \".join(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIXNPtE1JRCj"
      },
      "source": [
        "vocab_glove = {}\n",
        "spellings = []\n",
        "dictionary = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9zbOOVoIc-b"
      },
      "source": [
        "with open(\"/content/gdrive/MyDrive/InfluenceAnalysis/glove/glove.twitter.27B.200d.txt\", 'r', encoding=\"utf-8\") as f:\n",
        "  for line in f:\n",
        "      values = line.split()\n",
        "      word = values[0]\n",
        "      vector = np.asarray(values[1:], \"float32\")\n",
        "      dictionary[word] = 1\n",
        "      spellings.append(word)\n",
        "      vocab_glove[word] = vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8o7xFykJ_L3",
        "outputId": "8ed8bfe3-ab8d-4223-de75-cfac73882223"
      },
      "source": [
        "spelling_series = pd.Series(spellings)\n",
        "print(spelling_series)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0            <user>\n",
            "1                 .\n",
            "2                 :\n",
            "3                rt\n",
            "4                 ,\n",
            "             ...   \n",
            "1193509     ﾊﾞｲﾊﾞｰｲ\n",
            "1193510        ﾊﾟﾝﾁ\n",
            "1193511       ﾔﾒﾀﾏｴ\n",
            "1193512       ﾖｲｼｮｯ\n",
            "1193513    ﾟﾟﾟｵﾔｽﾐｰ\n",
            "Length: 1193514, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "E-hUACcTJKnn",
        "outputId": "5608780a-7144-4cf6-8cf1-0630b5066abf"
      },
      "source": [
        " crowdFlower['tweets'] = crowdFlower['tweets'].apply(lambda x : correct_spelling_tweet(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f5998d5e01a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcrowdFlower\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweets'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrowdFlower\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mcorrect_spelling_tweet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'crowdFlower' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX2DCmxpKWFS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}