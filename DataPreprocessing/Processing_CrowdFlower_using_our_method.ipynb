{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataPreprocess.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "OWyeiHlD2E6e",
        "2b-zUGCKE64a",
        "ifrEyo6lEtPm",
        "_ZEkjcA8Q0Os",
        "UATi1JgZc-FB"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harrymkwn/InfluenceAnalysis/blob/master/Processing_CrowdFlower_using_our_method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWyeiHlD2E6e"
      },
      "source": [
        "#Initialization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0gNX0av1Y0S"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import string\n",
        "\n",
        "\n",
        "from scipy import stats\n",
        "from statsmodels.stats.anova import anova_lm\n",
        "from statsmodels.formula.api import ols\n",
        "from sklearn.utils import shuffle \n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qpr7vCG9buj"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedShuffleSplit"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMsIIWh-8qU5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5daaafb2-ae13-43a0-eb58-bfc1f1bdcbdd"
      },
      "source": [
        "!pip install emot\n",
        "from emot.emo_unicode import UNICODE_EMO, EMOTICONS"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: emot in /usr/local/lib/python3.7/dist-packages (2.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHSD9B6qMrvZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d90905c6-70d0-4e5c-f0a9-214a1cfc90ad"
      },
      "source": [
        "from google.colab import  drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIk4mbPPjQ3a"
      },
      "source": [
        "pd.set_option('display.max_colwidth',1000)\n",
        "pd.set_option('display.max_rows',1000)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNG1AJUaE1U-"
      },
      "source": [
        "#Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOgwP_n-MnYt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1c7a462c-f88c-45e6-adb1-1bf72d02f00f"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/InfluenceAnalysis/crowdFlower/crowdFlower.csv')\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>empty</td>\n",
              "      <td>@tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sadness</td>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin on your call...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sadness</td>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@dannycastillo We want to trade with someone who has Houston tickets, but no one will.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      emotion                                                                                        tweets\n",
              "0       empty  @tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[\n",
              "1     sadness                                  Layin n bed with a headache  ughhhh...waitin on your call...\n",
              "2     sadness                                                           Funeral ceremony...gloomy friday...\n",
              "3  enthusiasm                                                          wants to hang out with friends SOON!\n",
              "4     neutral        @dannycastillo We want to trade with someone who has Houston tickets, but no one will."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gl_P-ZqMAHN_",
        "outputId": "d9ce77e1-eaa9-48cb-d82c-8d42467ab876"
      },
      "source": [
        "df['emotion'].value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral       8638\n",
              "worry         8459\n",
              "happiness     5209\n",
              "sadness       5165\n",
              "love          3842\n",
              "surprise      2187\n",
              "fun           1776\n",
              "relief        1526\n",
              "hate          1323\n",
              "empty          827\n",
              "enthusiasm     759\n",
              "boredom        179\n",
              "anger          110\n",
              "Name: emotion, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b-zUGCKE64a"
      },
      "source": [
        "#Methods to convert Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btJO2NxvO4oj"
      },
      "source": [
        "def is_camel_case(s):\n",
        "    return s != s.lower() and s != s.upper() and (\"_\" and \" \") not in s"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwssN1N2Cymr"
      },
      "source": [
        "def camel_case_split(identifier):\n",
        "    matches = re.finditer('.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)', identifier)\n",
        "    return [m.group(0) for m in matches]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ8TclIe13ZO"
      },
      "source": [
        "def convert_emojis(tweet):\n",
        "  for emot in UNICODE_EMO:\n",
        "    # print(\"_\".join(UNICODE_EMO[emot].replace(\",\",\"\").replace(\":\",\"\").split()))\n",
        "    tweet = tweet.replace(emot, \" sbfs\".join(UNICODE_EMO[emot].replace(\",\",\"\").replace(\":\",\"\").split()))\n",
        "  \n",
        "  return tweet\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULaOwz-k_M1A"
      },
      "source": [
        " def convert_emoticons(tweet):\n",
        "  tweet = tweet\n",
        "  for emot in EMOTICONS:\n",
        "      tweet = re.sub(u'('+emot+')', \" \".join(EMOTICONS[emot].replace(\",\",\"\").split()), tweet)\n",
        "  return tweet"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulCl6iO4fuF2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaafcde7-0e31-4041-dbae-6f17675dcf3f"
      },
      "source": [
        "print(convert_emoticons(convert_emojis((\":'â€‘) :') ðŸ™‚ ðŸ˜Š ðŸ˜€ ðŸ˜ \"))))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tears of happiness Tears of happiness slightly_smiling_face smiling_face_with_smiling_eyes grinning_face grinning_face_with_smiling_eyes \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJJJj4Rx_KCO"
      },
      "source": [
        "def clean_hashtags(tweet):\n",
        "  words_in_tweet = tweet.split(\" \")\n",
        "  temp = []\n",
        "  for i in words_in_tweet:\n",
        "    if \"#\" in i:\n",
        "      i = i.replace(\"#\",\"\")\n",
        "      if \"_\" in i:\n",
        "        i = i.replace(\"_\",\" \")\n",
        "        temp.append(i)\n",
        "      elif is_camel_case(i):\n",
        "        # print(\"camel case block\")\n",
        "        temp.append(\" \".join(camel_case_split(i)))\n",
        "      else:\n",
        "        temp.append(i)\n",
        "    else:\n",
        "      temp.append(i)\n",
        "  \n",
        "  return \" \".join(temp)\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXmWVMSPW8sL"
      },
      "source": [
        "def clean_mentions(tweet):\n",
        "    tweet = re.sub(r\"@[A-Za-z0-9_]+\",\"\", tweet)\n",
        "    return tweet"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqFtfhy8EwG_"
      },
      "source": [
        "def clean(tweet): \n",
        "            \n",
        "    # Special characters\n",
        "    tweet = re.sub(r\"\\x89Ã›_\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Ã›Ã’\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Ã›Ã“\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Ã›ÃWhen\", \"When\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Ã›Ã\", \"\", tweet)\n",
        "    tweet = re.sub(r\"China\\x89Ã›Âªs\", \"China's\", tweet)\n",
        "    tweet = re.sub(r\"let\\x89Ã›Âªs\", \"let's\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Ã›Ã·\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Ã›Âª\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Ã›\\x9d\", \"\", tweet)\n",
        "    tweet = re.sub(r\"Ã¥_\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Ã›Â¢\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Ã›Â¢Ã¥ÃŠ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"fromÃ¥ÃŠwounds\", \"from wounds\", tweet)\n",
        "    tweet = re.sub(r\"Ã¥ÃŠ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"Ã¥Ãˆ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"JapÃŒ_n\", \"Japan\", tweet)    \n",
        "    tweet = re.sub(r\"ÃŒÂ©\", \"e\", tweet)\n",
        "    tweet = re.sub(r\"Ã¥Â¨\", \"\", tweet)\n",
        "    tweet = re.sub(r\"SuruÃŒÂ¤\", \"Suruc\", tweet)\n",
        "    tweet = re.sub(r\"Ã¥Ã‡\", \"\", tweet)\n",
        "    tweet = re.sub(r\"Ã¥Â£3million\", \"3 million\", tweet)\n",
        "    tweet = re.sub(r\"Ã¥Ã€\", \"\", tweet)\n",
        "    \n",
        "    # Contractions\n",
        "    tweet = re.sub(r\"he's\", \"he is\", tweet)\n",
        "    tweet = re.sub(r\"there's\", \"there is\", tweet)\n",
        "    tweet = re.sub(r\"We're\", \"We are\", tweet)\n",
        "    tweet = re.sub(r\"That's\", \"That is\", tweet)\n",
        "    tweet = re.sub(r\"won't\", \"will not\", tweet)\n",
        "    tweet = re.sub(r\"they're\", \"they are\", tweet)\n",
        "    tweet = re.sub(r\"Can't\", \"Cannot\", tweet)\n",
        "    tweet = re.sub(r\"wasn't\", \"was not\", tweet)\n",
        "    tweet = re.sub(r\"don\\x89Ã›Âªt\", \"do not\", tweet)\n",
        "    tweet = re.sub(r\"aren't\", \"are not\", tweet)\n",
        "    tweet = re.sub(r\"isn't\", \"is not\", tweet)\n",
        "    tweet = re.sub(r\"What's\", \"What is\", tweet)\n",
        "    tweet = re.sub(r\"haven't\", \"have not\", tweet)\n",
        "    tweet = re.sub(r\"hasn't\", \"has not\", tweet)\n",
        "    tweet = re.sub(r\"There's\", \"There is\", tweet)\n",
        "    tweet = re.sub(r\"He's\", \"He is\", tweet)\n",
        "    tweet = re.sub(r\"It's\", \"It is\", tweet)\n",
        "    tweet = re.sub(r\"You're\", \"You are\", tweet)\n",
        "    tweet = re.sub(r\"I'M\", \"I am\", tweet)\n",
        "    tweet = re.sub(r\"shouldn't\", \"should not\", tweet)\n",
        "    tweet = re.sub(r\"wouldn't\", \"would not\", tweet)\n",
        "    tweet = re.sub(r\"i'm\", \"I am\", tweet)\n",
        "    tweet = re.sub(r\"I\\x89Ã›Âªm\", \"I am\", tweet)\n",
        "    tweet = re.sub(r\"I'm\", \"I am\", tweet)\n",
        "    tweet = re.sub(r\"Isn't\", \"is not\", tweet)\n",
        "    tweet = re.sub(r\"Here's\", \"Here is\", tweet)\n",
        "    tweet = re.sub(r\"you've\", \"you have\", tweet)\n",
        "    tweet = re.sub(r\"you\\x89Ã›Âªve\", \"you have\", tweet)\n",
        "    tweet = re.sub(r\"we're\", \"we are\", tweet)\n",
        "    tweet = re.sub(r\"what's\", \"what is\", tweet)\n",
        "    tweet = re.sub(r\"couldn't\", \"could not\", tweet)\n",
        "    tweet = re.sub(r\"we've\", \"we have\", tweet)\n",
        "    tweet = re.sub(r\"it\\x89Ã›Âªs\", \"it is\", tweet)\n",
        "    tweet = re.sub(r\"doesn\\x89Ã›Âªt\", \"does not\", tweet)\n",
        "    tweet = re.sub(r\"It\\x89Ã›Âªs\", \"It is\", tweet)\n",
        "    tweet = re.sub(r\"Here\\x89Ã›Âªs\", \"Here is\", tweet)\n",
        "    tweet = re.sub(r\"who's\", \"who is\", tweet)\n",
        "    tweet = re.sub(r\"I\\x89Ã›Âªve\", \"I have\", tweet)\n",
        "    tweet = re.sub(r\"y'all\", \"you all\", tweet)\n",
        "    tweet = re.sub(r\"can\\x89Ã›Âªt\", \"cannot\", tweet)\n",
        "    tweet = re.sub(r\"would've\", \"would have\", tweet)\n",
        "    tweet = re.sub(r\"it'll\", \"it will\", tweet)\n",
        "    tweet = re.sub(r\"we'll\", \"we will\", tweet)\n",
        "    tweet = re.sub(r\"wouldn\\x89Ã›Âªt\", \"would not\", tweet)\n",
        "    tweet = re.sub(r\"We've\", \"We have\", tweet)\n",
        "    tweet = re.sub(r\"he'll\", \"he will\", tweet)\n",
        "    tweet = re.sub(r\"Y'all\", \"You all\", tweet)\n",
        "    tweet = re.sub(r\"Weren't\", \"Were not\", tweet)\n",
        "    tweet = re.sub(r\"Didn't\", \"Did not\", tweet)\n",
        "    tweet = re.sub(r\"they'll\", \"they will\", tweet)\n",
        "    tweet = re.sub(r\"they'd\", \"they would\", tweet)\n",
        "    tweet = re.sub(r\"DON'T\", \"DO NOT\", tweet)\n",
        "    tweet = re.sub(r\"That\\x89Ã›Âªs\", \"That is\", tweet)\n",
        "    tweet = re.sub(r\"they've\", \"they have\", tweet)\n",
        "    tweet = re.sub(r\"i'd\", \"I would\", tweet)\n",
        "    tweet = re.sub(r\"should've\", \"should have\", tweet)\n",
        "    tweet = re.sub(r\"You\\x89Ã›Âªre\", \"You are\", tweet)\n",
        "    tweet = re.sub(r\"where's\", \"where is\", tweet)\n",
        "    tweet = re.sub(r\"Don\\x89Ã›Âªt\", \"Do not\", tweet)\n",
        "    tweet = re.sub(r\"we'd\", \"we would\", tweet)\n",
        "    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n",
        "    tweet = re.sub(r\"weren't\", \"were not\", tweet)\n",
        "    tweet = re.sub(r\"They're\", \"They are\", tweet)\n",
        "    tweet = re.sub(r\"Can\\x89Ã›Âªt\", \"Cannot\", tweet)\n",
        "    tweet = re.sub(r\"you\\x89Ã›Âªll\", \"you will\", tweet)\n",
        "    tweet = re.sub(r\"I\\x89Ã›Âªd\", \"I would\", tweet)\n",
        "    tweet = re.sub(r\"let's\", \"let us\", tweet)\n",
        "    tweet = re.sub(r\"it's\", \"it is\", tweet)\n",
        "    tweet = re.sub(r\"can't\", \"cannot\", tweet)\n",
        "    tweet = re.sub(r\"don't\", \"do not\", tweet)\n",
        "    tweet = re.sub(r\"you're\", \"you are\", tweet)\n",
        "    tweet = re.sub(r\"i've\", \"I have\", tweet)\n",
        "    tweet = re.sub(r\"that's\", \"that is\", tweet)\n",
        "    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n",
        "    tweet = re.sub(r\"doesn't\", \"does not\", tweet)\n",
        "    tweet = re.sub(r\"i'd\", \"I would\", tweet)\n",
        "    tweet = re.sub(r\"didn't\", \"did not\", tweet)\n",
        "    tweet = re.sub(r\"ain't\", \"am not\", tweet)\n",
        "    tweet = re.sub(r\"you'll\", \"you will\", tweet)\n",
        "    tweet = re.sub(r\"I've\", \"I have\", tweet)\n",
        "    tweet = re.sub(r\"Don't\", \"do not\", tweet)\n",
        "    tweet = re.sub(r\"I'll\", \"I will\", tweet)\n",
        "    tweet = re.sub(r\"I'd\", \"I would\", tweet)\n",
        "    tweet = re.sub(r\"Let's\", \"Let us\", tweet)\n",
        "    tweet = re.sub(r\"you'd\", \"You would\", tweet)\n",
        "    tweet = re.sub(r\"It's\", \"It is\", tweet)\n",
        "    tweet = re.sub(r\"Ain't\", \"am not\", tweet)\n",
        "    tweet = re.sub(r\"Haven't\", \"Have not\", tweet)\n",
        "    tweet = re.sub(r\"Could've\", \"Could have\", tweet)\n",
        "    tweet = re.sub(r\"youve\", \"you have\", tweet)  \n",
        "    tweet = re.sub(r\"donÃ¥Â«t\", \"do not\", tweet)   \n",
        "            \n",
        "    # Character entity references\n",
        "    tweet = re.sub(r\"&gt;\", \"greater than\", tweet)\n",
        "    tweet = re.sub(r\"&lt;\", \"less than\", tweet)\n",
        "    tweet = re.sub(r\"&amp;\", \"and\", tweet)\n",
        "    \n",
        "    # Typos, slang and informal abbreviations\n",
        "    tweet = re.sub(r\"w/e\", \"whatever\", tweet)\n",
        "    tweet = re.sub(r\"w/\", \"with\", tweet)\n",
        "    tweet = re.sub(r\"USAgov\", \"USA government\", tweet)\n",
        "    tweet = re.sub(r\"recentlu\", \"recently\", tweet)\n",
        "    tweet = re.sub(r\"Ph0tos\", \"Photos\", tweet)\n",
        "    tweet = re.sub(r\"amirite\", \"am I right\", tweet)\n",
        "    tweet = re.sub(r\"exp0sed\", \"exposed\", tweet)\n",
        "    tweet = re.sub(r\"<3\", \"love\", tweet)\n",
        "    tweet = re.sub(r\"amageddon\", \"armageddon\", tweet)\n",
        "    tweet = re.sub(r\"Trfc\", \"Traffic\", tweet)\n",
        "               \n",
        "    # Urls\n",
        "    tweet = re.sub(r\"https?:\\/\\/t.co\\/[A-Za-z0-9]+\", \"\", tweet)\n",
        "        \n",
        "    # Words with punctuations and special characters\n",
        "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\"\n",
        "    for p in punctuations:\n",
        "        tweet = tweet.replace(p, f' {p} ')\n",
        "        \n",
        "    # ... and ..\n",
        "    tweet = tweet.replace('...', ' ... ')\n",
        "    if '...' not in tweet:\n",
        "        tweet = tweet.replace('..', ' ... ')      \n",
        "        \n",
        "    # Acronyms\n",
        "    tweet = re.sub(r\"MH370\", \"Malaysia Airlines Flight 370\", tweet)\n",
        "    tweet = re.sub(r\"mÃŒÂ¼sica\", \"music\", tweet)\n",
        "    tweet = re.sub(r\"okwx\", \"Oklahoma City Weather\", tweet)\n",
        "    tweet = re.sub(r\"arwx\", \"Arkansas Weather\", tweet)    \n",
        "    tweet = re.sub(r\"gawx\", \"Georgia Weather\", tweet)  \n",
        "    tweet = re.sub(r\"scwx\", \"South Carolina Weather\", tweet)  \n",
        "    tweet = re.sub(r\"cawx\", \"California Weather\", tweet)\n",
        "    tweet = re.sub(r\"tnwx\", \"Tennessee Weather\", tweet)\n",
        "    tweet = re.sub(r\"azwx\", \"Arizona Weather\", tweet)  \n",
        "    tweet = re.sub(r\"alwx\", \"Alabama Weather\", tweet)\n",
        "    tweet = re.sub(r\"wordpressdotcom\", \"wordpress\", tweet)    \n",
        "    tweet = re.sub(r\"usNWSgov\", \"United States National Weather Service\", tweet)\n",
        "    tweet = re.sub(r\"Suruc\", \"Sanliurfa\", tweet)   \n",
        "\n",
        "\n",
        "    #fancy words\n",
        "    tweet = re.sub(r\"fu[* ]*k\", \"fuck\", tweet)\n",
        "    tweet = re.sub(r\"[o|O]+[h|H]+\", \"oh\", tweet)\n",
        "    tweet = re.sub(r\"[M|y]+[y|Y]+\", \"my\", tweet)\n",
        "    tweet = re.sub(r\"[G|g]+[o|O]+[d|D]+\", \"god\", tweet)\n",
        "    tweet = re.sub(r\"[h|H]+[i|I]+\", \"hi\", tweet)\n",
        "    tweet = re.sub(r\"[o|O]+[k|K]+\", \"ok\", tweet)\n",
        "    tweet = re.sub(r\"[g|G]+[o|O]+[d|D]+\", \"good\", tweet)\n",
        "    tweet = re.sub(r\"[m|M]+[o|O]+[r|R]+[n|N]+[i|I]+[n|N]+[g|G]+\", \"morning\", tweet)\n",
        "    tweet = re.sub(r\"[h|H]+[e|E]+[l|L]+[o|O]+\", \"hello\", tweet)\n",
        "    tweet = re.sub(r\"[b|B]+[y|Y]+[e|E]+\", \"bye\", tweet)\n",
        "    #design\n",
        "    tweet = re.sub(r\"[0-9]+[PM|AM]\", \"\", tweet)\n",
        "\n",
        "    return tweet"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dWfd1WDv2eM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88081e8a-e228-4984-8c40-cde0d24821ba"
      },
      "source": [
        "print(clean(\"Hhhhheeeeeelllllllllllooooooooooooooooo dosto, goood morninggggggggggggggggG\"))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello dosto, good morning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yrGwSawdRmH"
      },
      "source": [
        "#Function to remove Punctuation\n",
        "def remove_punct(text):\n",
        "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation])# It will discard all punctuations\n",
        "    return text_nopunct\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHKBni-j224E"
      },
      "source": [
        "def convert_label(label):\n",
        "    if label == \"empty\":return 0 # neutral\n",
        "    elif label == \"sadness\":return 2 # sad\n",
        "    elif label == \"enthusiasm\":return 1 # happy\n",
        "    elif label == \"neutral\":return 0 # neutral\n",
        "    elif label == \"worry\":return 2 # sad\n",
        "    elif label == \"surprise\":return 1 # happy\n",
        "    elif label == \"love\":return 1 # happy\n",
        "    elif label == \"fun\":return 1 # happy\n",
        "    elif label == \"hate\":return 3 #hate\n",
        "    elif label == \"happiness\":return 1 # happy\n",
        "    elif label == \"boredom\":return 0 # neutral\n",
        "    elif label == \"relief\":return 1 # happy\n",
        "    elif label == \"anger\":return 4 #anger"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifrEyo6lEtPm"
      },
      "source": [
        "#Applying Methods to Data Frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6Km_c4E29bA"
      },
      "source": [
        "def apply_methods(df):\n",
        "\n",
        "  df['tweets'] = df['tweets'].apply(lambda tweet : \" \".join(convert_emojis(tweet).split(\"_\")))\n",
        "\n",
        "  df['tweets'] = df['tweets'].apply(lambda tweet : convert_emoticons(tweet))\n",
        "\n",
        "  df['tweets'] = df['tweets'].apply(lambda tweet : clean_hashtags(tweet))\n",
        "\n",
        "  df['tweets'] = df['tweets'].apply(lambda tweet : clean_mentions(tweet))\n",
        "\n",
        "  df['tweets'] = df['tweets'].apply(lambda tweet: clean(tweet))\n",
        "\n",
        "  df['tweets'] = df['tweets'].apply(lambda tweet: remove_punct(tweet))\n",
        "\n",
        "  df['emotion'] = df['emotion'].apply(lambda label: convert_label(label))\n",
        "\n",
        "  df.head()\n",
        "\n",
        "  return df"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRbW7upx3o5q"
      },
      "source": [
        "df = apply_methods(df)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Ju41nyzW5Nfp",
        "outputId": "71ed957c-d85b-4113-d428-7662b9603cbb"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>i know  i was listenin to bad habit earlier and i started freakin at his part</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Layin n bed with a headache  ughhhh      waitin on your call</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Funeral ceremony      gloomy friday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>wants to hang out with friends SOON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>We want to trade with someone who has Houston tickets but no one will</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   emotion                                                                               tweets\n",
              "0        0   i know  i was listenin to bad habit earlier and i started freakin at his part     \n",
              "1        2                   Layin n bed with a headache  ughhhh      waitin on your call      \n",
              "2        2                                            Funeral ceremony      gloomy friday      \n",
              "3        1                                                wants to hang out with friends SOON  \n",
              "4        0              We want to trade with someone who has Houston tickets but no one will  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fcu3-G2sLRmi"
      },
      "source": [
        "# Save Clean Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LsiefCMBJbt"
      },
      "source": [
        "df.to_csv('/content/drive/MyDrive/InfluenceAnalysis/crowdFlower/crowdFlower_clean_our_combined.csv',index=None)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xHmdjAf53y2"
      },
      "source": [
        "#Stratified Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUu1Fohh9oC6"
      },
      "source": [
        "demo = df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqYhM6xF9QEN"
      },
      "source": [
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iFozdld9jA4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6baeb788-8ddc-4678-9519-e2cd34bb2e8b"
      },
      "source": [
        "sss.get_n_splits(demo['tweets'], demo['emotion'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7XHf-AA_EOL"
      },
      "source": [
        "df_train= [] \n",
        "df_test =[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zae2nC9P9tLp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b14d3d18-6b1e-4577-bfc9-85ae8eb32f3a"
      },
      "source": [
        "for train_index, test_index in sss.split(demo['tweets'], demo['emotion']):\n",
        "  print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "  X_train, X_test = demo['tweets'][train_index], demo['tweets'][test_index]\n",
        "  y_train, y_test = demo['emotion'][train_index], demo['emotion'][test_index]\n",
        "\n",
        "  df_train = pd.DataFrame({\n",
        "      'tweets' : X_train,\n",
        "      'emotion' : y_train\n",
        "  })\n",
        "  df_test = pd.DataFrame({\n",
        "      'tweets' : X_test,\n",
        "      'emotion' : y_test\n",
        "  })\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN: [26167 36619 28642 ... 31848 33646 13825] TEST: [14080 27123   217 ... 26570 36693 27606]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu--F45I_9DK"
      },
      "source": [
        "df_train.to_csv('/content/drive/MyDrive/InfluenceAnalysis/crowdFlower/crowdFlower_clean1_train.csv',index=None)\n",
        "df_test.to_csv('/content/drive/MyDrive/InfluenceAnalysis/crowdFlower/crowdFlower_clean1_test.csv',index=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fKf--hMAL0e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}