{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AllEmointGen_Amp1.2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harrymkwn/InfluenceAnalysis/blob/master/AllEmointGen_Amp1_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkuKKcIUmM27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22bfe860-7f0a-440b-c481-2afda867634c"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from gensim.models import Word2Vec\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import  drive\n",
        "drive.mount('/content/drive')\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('all')\n",
        "device_name = tf.test.gpu_device_name()\n",
        "print(device_name)\n",
        "df = pd.read_csv('/content/drive/MyDrive/InfluenceAnalysis/Data/Tweets_clean_data.csv')\n",
        "df = df.sample(frac=1,random_state=32)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Package alpino is already up-to-date!\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    |   Package comtrans is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Package crubadan is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Package dolch is already up-to-date!\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Package floresta is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Package indian is already up-to-date!\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    |   Package jeita is already up-to-date!\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Package kimmo is already up-to-date!\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    |   Package knbc is already up-to-date!\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    |   Package machado is already up-to-date!\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Package paradigms is already up-to-date!\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Package pil is already up-to-date!\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Package pl196x is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    |   Package propbank is already up-to-date!\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Package ptb is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Package qc is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Package rte is already up-to-date!\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    |   Package semcor is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Package smultron is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Package switchboard is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Package ycoe is already up-to-date!\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Package rslp is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Package porter_test is already up-to-date!\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n",
            "/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yV6_xYSnZHt"
      },
      "source": [
        "category_dict = {\"anger\":[1,0,0,0],\"sadness\":[0,1,0,0],\"fear\":[0,0,1,0],\"joy\":[0,0,0,1]}\n",
        "data_tweet = [x.lower().split() for x in df['Tweet']]\n",
        "data_cat = np.array([category_dict[x] for x in df['Emotion']])\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PmA3_Ihp-Ao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc0dd298-beb7-480a-d197-e79c1e030a1c"
      },
      "source": [
        "print(data_tweet[:5])\n",
        "print(data_cat[:5])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['with', 'their', 'faggy', 'colors', 'are', 'nice', 'is', 'ok', 'too', 'even', 'tho', 'some', 'might', 'take', 'offense', 'because', 'words', 'lol'], ['unbelievable', 'takes', '10', 'minutes', 'to', 'get', 'through', 'to', 'then', 'there', 'is', 'a', 'fault', 'and', 'the', 'call', 'hangs', 'up', 'treatcustomersfairly'], ['well', 'i', 'did', 'hear', 'once', 'before', 'that', 'girls', 'are', 'attracted', 'to', 'men', 'that', 'lok', 'like', 'their', 'dad', 'ok', 'hand'], ['agreed', 'so', 'tired', 'of', 'this', 'nonsense', 'soros', 'must', 'be', 'elated'], ['by', 'the', 'way', 'i', 'am', 'wearing', 'the', 'smile', 'you', 'gave', 'me', 'today', 'n', 'you', 'me']]\n",
            "[[1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [0 1 0 0]\n",
            " [0 0 0 1]\n",
            " [0 0 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mIV-pI5C44j"
      },
      "source": [
        "# Parameters\n",
        "Min_count = 0\n",
        "Embedding_size = 200\n",
        "Window_size = 5\n",
        "Negative_sampling = 00"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUSBfiE0nTVv"
      },
      "source": [
        "w2v_sg = Word2Vec(min_count=Min_count,\n",
        "                     window=Window_size,\n",
        "                     size=Embedding_size,\n",
        "                     negative=Negative_sampling,sg=1)\n",
        "w2v_sg.build_vocab(data_tweet)\n",
        "w2v_sg.train(data_tweet, total_examples=w2v_sg.corpus_count, epochs=5)\n",
        "w2v_cbow = Word2Vec(min_count=Min_count,\n",
        "                     window=Window_size,\n",
        "                     size=Embedding_size,\n",
        "                     negative=Negative_sampling,sg=0)\n",
        "w2v_cbow.build_vocab(data_tweet)\n",
        "w2v_cbow.train(data_tweet, total_examples=w2v_cbow.corpus_count, epochs=5)\n",
        "w2v_sg.wv.init_sims(True)\n",
        "w2v_cbow.wv.init_sims(True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVzquoxb6FQJ"
      },
      "source": [
        "vocab_sg = w2v_sg.wv.vocab\n",
        "vocab_sg = [x for x in vocab_sg]\n",
        "vocab_cbow = w2v_cbow.wv.vocab\n",
        "vocab_cbow = [x for x in vocab_cbow] \n",
        "vocab_glove = {}\n",
        "with open(\"/content/drive/My Drive/InfluenceAnalysis/glove/glove.twitter.27B.200d.txt\", 'r', encoding=\"utf-8\") as f:\n",
        "  for line in f:\n",
        "      values = line.split()\n",
        "      word = values[0]\n",
        "      vector = np.asarray(values[1:], \"float32\")\n",
        "      vocab_glove[word] = vector"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdgSI9FSmw60"
      },
      "source": [
        "batch_size = 100\r\n",
        "Max_input_size = max([len(x) for x in data_tweet])\r\n",
        "data_tweet = [nltk.pos_tag(x) for x in data_tweet]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArwAlW-wmZxv"
      },
      "source": [
        "def vec_gen(w2v,vocab,data_tweet,data_cat,batch_size,Max_input_size,Embedding_size,mul_factor=1.2):\r\n",
        "  while True:\r\n",
        "    for k in range(int(len(data_tweet)/batch_size)):\r\n",
        "      res=[]\r\n",
        "      for x in data_tweet[k*(batch_size):(k+1)*(batch_size)]:\r\n",
        "        tweet = [(w2v.wv.word_vec(i[0]),i[1]) for i in x if i[0] in vocab]\r\n",
        "        l=len(tweet)\r\n",
        "        for i in range(l):\r\n",
        "          if tweet[i][1][:2]=='JJ' or tweet[i][1][:2]=='RB' or tweet[i][1][:2]=='VB':\r\n",
        "            tweet[i]=((tweet[i][0])*mul_factor,tweet[i][1])\r\n",
        "        res+=[np.array([x[0] for x in tweet])]\r\n",
        "      temp = np.array([np.pad(z.flatten(),(0,Max_input_size*Embedding_size-len(z.flatten()))).reshape(Max_input_size,Embedding_size) for z in res])\r\n",
        "      tempres = data_cat[k*(batch_size):(k+1)*(batch_size)]\r\n",
        "      yield (temp,tempres)          \r\n",
        "      \r\n",
        "def glove_gen(vocab,data_tweet,data_cat,batch_size,Max_input_size,Embedding_size,mul_factor=1.2):\r\n",
        "  while True:\r\n",
        "    for k in range(int(len(data_tweet)/batch_size)):\r\n",
        "      res=[]\r\n",
        "      for x in data_tweet[k*(batch_size):(k+1)*(batch_size)]:\r\n",
        "        tweet = [(vocab[i[0]],i[1]) for i in x if i[0] in vocab.keys()]\r\n",
        "        l=len(tweet)\r\n",
        "        for i in range(l):\r\n",
        "          if tweet[i][1][:2]=='JJ' or tweet[i][1][:2]=='RB' or tweet[i][1][:2]=='VB':\r\n",
        "            tweet[i]=((tweet[i][0])*mul_factor,tweet[i][1])\r\n",
        "        res+=[np.array([x[0] for x in tweet])]\r\n",
        "      temp = np.array([np.pad(z.flatten(),(0,Max_input_size*Embedding_size-len(z.flatten()))).reshape(Max_input_size,Embedding_size) for z in res])\r\n",
        "      tempres = data_cat[k*(batch_size):(k+1)*(batch_size)]\r\n",
        "      yield (temp,tempres)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Fue2npdFINi"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data_tweet, data_cat, test_size=0.20, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42)\n",
        "result_table = [0,0,0,0,0,0,0,0,0]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0leTuTOb3naL"
      },
      "source": [
        "epochs = 60"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNj8uX_IBWt1"
      },
      "source": [
        "from keras import backend as K\r\n",
        "def recall(y_true, y_pred):\r\n",
        "        \"\"\"Recall metric.\r\n",
        "\r\n",
        "        Only computes a batch-wise average of recall.\r\n",
        "\r\n",
        "        Computes the recall, a metric for multi-label classification of\r\n",
        "        how many relevant items are selected.\r\n",
        "        \"\"\"\r\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\r\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\r\n",
        "        recalls = true_positives / (possible_positives + K.epsilon())\r\n",
        "        return recalls\r\n",
        "def precision(y_true, y_pred):\r\n",
        "        \"\"\"Precision metric.\r\n",
        "\r\n",
        "        Only computes a batch-wise average of precision.\r\n",
        "\r\n",
        "        Computes the precision, a metric for multi-label classification of\r\n",
        "        how many selected items are relevant.\r\n",
        "        \"\"\"\r\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\r\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\r\n",
        "        precisions = true_positives / (predicted_positives + K.epsilon())\r\n",
        "        return precisions\r\n",
        "def f1(y_true, y_pred):\r\n",
        "    precisions = precision(y_true, y_pred)\r\n",
        "    recalls = recall(y_true, y_pred)\r\n",
        "    return 2*((precisions*recalls)/(precisions+recalls+K.epsilon()))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GfgXfAFlD1J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7702969b-fb1a-4294-a775-f9d511802d1c"
      },
      "source": [
        "model_sg = tf.keras.Sequential()\n",
        "model_sg.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\n",
        "model_sg.add(tf.keras.layers.LSTM(64))\n",
        "model_sg.add(tf.keras.layers.Dropout(0.2))\n",
        "model_sg.add(tf.keras.layers.Dense(64,activation='relu'))\n",
        "model_sg.add(tf.keras.layers.Dropout(0.2))\n",
        "model_sg.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
        "model_sg.compile(loss='categorical_crossentropy',optimizer='adam', \n",
        "                           metrics=['accuracy',f1,precision,recall])\n",
        "sg_train_gen=vec_gen(w2v_sg,vocab_sg,X_train,y_train,batch_size,Max_input_size,Embedding_size)\n",
        "sg_val_gen=vec_gen(w2v_sg,vocab_sg,X_val,y_val,batch_size,Max_input_size,Embedding_size)\n",
        "history_sg_lstm = model_sg.fit_generator(sg_train_gen,validation_data=sg_val_gen,validation_steps=int((len(X_val)/batch_size)+1),steps_per_epoch=int((len(X_train)/batch_size)+1),epochs=epochs)\n",
        "history = model_sg.evaluate(x = vec_gen(w2v_sg,vocab_sg,X_test,y_test,batch_size,Max_input_size,Embedding_size),steps=int(len(y_test)/batch_size))\n",
        "print(history)\n",
        "\n",
        "result_table[0]=history[1]\n",
        "print(\"SG_LSTM\")\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "46/46 [==============================] - 37s 114ms/step - loss: 1.3825 - accuracy: 0.2964 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3728 - val_accuracy: 0.3300 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 1.3776 - accuracy: 0.3054 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3711 - val_accuracy: 0.3367 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.3766 - accuracy: 0.3106 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3706 - val_accuracy: 0.3333 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 1.3758 - accuracy: 0.3164 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3697 - val_accuracy: 0.3350 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 5/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.3761 - accuracy: 0.3129 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3696 - val_accuracy: 0.3383 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 6/60\n",
            "46/46 [==============================] - 4s 95ms/step - loss: 1.3765 - accuracy: 0.3119 - f1: 1.3491e-04 - precision: 0.0068 - recall: 6.8131e-05 - val_loss: 1.3712 - val_accuracy: 0.3292 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 7/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.3756 - accuracy: 0.3144 - f1: 1.4730e-04 - precision: 0.0074 - recall: 7.4389e-05 - val_loss: 1.3719 - val_accuracy: 0.3283 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 8/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 1.3764 - accuracy: 0.3113 - f1: 1.6007e-04 - precision: 0.0081 - recall: 8.0836e-05 - val_loss: 1.3686 - val_accuracy: 0.3375 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 9/60\n",
            "46/46 [==============================] - 4s 95ms/step - loss: 1.3724 - accuracy: 0.3148 - f1: 0.0045 - precision: 0.0410 - recall: 0.0025 - val_loss: 1.3500 - val_accuracy: 0.3400 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 10/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.3402 - accuracy: 0.3375 - f1: 0.1089 - precision: 0.5405 - recall: 0.0646 - val_loss: 1.3506 - val_accuracy: 0.3525 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 11/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.3092 - accuracy: 0.3859 - f1: 0.1062 - precision: 0.5001 - recall: 0.0661 - val_loss: 1.3428 - val_accuracy: 0.3550 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 12/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 1.2965 - accuracy: 0.3968 - f1: 0.1616 - precision: 0.5947 - recall: 0.0990 - val_loss: 1.3314 - val_accuracy: 0.3558 - val_f1: 0.2134 - val_precision: 0.5180 - val_recall: 0.1350\n",
            "Epoch 13/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.2925 - accuracy: 0.4027 - f1: 0.1907 - precision: 0.5709 - recall: 0.1187 - val_loss: 1.3226 - val_accuracy: 0.3633 - val_f1: 0.2303 - val_precision: 0.5321 - val_recall: 0.1475\n",
            "Epoch 14/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 1.2899 - accuracy: 0.4108 - f1: 0.2284 - precision: 0.5870 - recall: 0.1458 - val_loss: 1.3082 - val_accuracy: 0.3750 - val_f1: 0.2245 - val_precision: 0.5429 - val_recall: 0.1425\n",
            "Epoch 15/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 1.2784 - accuracy: 0.4176 - f1: 0.2566 - precision: 0.6016 - recall: 0.1657 - val_loss: 1.3145 - val_accuracy: 0.3625 - val_f1: 0.2416 - val_precision: 0.5278 - val_recall: 0.1575\n",
            "Epoch 16/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 1.2612 - accuracy: 0.4208 - f1: 0.2674 - precision: 0.5999 - recall: 0.1745 - val_loss: 1.3060 - val_accuracy: 0.3642 - val_f1: 0.2565 - val_precision: 0.5538 - val_recall: 0.1675\n",
            "Epoch 17/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 1.2540 - accuracy: 0.4301 - f1: 0.2835 - precision: 0.6241 - recall: 0.1854 - val_loss: 1.3091 - val_accuracy: 0.3692 - val_f1: 0.2624 - val_precision: 0.5249 - val_recall: 0.1758\n",
            "Epoch 18/60\n",
            "46/46 [==============================] - 5s 102ms/step - loss: 1.2415 - accuracy: 0.4407 - f1: 0.2873 - precision: 0.6187 - recall: 0.1892 - val_loss: 1.3182 - val_accuracy: 0.3683 - val_f1: 0.2542 - val_precision: 0.5270 - val_recall: 0.1683\n",
            "Epoch 19/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.2302 - accuracy: 0.4456 - f1: 0.3123 - precision: 0.6536 - recall: 0.2077 - val_loss: 1.3058 - val_accuracy: 0.3783 - val_f1: 0.2777 - val_precision: 0.5279 - val_recall: 0.1892\n",
            "Epoch 20/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 1.2359 - accuracy: 0.4390 - f1: 0.2773 - precision: 0.6283 - recall: 0.1814 - val_loss: 1.3062 - val_accuracy: 0.3842 - val_f1: 0.2809 - val_precision: 0.5317 - val_recall: 0.1917\n",
            "Epoch 21/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.2254 - accuracy: 0.4455 - f1: 0.3190 - precision: 0.6542 - recall: 0.2148 - val_loss: 1.3007 - val_accuracy: 0.3950 - val_f1: 0.2986 - val_precision: 0.5160 - val_recall: 0.2108\n",
            "Epoch 22/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.2268 - accuracy: 0.4341 - f1: 0.3158 - precision: 0.6426 - recall: 0.2117 - val_loss: 1.3121 - val_accuracy: 0.3892 - val_f1: 0.2986 - val_precision: 0.5213 - val_recall: 0.2100\n",
            "Epoch 23/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 1.2130 - accuracy: 0.4470 - f1: 0.3249 - precision: 0.6773 - recall: 0.2163 - val_loss: 1.2884 - val_accuracy: 0.4200 - val_f1: 0.3063 - val_precision: 0.5370 - val_recall: 0.2150\n",
            "Epoch 24/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 1.2144 - accuracy: 0.4407 - f1: 0.3283 - precision: 0.6585 - recall: 0.2201 - val_loss: 1.2994 - val_accuracy: 0.4042 - val_f1: 0.3041 - val_precision: 0.5276 - val_recall: 0.2142\n",
            "Epoch 25/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.2217 - accuracy: 0.4425 - f1: 0.3310 - precision: 0.6602 - recall: 0.2228 - val_loss: 1.3130 - val_accuracy: 0.3717 - val_f1: 0.1389 - val_precision: 0.6540 - val_recall: 0.0783\n",
            "Epoch 26/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.2056 - accuracy: 0.4651 - f1: 0.3115 - precision: 0.6869 - recall: 0.2066 - val_loss: 1.3114 - val_accuracy: 0.3833 - val_f1: 0.2840 - val_precision: 0.5466 - val_recall: 0.1925\n",
            "Epoch 27/60\n",
            "46/46 [==============================] - 4s 95ms/step - loss: 1.2022 - accuracy: 0.4721 - f1: 0.3418 - precision: 0.6784 - recall: 0.2293 - val_loss: 1.3247 - val_accuracy: 0.3750 - val_f1: 0.2619 - val_precision: 0.5694 - val_recall: 0.1708\n",
            "Epoch 28/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.1693 - accuracy: 0.4830 - f1: 0.3660 - precision: 0.7080 - recall: 0.2483 - val_loss: 1.3332 - val_accuracy: 0.3758 - val_f1: 0.2354 - val_precision: 0.5719 - val_recall: 0.1492\n",
            "Epoch 29/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 1.1719 - accuracy: 0.4785 - f1: 0.3551 - precision: 0.6982 - recall: 0.2395 - val_loss: 1.3049 - val_accuracy: 0.3908 - val_f1: 0.2454 - val_precision: 0.5812 - val_recall: 0.1567\n",
            "Epoch 30/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 1.1641 - accuracy: 0.4892 - f1: 0.3704 - precision: 0.7030 - recall: 0.2528 - val_loss: 1.3280 - val_accuracy: 0.3800 - val_f1: 0.2643 - val_precision: 0.5860 - val_recall: 0.1717\n",
            "Epoch 31/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 1.1874 - accuracy: 0.4613 - f1: 0.3472 - precision: 0.6920 - recall: 0.2330 - val_loss: 1.3307 - val_accuracy: 0.3767 - val_f1: 0.2538 - val_precision: 0.5683 - val_recall: 0.1642\n",
            "Epoch 32/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 1.1606 - accuracy: 0.4880 - f1: 0.3728 - precision: 0.6871 - recall: 0.2577 - val_loss: 1.3129 - val_accuracy: 0.4083 - val_f1: 0.2817 - val_precision: 0.5692 - val_recall: 0.1883\n",
            "Epoch 33/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 1.1445 - accuracy: 0.5057 - f1: 0.3948 - precision: 0.6837 - recall: 0.2802 - val_loss: 1.3180 - val_accuracy: 0.4133 - val_f1: 0.3201 - val_precision: 0.6026 - val_recall: 0.2200\n",
            "Epoch 34/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 1.1451 - accuracy: 0.5041 - f1: 0.3982 - precision: 0.6893 - recall: 0.2827 - val_loss: 1.3329 - val_accuracy: 0.3933 - val_f1: 0.3155 - val_precision: 0.5869 - val_recall: 0.2183\n",
            "Epoch 35/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 1.1457 - accuracy: 0.5107 - f1: 0.3970 - precision: 0.6816 - recall: 0.2825 - val_loss: 1.3492 - val_accuracy: 0.4117 - val_f1: 0.3600 - val_precision: 0.5309 - val_recall: 0.2742\n",
            "Epoch 36/60\n",
            "46/46 [==============================] - 4s 99ms/step - loss: 1.1300 - accuracy: 0.5190 - f1: 0.4177 - precision: 0.6899 - recall: 0.3010 - val_loss: 1.3718 - val_accuracy: 0.4025 - val_f1: 0.3718 - val_precision: 0.5034 - val_recall: 0.2967\n",
            "Epoch 37/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 1.1300 - accuracy: 0.5157 - f1: 0.4094 - precision: 0.6740 - recall: 0.2970 - val_loss: 1.3524 - val_accuracy: 0.4308 - val_f1: 0.3742 - val_precision: 0.5653 - val_recall: 0.2817\n",
            "Epoch 38/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.1062 - accuracy: 0.5362 - f1: 0.4515 - precision: 0.7071 - recall: 0.3339 - val_loss: 1.3005 - val_accuracy: 0.4475 - val_f1: 0.3889 - val_precision: 0.5735 - val_recall: 0.2958\n",
            "Epoch 39/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 1.0911 - accuracy: 0.5506 - f1: 0.4536 - precision: 0.7158 - recall: 0.3342 - val_loss: 1.3001 - val_accuracy: 0.4442 - val_f1: 0.3764 - val_precision: 0.5951 - val_recall: 0.2775\n",
            "Epoch 40/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.0693 - accuracy: 0.5622 - f1: 0.4648 - precision: 0.7246 - recall: 0.3439 - val_loss: 1.3147 - val_accuracy: 0.4425 - val_f1: 0.3687 - val_precision: 0.5742 - val_recall: 0.2742\n",
            "Epoch 41/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 1.0579 - accuracy: 0.5689 - f1: 0.4852 - precision: 0.7106 - recall: 0.3709 - val_loss: 1.2899 - val_accuracy: 0.4525 - val_f1: 0.3767 - val_precision: 0.5879 - val_recall: 0.2792\n",
            "Epoch 42/60\n",
            "46/46 [==============================] - 4s 95ms/step - loss: 1.0628 - accuracy: 0.5665 - f1: 0.4680 - precision: 0.7296 - recall: 0.3468 - val_loss: 1.2992 - val_accuracy: 0.4667 - val_f1: 0.4080 - val_precision: 0.5788 - val_recall: 0.3167\n",
            "Epoch 43/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.0423 - accuracy: 0.5740 - f1: 0.4889 - precision: 0.7217 - recall: 0.3712 - val_loss: 1.3151 - val_accuracy: 0.4542 - val_f1: 0.3631 - val_precision: 0.6249 - val_recall: 0.2575\n",
            "Epoch 44/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 1.0314 - accuracy: 0.5832 - f1: 0.4965 - precision: 0.7379 - recall: 0.3768 - val_loss: 1.2633 - val_accuracy: 0.4633 - val_f1: 0.3896 - val_precision: 0.6437 - val_recall: 0.2817\n",
            "Epoch 45/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 1.0159 - accuracy: 0.5848 - f1: 0.5054 - precision: 0.7432 - recall: 0.3856 - val_loss: 1.2710 - val_accuracy: 0.4783 - val_f1: 0.3907 - val_precision: 0.6391 - val_recall: 0.2825\n",
            "Epoch 46/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.9904 - accuracy: 0.6035 - f1: 0.5138 - precision: 0.7711 - recall: 0.3880 - val_loss: 1.2863 - val_accuracy: 0.4792 - val_f1: 0.4133 - val_precision: 0.5943 - val_recall: 0.3183\n",
            "Epoch 47/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.9598 - accuracy: 0.6090 - f1: 0.5282 - precision: 0.7866 - recall: 0.3995 - val_loss: 1.2983 - val_accuracy: 0.4833 - val_f1: 0.4241 - val_precision: 0.5697 - val_recall: 0.3392\n",
            "Epoch 48/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.9388 - accuracy: 0.6183 - f1: 0.5542 - precision: 0.7801 - recall: 0.4316 - val_loss: 1.2732 - val_accuracy: 0.4850 - val_f1: 0.4299 - val_precision: 0.5976 - val_recall: 0.3367\n",
            "Epoch 49/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.9156 - accuracy: 0.6316 - f1: 0.5625 - precision: 0.7648 - recall: 0.4478 - val_loss: 1.2810 - val_accuracy: 0.4883 - val_f1: 0.4295 - val_precision: 0.6108 - val_recall: 0.3325\n",
            "Epoch 50/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.8760 - accuracy: 0.6597 - f1: 0.6032 - precision: 0.7592 - recall: 0.5026 - val_loss: 1.3021 - val_accuracy: 0.4858 - val_f1: 0.4157 - val_precision: 0.5938 - val_recall: 0.3208\n",
            "Epoch 51/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.8828 - accuracy: 0.6562 - f1: 0.5759 - precision: 0.7880 - recall: 0.4564 - val_loss: 1.3028 - val_accuracy: 0.4917 - val_f1: 0.4256 - val_precision: 0.5893 - val_recall: 0.3342\n",
            "Epoch 52/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.8644 - accuracy: 0.6518 - f1: 0.5974 - precision: 0.7827 - recall: 0.4862 - val_loss: 1.3423 - val_accuracy: 0.5000 - val_f1: 0.4415 - val_precision: 0.5827 - val_recall: 0.3567\n",
            "Epoch 53/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.8324 - accuracy: 0.6803 - f1: 0.6115 - precision: 0.7709 - recall: 0.5085 - val_loss: 1.3116 - val_accuracy: 0.4958 - val_f1: 0.4451 - val_precision: 0.5844 - val_recall: 0.3600\n",
            "Epoch 54/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.8186 - accuracy: 0.6810 - f1: 0.6158 - precision: 0.7950 - recall: 0.5051 - val_loss: 1.3292 - val_accuracy: 0.5158 - val_f1: 0.4447 - val_precision: 0.5935 - val_recall: 0.3567\n",
            "Epoch 55/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.8070 - accuracy: 0.6736 - f1: 0.6310 - precision: 0.7733 - recall: 0.5356 - val_loss: 1.3187 - val_accuracy: 0.4858 - val_f1: 0.4235 - val_precision: 0.5979 - val_recall: 0.3292\n",
            "Epoch 56/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.8027 - accuracy: 0.6696 - f1: 0.6124 - precision: 0.8027 - recall: 0.4983 - val_loss: 1.4250 - val_accuracy: 0.4975 - val_f1: 0.4449 - val_precision: 0.5677 - val_recall: 0.3667\n",
            "Epoch 57/60\n",
            "46/46 [==============================] - 4s 99ms/step - loss: 0.8599 - accuracy: 0.6490 - f1: 0.5985 - precision: 0.7685 - recall: 0.4920 - val_loss: 1.2695 - val_accuracy: 0.5075 - val_f1: 0.4412 - val_precision: 0.6525 - val_recall: 0.3342\n",
            "Epoch 58/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.8578 - accuracy: 0.6506 - f1: 0.5848 - precision: 0.7995 - recall: 0.4637 - val_loss: 1.2841 - val_accuracy: 0.5100 - val_f1: 0.4472 - val_precision: 0.6229 - val_recall: 0.3492\n",
            "Epoch 59/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.8472 - accuracy: 0.6526 - f1: 0.5926 - precision: 0.7948 - recall: 0.4750 - val_loss: 1.3572 - val_accuracy: 0.5150 - val_f1: 0.4456 - val_precision: 0.5928 - val_recall: 0.3575\n",
            "Epoch 60/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.8527 - accuracy: 0.6520 - f1: 0.6050 - precision: 0.7768 - recall: 0.4983 - val_loss: 1.4317 - val_accuracy: 0.5025 - val_f1: 0.4575 - val_precision: 0.5590 - val_recall: 0.3875\n",
            "14/14 [==============================] - 1s 78ms/step - loss: 1.4631 - accuracy: 0.4736 - f1: 0.4386 - precision: 0.5457 - recall: 0.3671\n",
            "[1.463075876235962, 0.47357141971588135, 0.4385890066623688, 0.5457113981246948, 0.3671428859233856]\n",
            "SG_LSTM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJHtKjzc1SA8",
        "outputId": "c52b9295-cdc2-4cb6-cfc1-362ffcbcf768"
      },
      "source": [
        "model_sg_bi = tf.keras.Sequential()\r\n",
        "model_sg_bi.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_sg_bi.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64),merge_mode='concat'))\r\n",
        "model_sg_bi.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_sg_bi.add(tf.keras.layers.Dense(64,activation='relu'))\r\n",
        "model_sg_bi.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_sg_bi.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_sg_bi.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy',f1,precision,recall])\r\n",
        "history_sg_bi = model_sg_bi.fit_generator(sg_train_gen,validation_data=sg_val_gen,validation_steps=int((len(X_val)/batch_size)+1),steps_per_epoch=int((len(X_train)/batch_size)+1),epochs=epochs)\r\n",
        "history = model_sg_bi.evaluate(x = vec_gen(w2v_sg,vocab_sg,X_test,y_test,batch_size,Max_input_size,Embedding_size),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table[1]=history[1]\r\n",
        "print(\"SG_BI\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "46/46 [==============================] - 8s 115ms/step - loss: 1.3822 - accuracy: 0.2884 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3643 - val_accuracy: 0.3292 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/60\n",
            "46/46 [==============================] - 5s 98ms/step - loss: 1.3622 - accuracy: 0.3218 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3272 - val_accuracy: 0.3683 - val_f1: 0.0017 - val_precision: 0.0833 - val_recall: 8.3333e-04\n",
            "Epoch 3/60\n",
            "46/46 [==============================] - 5s 102ms/step - loss: 1.2960 - accuracy: 0.4007 - f1: 0.0543 - precision: 0.5299 - recall: 0.0294 - val_loss: 1.2757 - val_accuracy: 0.4133 - val_f1: 0.1352 - val_precision: 0.5552 - val_recall: 0.0775\n",
            "Epoch 4/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 1.2107 - accuracy: 0.4659 - f1: 0.2214 - precision: 0.6455 - recall: 0.1361 - val_loss: 1.2349 - val_accuracy: 0.4483 - val_f1: 0.2924 - val_precision: 0.5594 - val_recall: 0.1983\n",
            "Epoch 5/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 1.1534 - accuracy: 0.5033 - f1: 0.3397 - precision: 0.6478 - recall: 0.2323 - val_loss: 1.2279 - val_accuracy: 0.4600 - val_f1: 0.3309 - val_precision: 0.5434 - val_recall: 0.2383\n",
            "Epoch 6/60\n",
            "46/46 [==============================] - 5s 102ms/step - loss: 1.0900 - accuracy: 0.5405 - f1: 0.4223 - precision: 0.6818 - recall: 0.3079 - val_loss: 1.2321 - val_accuracy: 0.4742 - val_f1: 0.3650 - val_precision: 0.5404 - val_recall: 0.2758\n",
            "Epoch 7/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 1.0603 - accuracy: 0.5693 - f1: 0.4547 - precision: 0.6954 - recall: 0.3405 - val_loss: 1.2186 - val_accuracy: 0.4783 - val_f1: 0.3764 - val_precision: 0.5570 - val_recall: 0.2850\n",
            "Epoch 8/60\n",
            "46/46 [==============================] - 4s 99ms/step - loss: 1.0296 - accuracy: 0.5881 - f1: 0.4867 - precision: 0.7236 - recall: 0.3700 - val_loss: 1.2206 - val_accuracy: 0.4858 - val_f1: 0.4177 - val_precision: 0.5598 - val_recall: 0.3333\n",
            "Epoch 9/60\n",
            "46/46 [==============================] - 5s 102ms/step - loss: 0.9880 - accuracy: 0.6150 - f1: 0.5350 - precision: 0.7184 - recall: 0.4272 - val_loss: 1.2103 - val_accuracy: 0.4883 - val_f1: 0.4141 - val_precision: 0.5568 - val_recall: 0.3300\n",
            "Epoch 10/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.9326 - accuracy: 0.6362 - f1: 0.5714 - precision: 0.7616 - recall: 0.4591 - val_loss: 1.2373 - val_accuracy: 0.4775 - val_f1: 0.4196 - val_precision: 0.5468 - val_recall: 0.3408\n",
            "Epoch 11/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.9225 - accuracy: 0.6345 - f1: 0.5800 - precision: 0.7440 - recall: 0.4768 - val_loss: 1.2330 - val_accuracy: 0.4900 - val_f1: 0.4183 - val_precision: 0.5491 - val_recall: 0.3383\n",
            "Epoch 12/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.8908 - accuracy: 0.6541 - f1: 0.6026 - precision: 0.7477 - recall: 0.5060 - val_loss: 1.2784 - val_accuracy: 0.4792 - val_f1: 0.4391 - val_precision: 0.5480 - val_recall: 0.3667\n",
            "Epoch 13/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.8506 - accuracy: 0.6769 - f1: 0.6428 - precision: 0.7707 - recall: 0.5518 - val_loss: 1.2626 - val_accuracy: 0.4867 - val_f1: 0.4420 - val_precision: 0.5518 - val_recall: 0.3692\n",
            "Epoch 14/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.8078 - accuracy: 0.6987 - f1: 0.6588 - precision: 0.7798 - recall: 0.5715 - val_loss: 1.2576 - val_accuracy: 0.4925 - val_f1: 0.4532 - val_precision: 0.5531 - val_recall: 0.3842\n",
            "Epoch 15/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.7886 - accuracy: 0.7050 - f1: 0.6790 - precision: 0.7939 - recall: 0.5937 - val_loss: 1.2650 - val_accuracy: 0.4975 - val_f1: 0.4795 - val_precision: 0.5651 - val_recall: 0.4167\n",
            "Epoch 16/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.7529 - accuracy: 0.7121 - f1: 0.6904 - precision: 0.7910 - recall: 0.6133 - val_loss: 1.3032 - val_accuracy: 0.5083 - val_f1: 0.4862 - val_precision: 0.5746 - val_recall: 0.4217\n",
            "Epoch 17/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.7285 - accuracy: 0.7382 - f1: 0.7187 - precision: 0.8119 - recall: 0.6460 - val_loss: 1.3499 - val_accuracy: 0.5258 - val_f1: 0.4957 - val_precision: 0.5724 - val_recall: 0.4375\n",
            "Epoch 18/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.6842 - accuracy: 0.7477 - f1: 0.7378 - precision: 0.8190 - recall: 0.6722 - val_loss: 1.2822 - val_accuracy: 0.5208 - val_f1: 0.5058 - val_precision: 0.5765 - val_recall: 0.4508\n",
            "Epoch 19/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.6400 - accuracy: 0.7760 - f1: 0.7548 - precision: 0.8341 - recall: 0.6902 - val_loss: 1.3313 - val_accuracy: 0.5400 - val_f1: 0.5103 - val_precision: 0.5777 - val_recall: 0.4575\n",
            "Epoch 20/60\n",
            "46/46 [==============================] - 5s 103ms/step - loss: 0.6120 - accuracy: 0.7824 - f1: 0.7691 - precision: 0.8444 - recall: 0.7069 - val_loss: 1.3704 - val_accuracy: 0.5308 - val_f1: 0.5216 - val_precision: 0.5803 - val_recall: 0.4742\n",
            "Epoch 21/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.5860 - accuracy: 0.7899 - f1: 0.7782 - precision: 0.8493 - recall: 0.7191 - val_loss: 1.4716 - val_accuracy: 0.5333 - val_f1: 0.5256 - val_precision: 0.5764 - val_recall: 0.4833\n",
            "Epoch 22/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.5569 - accuracy: 0.8002 - f1: 0.7919 - precision: 0.8517 - recall: 0.7403 - val_loss: 1.4611 - val_accuracy: 0.5375 - val_f1: 0.5305 - val_precision: 0.5797 - val_recall: 0.4892\n",
            "Epoch 23/60\n",
            "46/46 [==============================] - 5s 104ms/step - loss: 0.4974 - accuracy: 0.8131 - f1: 0.8111 - precision: 0.8593 - recall: 0.7682 - val_loss: 1.4225 - val_accuracy: 0.5500 - val_f1: 0.5372 - val_precision: 0.5857 - val_recall: 0.4967\n",
            "Epoch 24/60\n",
            "46/46 [==============================] - 5s 104ms/step - loss: 0.4933 - accuracy: 0.8258 - f1: 0.8182 - precision: 0.8688 - recall: 0.7737 - val_loss: 1.4377 - val_accuracy: 0.5525 - val_f1: 0.5359 - val_precision: 0.5825 - val_recall: 0.4967\n",
            "Epoch 25/60\n",
            "46/46 [==============================] - 5s 102ms/step - loss: 0.4538 - accuracy: 0.8298 - f1: 0.8321 - precision: 0.8750 - recall: 0.7934 - val_loss: 1.4408 - val_accuracy: 0.5308 - val_f1: 0.5263 - val_precision: 0.5747 - val_recall: 0.4858\n",
            "Epoch 26/60\n",
            "46/46 [==============================] - 5s 102ms/step - loss: 0.4439 - accuracy: 0.8388 - f1: 0.8403 - precision: 0.8832 - recall: 0.8018 - val_loss: 1.4378 - val_accuracy: 0.5458 - val_f1: 0.5487 - val_precision: 0.5889 - val_recall: 0.5142\n",
            "Epoch 27/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.4089 - accuracy: 0.8587 - f1: 0.8551 - precision: 0.8941 - recall: 0.8195 - val_loss: 1.5279 - val_accuracy: 0.5533 - val_f1: 0.5457 - val_precision: 0.5884 - val_recall: 0.5092\n",
            "Epoch 28/60\n",
            "46/46 [==============================] - 5s 105ms/step - loss: 0.3727 - accuracy: 0.8751 - f1: 0.8676 - precision: 0.9026 - recall: 0.8356 - val_loss: 1.6216 - val_accuracy: 0.5725 - val_f1: 0.5633 - val_precision: 0.5949 - val_recall: 0.5350\n",
            "Epoch 29/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.3630 - accuracy: 0.8739 - f1: 0.8732 - precision: 0.9008 - recall: 0.8474 - val_loss: 1.5051 - val_accuracy: 0.5808 - val_f1: 0.5690 - val_precision: 0.6010 - val_recall: 0.5408\n",
            "Epoch 30/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.3258 - accuracy: 0.8898 - f1: 0.8843 - precision: 0.9094 - recall: 0.8607 - val_loss: 1.6272 - val_accuracy: 0.5833 - val_f1: 0.5843 - val_precision: 0.6142 - val_recall: 0.5575\n",
            "Epoch 31/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.3007 - accuracy: 0.8939 - f1: 0.8928 - precision: 0.9160 - recall: 0.8708 - val_loss: 1.7139 - val_accuracy: 0.5867 - val_f1: 0.5823 - val_precision: 0.6109 - val_recall: 0.5567\n",
            "Epoch 32/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.2828 - accuracy: 0.8952 - f1: 0.8973 - precision: 0.9196 - recall: 0.8763 - val_loss: 1.8813 - val_accuracy: 0.5708 - val_f1: 0.5706 - val_precision: 0.5960 - val_recall: 0.5475\n",
            "Epoch 33/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.3074 - accuracy: 0.8932 - f1: 0.8941 - precision: 0.9135 - recall: 0.8756 - val_loss: 1.6891 - val_accuracy: 0.5992 - val_f1: 0.5959 - val_precision: 0.6167 - val_recall: 0.5767\n",
            "Epoch 34/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.3457 - accuracy: 0.8763 - f1: 0.8766 - precision: 0.8984 - recall: 0.8560 - val_loss: 1.5331 - val_accuracy: 0.6117 - val_f1: 0.6061 - val_precision: 0.6299 - val_recall: 0.5842\n",
            "Epoch 35/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.2807 - accuracy: 0.9017 - f1: 0.9008 - precision: 0.9187 - recall: 0.8839 - val_loss: 1.7792 - val_accuracy: 0.5933 - val_f1: 0.5924 - val_precision: 0.6112 - val_recall: 0.5750\n",
            "Epoch 36/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.2448 - accuracy: 0.9188 - f1: 0.9200 - precision: 0.9333 - recall: 0.9073 - val_loss: 1.8501 - val_accuracy: 0.5767 - val_f1: 0.5783 - val_precision: 0.5991 - val_recall: 0.5592\n",
            "Epoch 37/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.2184 - accuracy: 0.9312 - f1: 0.9293 - precision: 0.9436 - recall: 0.9155 - val_loss: 1.9820 - val_accuracy: 0.5883 - val_f1: 0.5902 - val_precision: 0.6063 - val_recall: 0.5750\n",
            "Epoch 38/60\n",
            "46/46 [==============================] - 5s 102ms/step - loss: 0.2140 - accuracy: 0.9225 - f1: 0.9243 - precision: 0.9369 - recall: 0.9120 - val_loss: 1.9271 - val_accuracy: 0.5933 - val_f1: 0.5882 - val_precision: 0.6040 - val_recall: 0.5733\n",
            "Epoch 39/60\n",
            "46/46 [==============================] - 5s 103ms/step - loss: 0.1941 - accuracy: 0.9361 - f1: 0.9353 - precision: 0.9456 - recall: 0.9253 - val_loss: 2.0909 - val_accuracy: 0.5925 - val_f1: 0.5942 - val_precision: 0.6084 - val_recall: 0.5808\n",
            "Epoch 40/60\n",
            "46/46 [==============================] - 5s 102ms/step - loss: 0.1781 - accuracy: 0.9398 - f1: 0.9400 - precision: 0.9497 - recall: 0.9305 - val_loss: 2.1217 - val_accuracy: 0.5917 - val_f1: 0.5926 - val_precision: 0.6096 - val_recall: 0.5767\n",
            "Epoch 41/60\n",
            "46/46 [==============================] - 5s 102ms/step - loss: 0.2381 - accuracy: 0.9124 - f1: 0.9118 - precision: 0.9268 - recall: 0.8975 - val_loss: 2.0095 - val_accuracy: 0.6025 - val_f1: 0.5991 - val_precision: 0.6149 - val_recall: 0.5842\n",
            "Epoch 42/60\n",
            "46/46 [==============================] - 5s 104ms/step - loss: 0.2009 - accuracy: 0.9307 - f1: 0.9319 - precision: 0.9419 - recall: 0.9223 - val_loss: 2.0565 - val_accuracy: 0.6067 - val_f1: 0.6097 - val_precision: 0.6224 - val_recall: 0.5975\n",
            "Epoch 43/60\n",
            "46/46 [==============================] - 5s 102ms/step - loss: 0.1692 - accuracy: 0.9417 - f1: 0.9421 - precision: 0.9517 - recall: 0.9328 - val_loss: 2.0404 - val_accuracy: 0.5983 - val_f1: 0.5981 - val_precision: 0.6100 - val_recall: 0.5867\n",
            "Epoch 44/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.1742 - accuracy: 0.9433 - f1: 0.9402 - precision: 0.9479 - recall: 0.9328 - val_loss: 2.1044 - val_accuracy: 0.6008 - val_f1: 0.6049 - val_precision: 0.6217 - val_recall: 0.5892\n",
            "Epoch 45/60\n",
            "46/46 [==============================] - 4s 99ms/step - loss: 0.1754 - accuracy: 0.9371 - f1: 0.9380 - precision: 0.9466 - recall: 0.9297 - val_loss: 1.9386 - val_accuracy: 0.6075 - val_f1: 0.6070 - val_precision: 0.6205 - val_recall: 0.5942\n",
            "Epoch 46/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.1501 - accuracy: 0.9484 - f1: 0.9480 - precision: 0.9555 - recall: 0.9407 - val_loss: 2.1393 - val_accuracy: 0.6050 - val_f1: 0.6069 - val_precision: 0.6211 - val_recall: 0.5933\n",
            "Epoch 47/60\n",
            "46/46 [==============================] - 5s 103ms/step - loss: 0.1753 - accuracy: 0.9394 - f1: 0.9388 - precision: 0.9461 - recall: 0.9317 - val_loss: 2.1922 - val_accuracy: 0.6075 - val_f1: 0.6074 - val_precision: 0.6161 - val_recall: 0.5992\n",
            "Epoch 48/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.1525 - accuracy: 0.9478 - f1: 0.9492 - precision: 0.9554 - recall: 0.9431 - val_loss: 2.1506 - val_accuracy: 0.6008 - val_f1: 0.6023 - val_precision: 0.6134 - val_recall: 0.5917\n",
            "Epoch 49/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.1581 - accuracy: 0.9429 - f1: 0.9425 - precision: 0.9499 - recall: 0.9353 - val_loss: 2.0985 - val_accuracy: 0.6075 - val_f1: 0.6077 - val_precision: 0.6240 - val_recall: 0.5925\n",
            "Epoch 50/60\n",
            "46/46 [==============================] - 5s 103ms/step - loss: 0.1493 - accuracy: 0.9461 - f1: 0.9478 - precision: 0.9534 - recall: 0.9424 - val_loss: 2.2753 - val_accuracy: 0.6000 - val_f1: 0.5982 - val_precision: 0.6095 - val_recall: 0.5875\n",
            "Epoch 51/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.1316 - accuracy: 0.9520 - f1: 0.9537 - precision: 0.9594 - recall: 0.9482 - val_loss: 2.2788 - val_accuracy: 0.6050 - val_f1: 0.6035 - val_precision: 0.6158 - val_recall: 0.5917\n",
            "Epoch 52/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.1212 - accuracy: 0.9514 - f1: 0.9522 - precision: 0.9569 - recall: 0.9476 - val_loss: 2.1281 - val_accuracy: 0.6208 - val_f1: 0.6213 - val_precision: 0.6359 - val_recall: 0.6075\n",
            "Epoch 53/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.1253 - accuracy: 0.9588 - f1: 0.9586 - precision: 0.9630 - recall: 0.9543 - val_loss: 2.1991 - val_accuracy: 0.6075 - val_f1: 0.6084 - val_precision: 0.6170 - val_recall: 0.6000\n",
            "Epoch 54/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.1382 - accuracy: 0.9522 - f1: 0.9523 - precision: 0.9582 - recall: 0.9465 - val_loss: 2.2910 - val_accuracy: 0.5992 - val_f1: 0.5964 - val_precision: 0.6074 - val_recall: 0.5858\n",
            "Epoch 55/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.1718 - accuracy: 0.9483 - f1: 0.9468 - precision: 0.9524 - recall: 0.9414 - val_loss: 2.0580 - val_accuracy: 0.5900 - val_f1: 0.5837 - val_precision: 0.5937 - val_recall: 0.5742\n",
            "Epoch 56/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.1451 - accuracy: 0.9509 - f1: 0.9503 - precision: 0.9553 - recall: 0.9454 - val_loss: 2.2040 - val_accuracy: 0.6183 - val_f1: 0.6130 - val_precision: 0.6222 - val_recall: 0.6042\n",
            "Epoch 57/60\n",
            "46/46 [==============================] - 5s 104ms/step - loss: 0.1015 - accuracy: 0.9625 - f1: 0.9634 - precision: 0.9669 - recall: 0.9599 - val_loss: 2.1079 - val_accuracy: 0.6117 - val_f1: 0.6128 - val_precision: 0.6208 - val_recall: 0.6050\n",
            "Epoch 58/60\n",
            "46/46 [==============================] - 5s 102ms/step - loss: 0.0907 - accuracy: 0.9681 - f1: 0.9686 - precision: 0.9712 - recall: 0.9659 - val_loss: 2.2970 - val_accuracy: 0.6075 - val_f1: 0.6074 - val_precision: 0.6168 - val_recall: 0.5983\n",
            "Epoch 59/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.0863 - accuracy: 0.9686 - f1: 0.9682 - precision: 0.9707 - recall: 0.9657 - val_loss: 2.3443 - val_accuracy: 0.6142 - val_f1: 0.6113 - val_precision: 0.6196 - val_recall: 0.6033\n",
            "Epoch 60/60\n",
            "46/46 [==============================] - 5s 103ms/step - loss: 0.0951 - accuracy: 0.9675 - f1: 0.9674 - precision: 0.9698 - recall: 0.9650 - val_loss: 2.3922 - val_accuracy: 0.6183 - val_f1: 0.6157 - val_precision: 0.6241 - val_recall: 0.6075\n",
            "14/14 [==============================] - 1s 78ms/step - loss: 2.0939 - accuracy: 0.6314 - f1: 0.6316 - precision: 0.6392 - recall: 0.6243\n",
            "[2.0939128398895264, 0.631428599357605, 0.6316362619400024, 0.6392024159431458, 0.6242857575416565]\n",
            "SG_BI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opfhhYPH1VoL",
        "outputId": "5249444a-2448-4ca0-dddd-8e5900387809"
      },
      "source": [
        "model_sg_rnn = tf.keras.Sequential()\r\n",
        "model_sg_rnn.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_sg_rnn.add(tf.keras.layers.SimpleRNN(64))\r\n",
        "model_sg_rnn.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_sg_rnn.add(tf.keras.layers.Dense(64,activation='relu'))\r\n",
        "model_sg_rnn.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_sg_rnn.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_sg_rnn.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy',f1,precision,recall])\r\n",
        "history_sg_rnn = model_sg_rnn.fit_generator(sg_train_gen,validation_data=sg_val_gen,validation_steps=int((len(X_val)/batch_size)+1),steps_per_epoch=int((len(X_train)/batch_size)+1),epochs=epochs)\r\n",
        "history = model_sg_rnn.evaluate(x = vec_gen(w2v_sg,vocab_sg,X_test,y_test,batch_size,Max_input_size,Embedding_size),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "\r\n",
        "result_table[2]=history[1]\r\n",
        "print(\"SG_RNN\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "46/46 [==============================] - 7s 134ms/step - loss: 1.3855 - accuracy: 0.2766 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3722 - val_accuracy: 0.3292 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/60\n",
            "46/46 [==============================] - 6s 127ms/step - loss: 1.3772 - accuracy: 0.3026 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3701 - val_accuracy: 0.3300 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/60\n",
            "46/46 [==============================] - 6s 128ms/step - loss: 1.3756 - accuracy: 0.3077 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3582 - val_accuracy: 0.3492 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/60\n",
            "46/46 [==============================] - 6s 131ms/step - loss: 1.3740 - accuracy: 0.3131 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3745 - val_accuracy: 0.3367 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 5/60\n",
            "46/46 [==============================] - 6s 130ms/step - loss: 1.3779 - accuracy: 0.3047 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3712 - val_accuracy: 0.3358 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 6/60\n",
            "46/46 [==============================] - 6s 129ms/step - loss: 1.3704 - accuracy: 0.3091 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3710 - val_accuracy: 0.3333 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 7/60\n",
            "46/46 [==============================] - 6s 129ms/step - loss: 1.3704 - accuracy: 0.2986 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3759 - val_accuracy: 0.3242 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 8/60\n",
            "46/46 [==============================] - 6s 127ms/step - loss: 1.3731 - accuracy: 0.3014 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3734 - val_accuracy: 0.3225 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 9/60\n",
            "46/46 [==============================] - 6s 132ms/step - loss: 1.3636 - accuracy: 0.3252 - f1: 2.8403e-04 - precision: 0.0058 - recall: 1.4573e-04 - val_loss: 1.3752 - val_accuracy: 0.3258 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 10/60\n",
            "46/46 [==============================] - 6s 129ms/step - loss: 1.3641 - accuracy: 0.3151 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3606 - val_accuracy: 0.3508 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 11/60\n",
            "46/46 [==============================] - 6s 132ms/step - loss: 1.3532 - accuracy: 0.3290 - f1: 0.0023 - precision: 0.0418 - recall: 0.0012 - val_loss: 1.3825 - val_accuracy: 0.2892 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 12/60\n",
            "46/46 [==============================] - 6s 129ms/step - loss: 1.3800 - accuracy: 0.2983 - f1: 0.0022 - precision: 0.1126 - recall: 0.0011 - val_loss: 1.3897 - val_accuracy: 0.2825 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 13/60\n",
            "46/46 [==============================] - 6s 131ms/step - loss: 1.3551 - accuracy: 0.3316 - f1: 0.0128 - precision: 0.1507 - recall: 0.0068 - val_loss: 1.3763 - val_accuracy: 0.3133 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 14/60\n",
            "46/46 [==============================] - 6s 132ms/step - loss: 1.3433 - accuracy: 0.3557 - f1: 0.0427 - precision: 0.3181 - recall: 0.0241 - val_loss: 1.3798 - val_accuracy: 0.2942 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 15/60\n",
            "46/46 [==============================] - 6s 134ms/step - loss: 1.3602 - accuracy: 0.3230 - f1: 5.3455e-04 - precision: 0.0270 - recall: 2.6995e-04 - val_loss: 1.3882 - val_accuracy: 0.2708 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 16/60\n",
            "46/46 [==============================] - 6s 129ms/step - loss: 1.3679 - accuracy: 0.3170 - f1: 0.0018 - precision: 0.0924 - recall: 9.2415e-04 - val_loss: 1.3987 - val_accuracy: 0.2942 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 17/60\n",
            "46/46 [==============================] - 6s 128ms/step - loss: 1.3540 - accuracy: 0.3305 - f1: 0.0029 - precision: 0.1018 - recall: 0.0015 - val_loss: 1.3927 - val_accuracy: 0.2992 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 18/60\n",
            "46/46 [==============================] - 6s 135ms/step - loss: 1.3653 - accuracy: 0.3337 - f1: 0.0238 - precision: 0.2737 - recall: 0.0125 - val_loss: 1.3849 - val_accuracy: 0.2850 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 19/60\n",
            "46/46 [==============================] - 6s 133ms/step - loss: 1.3519 - accuracy: 0.3388 - f1: 0.0141 - precision: 0.4490 - recall: 0.0072 - val_loss: 1.4097 - val_accuracy: 0.2808 - val_f1: 0.0017 - val_precision: 0.0833 - val_recall: 8.3333e-04\n",
            "Epoch 20/60\n",
            "46/46 [==============================] - 6s 131ms/step - loss: 1.3689 - accuracy: 0.3281 - f1: 0.0165 - precision: 0.1840 - recall: 0.0087 - val_loss: 1.4075 - val_accuracy: 0.2642 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 21/60\n",
            "46/46 [==============================] - 6s 129ms/step - loss: 1.4117 - accuracy: 0.2605 - f1: 0.0045 - precision: 0.0836 - recall: 0.0023 - val_loss: 1.3747 - val_accuracy: 0.3167 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 22/60\n",
            "46/46 [==============================] - 6s 129ms/step - loss: 1.3822 - accuracy: 0.3031 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3795 - val_accuracy: 0.3108 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 23/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 1.3706 - accuracy: 0.3034 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3786 - val_accuracy: 0.3125 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 24/60\n",
            "46/46 [==============================] - 6s 131ms/step - loss: 1.3673 - accuracy: 0.3142 - f1: 9.9490e-04 - precision: 0.0173 - recall: 5.1511e-04 - val_loss: 1.3812 - val_accuracy: 0.2917 - val_f1: 0.0016 - val_precision: 0.0417 - val_recall: 8.3333e-04\n",
            "Epoch 25/60\n",
            "46/46 [==============================] - 6s 135ms/step - loss: 1.3656 - accuracy: 0.3376 - f1: 0.0103 - precision: 0.2518 - recall: 0.0053 - val_loss: 1.3863 - val_accuracy: 0.3075 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 26/60\n",
            "46/46 [==============================] - 6s 135ms/step - loss: 1.3882 - accuracy: 0.2945 - f1: 0.0116 - precision: 0.1679 - recall: 0.0062 - val_loss: 1.3740 - val_accuracy: 0.3367 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 27/60\n",
            "46/46 [==============================] - 6s 130ms/step - loss: 1.3712 - accuracy: 0.3044 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3740 - val_accuracy: 0.3167 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 28/60\n",
            "46/46 [==============================] - 6s 132ms/step - loss: 1.3697 - accuracy: 0.3224 - f1: 7.4464e-05 - precision: 0.0031 - recall: 3.7741e-05 - val_loss: 1.3935 - val_accuracy: 0.3000 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 29/60\n",
            "46/46 [==============================] - 6s 132ms/step - loss: 1.3724 - accuracy: 0.3220 - f1: 0.0010 - precision: 0.0504 - recall: 5.1033e-04 - val_loss: 1.3897 - val_accuracy: 0.2942 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 30/60\n",
            "46/46 [==============================] - 6s 132ms/step - loss: 1.3656 - accuracy: 0.3282 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.4030 - val_accuracy: 0.2825 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 31/60\n",
            "46/46 [==============================] - 6s 135ms/step - loss: 1.3711 - accuracy: 0.3152 - f1: 6.9758e-04 - precision: 0.0143 - recall: 3.6225e-04 - val_loss: 1.3634 - val_accuracy: 0.3442 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 32/60\n",
            "46/46 [==============================] - 6s 134ms/step - loss: 1.3582 - accuracy: 0.3337 - f1: 0.0058 - precision: 0.2497 - recall: 0.0029 - val_loss: 1.3531 - val_accuracy: 0.3525 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 33/60\n",
            "46/46 [==============================] - 6s 131ms/step - loss: 1.3390 - accuracy: 0.3610 - f1: 0.0094 - precision: 0.1488 - recall: 0.0049 - val_loss: 1.3539 - val_accuracy: 0.3233 - val_f1: 0.0229 - val_precision: 0.7500 - val_recall: 0.0117\n",
            "Epoch 34/60\n",
            "46/46 [==============================] - 6s 131ms/step - loss: 1.3191 - accuracy: 0.3785 - f1: 0.0546 - precision: 0.6398 - recall: 0.0291 - val_loss: 1.3584 - val_accuracy: 0.3275 - val_f1: 0.0478 - val_precision: 0.6081 - val_recall: 0.0250\n",
            "Epoch 35/60\n",
            "46/46 [==============================] - 6s 131ms/step - loss: 1.3164 - accuracy: 0.3704 - f1: 0.0877 - precision: 0.6525 - recall: 0.0488 - val_loss: 1.3509 - val_accuracy: 0.3225 - val_f1: 0.0710 - val_precision: 0.5196 - val_recall: 0.0383\n",
            "Epoch 36/60\n",
            "46/46 [==============================] - 6s 127ms/step - loss: 1.3489 - accuracy: 0.3532 - f1: 0.0650 - precision: 0.4589 - recall: 0.0369 - val_loss: 1.3998 - val_accuracy: 0.2708 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 37/60\n",
            "46/46 [==============================] - 6s 136ms/step - loss: 1.3893 - accuracy: 0.2968 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3816 - val_accuracy: 0.3158 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 38/60\n",
            "46/46 [==============================] - 6s 128ms/step - loss: 1.3813 - accuracy: 0.2867 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3809 - val_accuracy: 0.3225 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 39/60\n",
            "46/46 [==============================] - 6s 134ms/step - loss: 1.3567 - accuracy: 0.3201 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3827 - val_accuracy: 0.2967 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 40/60\n",
            "46/46 [==============================] - 6s 128ms/step - loss: 1.3593 - accuracy: 0.3254 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3787 - val_accuracy: 0.3050 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 41/60\n",
            "46/46 [==============================] - 6s 127ms/step - loss: 1.3565 - accuracy: 0.3349 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3952 - val_accuracy: 0.2733 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 42/60\n",
            "46/46 [==============================] - 6s 136ms/step - loss: 1.3532 - accuracy: 0.3370 - f1: 0.0027 - precision: 0.0997 - recall: 0.0014 - val_loss: 1.3769 - val_accuracy: 0.3050 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 43/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 1.3566 - accuracy: 0.3431 - f1: 7.7899e-04 - precision: 0.0295 - recall: 3.9573e-04 - val_loss: 1.3820 - val_accuracy: 0.3125 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 44/60\n",
            "46/46 [==============================] - 6s 129ms/step - loss: 1.3686 - accuracy: 0.3299 - f1: 0.0030 - precision: 0.0471 - recall: 0.0016 - val_loss: 1.3850 - val_accuracy: 0.2958 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 45/60\n",
            "46/46 [==============================] - 6s 131ms/step - loss: 1.3493 - accuracy: 0.3540 - f1: 0.0031 - precision: 0.0787 - recall: 0.0016 - val_loss: 1.3891 - val_accuracy: 0.2908 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 46/60\n",
            "46/46 [==============================] - 6s 127ms/step - loss: 1.3430 - accuracy: 0.3650 - f1: 0.0134 - precision: 0.2814 - recall: 0.0069 - val_loss: 1.3960 - val_accuracy: 0.2917 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 47/60\n",
            "46/46 [==============================] - 6s 129ms/step - loss: 1.3361 - accuracy: 0.3667 - f1: 0.0339 - precision: 0.4353 - recall: 0.0179 - val_loss: 1.3718 - val_accuracy: 0.3158 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 48/60\n",
            "46/46 [==============================] - 6s 130ms/step - loss: 1.3127 - accuracy: 0.4003 - f1: 0.0496 - precision: 0.4641 - recall: 0.0273 - val_loss: 1.4286 - val_accuracy: 0.2817 - val_f1: 0.0555 - val_precision: 0.2941 - val_recall: 0.0308\n",
            "Epoch 49/60\n",
            "46/46 [==============================] - 6s 129ms/step - loss: 1.2948 - accuracy: 0.4120 - f1: 0.1555 - precision: 0.5568 - recall: 0.0907 - val_loss: 1.4317 - val_accuracy: 0.2783 - val_f1: 0.0962 - val_precision: 0.3040 - val_recall: 0.0575\n",
            "Epoch 50/60\n",
            "46/46 [==============================] - 6s 129ms/step - loss: 1.2862 - accuracy: 0.4215 - f1: 0.1928 - precision: 0.5390 - recall: 0.1200 - val_loss: 1.4098 - val_accuracy: 0.2933 - val_f1: 0.0911 - val_precision: 0.4198 - val_recall: 0.0517\n",
            "Epoch 51/60\n",
            "46/46 [==============================] - 6s 136ms/step - loss: 1.2934 - accuracy: 0.4324 - f1: 0.1726 - precision: 0.5306 - recall: 0.1063 - val_loss: 1.4045 - val_accuracy: 0.3067 - val_f1: 0.0642 - val_precision: 0.4016 - val_recall: 0.0350\n",
            "Epoch 52/60\n",
            "46/46 [==============================] - 6s 129ms/step - loss: 1.2848 - accuracy: 0.4363 - f1: 0.1915 - precision: 0.5729 - recall: 0.1171 - val_loss: 1.3955 - val_accuracy: 0.3175 - val_f1: 0.0881 - val_precision: 0.3920 - val_recall: 0.0500\n",
            "Epoch 53/60\n",
            "46/46 [==============================] - 6s 135ms/step - loss: 1.2878 - accuracy: 0.4284 - f1: 0.1809 - precision: 0.5406 - recall: 0.1099 - val_loss: 1.3864 - val_accuracy: 0.3117 - val_f1: 0.0570 - val_precision: 0.4140 - val_recall: 0.0308\n",
            "Epoch 54/60\n",
            "46/46 [==============================] - 6s 127ms/step - loss: 1.2980 - accuracy: 0.4133 - f1: 0.1158 - precision: 0.5415 - recall: 0.0656 - val_loss: 1.3730 - val_accuracy: 0.3367 - val_f1: 0.1665 - val_precision: 0.4689 - val_recall: 0.1017\n",
            "Epoch 55/60\n",
            "46/46 [==============================] - 6s 131ms/step - loss: 1.2940 - accuracy: 0.4187 - f1: 0.1686 - precision: 0.5281 - recall: 0.1011 - val_loss: 1.3839 - val_accuracy: 0.3250 - val_f1: 0.1201 - val_precision: 0.3786 - val_recall: 0.0717\n",
            "Epoch 56/60\n",
            "46/46 [==============================] - 6s 130ms/step - loss: 1.3003 - accuracy: 0.4108 - f1: 0.1338 - precision: 0.5289 - recall: 0.0784 - val_loss: 1.4103 - val_accuracy: 0.2933 - val_f1: 0.0238 - val_precision: 0.2849 - val_recall: 0.0125\n",
            "Epoch 57/60\n",
            "46/46 [==============================] - 6s 132ms/step - loss: 1.3168 - accuracy: 0.3998 - f1: 0.0935 - precision: 0.5238 - recall: 0.0527 - val_loss: 1.3748 - val_accuracy: 0.3158 - val_f1: 0.0669 - val_precision: 0.5497 - val_recall: 0.0358\n",
            "Epoch 58/60\n",
            "46/46 [==============================] - 6s 130ms/step - loss: 1.2998 - accuracy: 0.4171 - f1: 0.1423 - precision: 0.5368 - recall: 0.0829 - val_loss: 1.3598 - val_accuracy: 0.3517 - val_f1: 0.0610 - val_precision: 0.5133 - val_recall: 0.0325\n",
            "Epoch 59/60\n",
            "46/46 [==============================] - 6s 131ms/step - loss: 1.2749 - accuracy: 0.4383 - f1: 0.1527 - precision: 0.5943 - recall: 0.0898 - val_loss: 1.3838 - val_accuracy: 0.3192 - val_f1: 0.0607 - val_precision: 0.3929 - val_recall: 0.0333\n",
            "Epoch 60/60\n",
            "46/46 [==============================] - 6s 133ms/step - loss: 1.3093 - accuracy: 0.4029 - f1: 0.1147 - precision: 0.5968 - recall: 0.0637 - val_loss: 1.3843 - val_accuracy: 0.3158 - val_f1: 0.0789 - val_precision: 0.3984 - val_recall: 0.0442\n",
            "14/14 [==============================] - 1s 79ms/step - loss: 1.3832 - accuracy: 0.3343 - f1: 0.1016 - precision: 0.4318 - recall: 0.0579\n",
            "[1.3831638097763062, 0.334285706281662, 0.10161393880844116, 0.4318166673183441, 0.05785713717341423]\n",
            "SG_RNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YumD1M9Y1Xxr",
        "outputId": "3bdf7a88-7e8f-41dc-d64d-7ebfc91a78d6"
      },
      "source": [
        "model_cbow = tf.keras.Sequential()\r\n",
        "model_cbow.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_cbow.add(tf.keras.layers.LSTM(64))\r\n",
        "model_cbow.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_cbow.add(tf.keras.layers.Dense(64,activation='relu'))\r\n",
        "model_cbow.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_cbow.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_cbow.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy',f1,precision,recall])\r\n",
        "cbow_train_gen=vec_gen(w2v_cbow,vocab_cbow,X_train,y_train,batch_size,Max_input_size,Embedding_size)\r\n",
        "cbow_val_gen=vec_gen(w2v_cbow,vocab_cbow,X_val,y_val,batch_size,Max_input_size,Embedding_size)\r\n",
        "history_cbow_lstm = model_cbow.fit_generator(cbow_train_gen,validation_data=cbow_val_gen,validation_steps=int((len(X_val)/batch_size)+1),steps_per_epoch=int((len(X_train)/batch_size)+1),epochs=epochs)\r\n",
        "history = model_cbow.evaluate(x = vec_gen(w2v_cbow,vocab_cbow,X_test,y_test,batch_size,Max_input_size,Embedding_size),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table[3]=history[1]\r\n",
        "print(\"CBOW_LSTM\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "46/46 [==============================] - 7s 108ms/step - loss: 1.3819 - accuracy: 0.2951 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3728 - val_accuracy: 0.3300 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/60\n",
            "46/46 [==============================] - 4s 95ms/step - loss: 1.3782 - accuracy: 0.3054 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3703 - val_accuracy: 0.3367 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 1.3770 - accuracy: 0.3106 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3707 - val_accuracy: 0.3333 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 1.3761 - accuracy: 0.3164 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3694 - val_accuracy: 0.3350 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 5/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.3759 - accuracy: 0.3129 - f1: 1.2288e-04 - precision: 0.0062 - recall: 6.2052e-05 - val_loss: 1.3684 - val_accuracy: 0.3458 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 6/60\n",
            "46/46 [==============================] - 5s 98ms/step - loss: 1.3703 - accuracy: 0.3193 - f1: 0.0085 - precision: 0.0611 - recall: 0.0047 - val_loss: 1.3379 - val_accuracy: 0.3733 - val_f1: 0.0819 - val_precision: 0.4808 - val_recall: 0.0450\n",
            "Epoch 7/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.3360 - accuracy: 0.3649 - f1: 0.0715 - precision: 0.3427 - recall: 0.0437 - val_loss: 1.3426 - val_accuracy: 0.3525 - val_f1: 0.1861 - val_precision: 0.4782 - val_recall: 0.1158\n",
            "Epoch 8/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.3079 - accuracy: 0.3961 - f1: 0.1240 - precision: 0.4792 - recall: 0.0761 - val_loss: 1.3401 - val_accuracy: 0.3600 - val_f1: 0.0098 - val_precision: 0.3472 - val_recall: 0.0050\n",
            "Epoch 9/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.2904 - accuracy: 0.4098 - f1: 0.1605 - precision: 0.5654 - recall: 0.0999 - val_loss: 1.3300 - val_accuracy: 0.3617 - val_f1: 0.1130 - val_precision: 0.5440 - val_recall: 0.0633\n",
            "Epoch 10/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 1.2752 - accuracy: 0.4260 - f1: 0.1767 - precision: 0.5702 - recall: 0.1099 - val_loss: 1.3252 - val_accuracy: 0.3700 - val_f1: 0.0971 - val_precision: 0.5178 - val_recall: 0.0542\n",
            "Epoch 11/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.2652 - accuracy: 0.4254 - f1: 0.1756 - precision: 0.6138 - recall: 0.1103 - val_loss: 1.3166 - val_accuracy: 0.3833 - val_f1: 0.2174 - val_precision: 0.4921 - val_recall: 0.1408\n",
            "Epoch 12/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.2581 - accuracy: 0.4307 - f1: 0.2129 - precision: 0.5682 - recall: 0.1346 - val_loss: 1.2977 - val_accuracy: 0.4050 - val_f1: 0.2344 - val_precision: 0.5163 - val_recall: 0.1525\n",
            "Epoch 13/60\n",
            "46/46 [==============================] - 4s 95ms/step - loss: 1.2516 - accuracy: 0.4396 - f1: 0.2317 - precision: 0.6167 - recall: 0.1486 - val_loss: 1.2837 - val_accuracy: 0.4133 - val_f1: 0.2891 - val_precision: 0.5509 - val_recall: 0.1967\n",
            "Epoch 14/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 1.2444 - accuracy: 0.4469 - f1: 0.2445 - precision: 0.6181 - recall: 0.1581 - val_loss: 1.2919 - val_accuracy: 0.4133 - val_f1: 0.3414 - val_precision: 0.5194 - val_recall: 0.2550\n",
            "Epoch 15/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.2375 - accuracy: 0.4508 - f1: 0.2724 - precision: 0.6272 - recall: 0.1829 - val_loss: 1.2821 - val_accuracy: 0.4158 - val_f1: 0.2932 - val_precision: 0.5731 - val_recall: 0.1975\n",
            "Epoch 16/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 1.2174 - accuracy: 0.4618 - f1: 0.2870 - precision: 0.6630 - recall: 0.1910 - val_loss: 1.2743 - val_accuracy: 0.4175 - val_f1: 0.3221 - val_precision: 0.5709 - val_recall: 0.2250\n",
            "Epoch 17/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.2048 - accuracy: 0.4538 - f1: 0.2978 - precision: 0.6763 - recall: 0.2005 - val_loss: 1.2711 - val_accuracy: 0.4142 - val_f1: 0.3270 - val_precision: 0.5639 - val_recall: 0.2317\n",
            "Epoch 18/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.2086 - accuracy: 0.4561 - f1: 0.3108 - precision: 0.6577 - recall: 0.2130 - val_loss: 1.2938 - val_accuracy: 0.4142 - val_f1: 0.3332 - val_precision: 0.5567 - val_recall: 0.2392\n",
            "Epoch 19/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 1.1714 - accuracy: 0.4867 - f1: 0.3487 - precision: 0.7123 - recall: 0.2401 - val_loss: 1.2554 - val_accuracy: 0.4208 - val_f1: 0.3185 - val_precision: 0.6274 - val_recall: 0.2150\n",
            "Epoch 20/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 1.1408 - accuracy: 0.5050 - f1: 0.3872 - precision: 0.7361 - recall: 0.2674 - val_loss: 1.2493 - val_accuracy: 0.4150 - val_f1: 0.3171 - val_precision: 0.6450 - val_recall: 0.2117\n",
            "Epoch 21/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 1.1229 - accuracy: 0.5078 - f1: 0.4044 - precision: 0.7669 - recall: 0.2819 - val_loss: 1.2332 - val_accuracy: 0.4392 - val_f1: 0.3478 - val_precision: 0.6363 - val_recall: 0.2408\n",
            "Epoch 22/60\n",
            "46/46 [==============================] - 5s 102ms/step - loss: 1.0858 - accuracy: 0.5359 - f1: 0.4352 - precision: 0.7699 - recall: 0.3087 - val_loss: 1.2488 - val_accuracy: 0.4292 - val_f1: 0.2919 - val_precision: 0.6449 - val_recall: 0.1900\n",
            "Epoch 23/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 1.0793 - accuracy: 0.5259 - f1: 0.4322 - precision: 0.7706 - recall: 0.3057 - val_loss: 1.2042 - val_accuracy: 0.4492 - val_f1: 0.3295 - val_precision: 0.6941 - val_recall: 0.2175\n",
            "Epoch 24/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.0437 - accuracy: 0.5489 - f1: 0.4560 - precision: 0.7836 - recall: 0.3288 - val_loss: 1.2171 - val_accuracy: 0.4375 - val_f1: 0.3013 - val_precision: 0.7212 - val_recall: 0.1917\n",
            "Epoch 25/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.0831 - accuracy: 0.5348 - f1: 0.4287 - precision: 0.7645 - recall: 0.3117 - val_loss: 1.1873 - val_accuracy: 0.4808 - val_f1: 0.3379 - val_precision: 0.6932 - val_recall: 0.2250\n",
            "Epoch 26/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.0143 - accuracy: 0.5679 - f1: 0.4786 - precision: 0.8131 - recall: 0.3474 - val_loss: 1.2156 - val_accuracy: 0.4775 - val_f1: 0.4003 - val_precision: 0.6074 - val_recall: 0.3000\n",
            "Epoch 27/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.0099 - accuracy: 0.5681 - f1: 0.4866 - precision: 0.7850 - recall: 0.3577 - val_loss: 1.2521 - val_accuracy: 0.4750 - val_f1: 0.4346 - val_precision: 0.5769 - val_recall: 0.3492\n",
            "Epoch 28/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.9667 - accuracy: 0.5755 - f1: 0.5073 - precision: 0.8049 - recall: 0.3767 - val_loss: 1.2364 - val_accuracy: 0.4850 - val_f1: 0.4436 - val_precision: 0.5928 - val_recall: 0.3550\n",
            "Epoch 29/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.9146 - accuracy: 0.6081 - f1: 0.5340 - precision: 0.8250 - recall: 0.3991 - val_loss: 1.2548 - val_accuracy: 0.4917 - val_f1: 0.4396 - val_precision: 0.5890 - val_recall: 0.3517\n",
            "Epoch 30/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.8859 - accuracy: 0.6107 - f1: 0.5459 - precision: 0.8302 - recall: 0.4092 - val_loss: 1.2533 - val_accuracy: 0.4992 - val_f1: 0.4456 - val_precision: 0.6019 - val_recall: 0.3550\n",
            "Epoch 31/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.8657 - accuracy: 0.6219 - f1: 0.5509 - precision: 0.8418 - recall: 0.4117 - val_loss: 1.2358 - val_accuracy: 0.5158 - val_f1: 0.4522 - val_precision: 0.6304 - val_recall: 0.3542\n",
            "Epoch 32/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.8332 - accuracy: 0.6423 - f1: 0.5618 - precision: 0.8299 - recall: 0.4266 - val_loss: 1.2178 - val_accuracy: 0.5275 - val_f1: 0.4595 - val_precision: 0.6375 - val_recall: 0.3600\n",
            "Epoch 33/60\n",
            "46/46 [==============================] - 4s 99ms/step - loss: 0.8291 - accuracy: 0.6348 - f1: 0.5712 - precision: 0.7978 - recall: 0.4465 - val_loss: 1.2052 - val_accuracy: 0.5208 - val_f1: 0.4459 - val_precision: 0.6558 - val_recall: 0.3383\n",
            "Epoch 34/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.8334 - accuracy: 0.6370 - f1: 0.5676 - precision: 0.8454 - recall: 0.4295 - val_loss: 1.2377 - val_accuracy: 0.5008 - val_f1: 0.4689 - val_precision: 0.6215 - val_recall: 0.3775\n",
            "Epoch 35/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.8009 - accuracy: 0.6621 - f1: 0.5992 - precision: 0.8020 - recall: 0.4809 - val_loss: 1.2545 - val_accuracy: 0.5225 - val_f1: 0.4533 - val_precision: 0.6537 - val_recall: 0.3475\n",
            "Epoch 36/60\n",
            "46/46 [==============================] - 4s 99ms/step - loss: 0.7776 - accuracy: 0.6637 - f1: 0.5944 - precision: 0.8188 - recall: 0.4709 - val_loss: 1.2451 - val_accuracy: 0.5092 - val_f1: 0.4473 - val_precision: 0.6766 - val_recall: 0.3350\n",
            "Epoch 37/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.8063 - accuracy: 0.6530 - f1: 0.5959 - precision: 0.7988 - recall: 0.4784 - val_loss: 1.3325 - val_accuracy: 0.4983 - val_f1: 0.4612 - val_precision: 0.6282 - val_recall: 0.3650\n",
            "Epoch 38/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.8108 - accuracy: 0.6587 - f1: 0.5850 - precision: 0.8307 - recall: 0.4589 - val_loss: 1.3315 - val_accuracy: 0.4900 - val_f1: 0.4639 - val_precision: 0.5888 - val_recall: 0.3833\n",
            "Epoch 39/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.8135 - accuracy: 0.6670 - f1: 0.5768 - precision: 0.8537 - recall: 0.4434 - val_loss: 1.2578 - val_accuracy: 0.5533 - val_f1: 0.5011 - val_precision: 0.6525 - val_recall: 0.4075\n",
            "Epoch 40/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.7433 - accuracy: 0.6859 - f1: 0.6333 - precision: 0.8329 - recall: 0.5135 - val_loss: 1.2699 - val_accuracy: 0.5358 - val_f1: 0.4746 - val_precision: 0.6354 - val_recall: 0.3792\n",
            "Epoch 41/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.7636 - accuracy: 0.6685 - f1: 0.6105 - precision: 0.8111 - recall: 0.4918 - val_loss: 1.3266 - val_accuracy: 0.5042 - val_f1: 0.4452 - val_precision: 0.6122 - val_recall: 0.3508\n",
            "Epoch 42/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.7128 - accuracy: 0.6931 - f1: 0.6477 - precision: 0.8101 - recall: 0.5420 - val_loss: 1.2595 - val_accuracy: 0.5050 - val_f1: 0.4197 - val_precision: 0.6291 - val_recall: 0.3158\n",
            "Epoch 43/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.7038 - accuracy: 0.6998 - f1: 0.6516 - precision: 0.8055 - recall: 0.5535 - val_loss: 1.2292 - val_accuracy: 0.5042 - val_f1: 0.4423 - val_precision: 0.6281 - val_recall: 0.3425\n",
            "Epoch 44/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.6713 - accuracy: 0.7118 - f1: 0.6664 - precision: 0.8160 - recall: 0.5663 - val_loss: 1.2238 - val_accuracy: 0.5025 - val_f1: 0.4572 - val_precision: 0.6124 - val_recall: 0.3658\n",
            "Epoch 45/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.7366 - accuracy: 0.6812 - f1: 0.6536 - precision: 0.7771 - recall: 0.5672 - val_loss: 1.1788 - val_accuracy: 0.5483 - val_f1: 0.5120 - val_precision: 0.6809 - val_recall: 0.4117\n",
            "Epoch 46/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.7117 - accuracy: 0.6901 - f1: 0.6523 - precision: 0.7904 - recall: 0.5581 - val_loss: 1.2104 - val_accuracy: 0.5417 - val_f1: 0.4888 - val_precision: 0.7216 - val_recall: 0.3700\n",
            "Epoch 47/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.7573 - accuracy: 0.6748 - f1: 0.6271 - precision: 0.7977 - recall: 0.5203 - val_loss: 1.2554 - val_accuracy: 0.5342 - val_f1: 0.4744 - val_precision: 0.6759 - val_recall: 0.3667\n",
            "Epoch 48/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.7824 - accuracy: 0.6673 - f1: 0.6326 - precision: 0.7822 - recall: 0.5325 - val_loss: 1.1945 - val_accuracy: 0.5492 - val_f1: 0.4991 - val_precision: 0.7155 - val_recall: 0.3842\n",
            "Epoch 49/60\n",
            "46/46 [==============================] - 5s 102ms/step - loss: 0.6811 - accuracy: 0.7061 - f1: 0.6804 - precision: 0.8076 - recall: 0.5897 - val_loss: 1.2529 - val_accuracy: 0.5283 - val_f1: 0.5160 - val_precision: 0.6030 - val_recall: 0.4517\n",
            "Epoch 50/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.6369 - accuracy: 0.7167 - f1: 0.6923 - precision: 0.7844 - recall: 0.6214 - val_loss: 1.2007 - val_accuracy: 0.5483 - val_f1: 0.5428 - val_precision: 0.6114 - val_recall: 0.4892\n",
            "Epoch 51/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.5816 - accuracy: 0.7347 - f1: 0.7180 - precision: 0.7915 - recall: 0.6586 - val_loss: 1.2860 - val_accuracy: 0.5267 - val_f1: 0.5269 - val_precision: 0.5712 - val_recall: 0.4892\n",
            "Epoch 52/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.5412 - accuracy: 0.7553 - f1: 0.7427 - precision: 0.8118 - recall: 0.6867 - val_loss: 1.3005 - val_accuracy: 0.5542 - val_f1: 0.5501 - val_precision: 0.5908 - val_recall: 0.5150\n",
            "Epoch 53/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.5064 - accuracy: 0.7744 - f1: 0.7665 - precision: 0.8239 - recall: 0.7175 - val_loss: 1.3429 - val_accuracy: 0.5667 - val_f1: 0.5636 - val_precision: 0.6023 - val_recall: 0.5300\n",
            "Epoch 54/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.5192 - accuracy: 0.7765 - f1: 0.7690 - precision: 0.8172 - recall: 0.7270 - val_loss: 1.4049 - val_accuracy: 0.5708 - val_f1: 0.5577 - val_precision: 0.6027 - val_recall: 0.5192\n",
            "Epoch 55/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.5115 - accuracy: 0.7981 - f1: 0.7829 - precision: 0.8344 - recall: 0.7380 - val_loss: 1.4094 - val_accuracy: 0.5900 - val_f1: 0.5761 - val_precision: 0.6256 - val_recall: 0.5342\n",
            "Epoch 56/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.4782 - accuracy: 0.8194 - f1: 0.8129 - precision: 0.8562 - recall: 0.7747 - val_loss: 1.4699 - val_accuracy: 0.5892 - val_f1: 0.5731 - val_precision: 0.6207 - val_recall: 0.5325\n",
            "Epoch 57/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.5010 - accuracy: 0.7969 - f1: 0.7858 - precision: 0.8338 - recall: 0.7446 - val_loss: 1.4225 - val_accuracy: 0.5892 - val_f1: 0.5698 - val_precision: 0.6223 - val_recall: 0.5258\n",
            "Epoch 58/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.5140 - accuracy: 0.7996 - f1: 0.7874 - precision: 0.8304 - recall: 0.7496 - val_loss: 1.4187 - val_accuracy: 0.5875 - val_f1: 0.5831 - val_precision: 0.6306 - val_recall: 0.5425\n",
            "Epoch 59/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.5417 - accuracy: 0.7837 - f1: 0.7662 - precision: 0.8226 - recall: 0.7193 - val_loss: 1.4272 - val_accuracy: 0.5933 - val_f1: 0.5896 - val_precision: 0.6282 - val_recall: 0.5558\n",
            "Epoch 60/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.4701 - accuracy: 0.8244 - f1: 0.8103 - precision: 0.8547 - recall: 0.7727 - val_loss: 1.6212 - val_accuracy: 0.6050 - val_f1: 0.6070 - val_precision: 0.6270 - val_recall: 0.5883\n",
            "14/14 [==============================] - 1s 76ms/step - loss: 1.6004 - accuracy: 0.5793 - f1: 0.5818 - precision: 0.5984 - recall: 0.5664\n",
            "[1.6004332304000854, 0.579285740852356, 0.5818132162094116, 0.5984386205673218, 0.5664286017417908]\n",
            "CBOW_LSTM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01yVMiF41ZtT",
        "outputId": "99d833f2-d725-44da-e2d2-c89a28c23987"
      },
      "source": [
        "model_cbow_bi = tf.keras.Sequential()\r\n",
        "model_cbow_bi.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_cbow_bi.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64),merge_mode='concat'))\r\n",
        "model_cbow_bi.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_cbow_bi.add(tf.keras.layers.Dense(64,activation='relu'))\r\n",
        "model_cbow_bi.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_cbow_bi.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_cbow_bi.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy',f1,precision,recall])\r\n",
        "history_cbow_bi = model_cbow_bi.fit_generator(cbow_train_gen,validation_data=cbow_val_gen,validation_steps=int((len(X_val)/batch_size)+1),steps_per_epoch=int((len(X_train)/batch_size)+1),epochs=epochs)\r\n",
        "history = model_cbow_bi.evaluate(x = vec_gen(w2v_cbow,vocab_cbow,X_test,y_test,batch_size,Max_input_size,Embedding_size),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table[4]=history[1]\r\n",
        "print(\"CBOW_BI\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "46/46 [==============================] - 8s 115ms/step - loss: 1.3799 - accuracy: 0.3078 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3657 - val_accuracy: 0.3292 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 1.3614 - accuracy: 0.3187 - f1: 9.4342e-05 - precision: 0.0048 - recall: 4.7643e-05 - val_loss: 1.3432 - val_accuracy: 0.3783 - val_f1: 0.0033 - val_precision: 0.0833 - val_recall: 0.0017\n",
            "Epoch 3/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.3216 - accuracy: 0.3957 - f1: 0.0220 - precision: 0.2833 - recall: 0.0117 - val_loss: 1.2924 - val_accuracy: 0.4200 - val_f1: 0.1672 - val_precision: 0.5116 - val_recall: 0.1008\n",
            "Epoch 4/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 1.2506 - accuracy: 0.4554 - f1: 0.1782 - precision: 0.6471 - recall: 0.1059 - val_loss: 1.2445 - val_accuracy: 0.4367 - val_f1: 0.2370 - val_precision: 0.5694 - val_recall: 0.1500\n",
            "Epoch 5/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 1.1719 - accuracy: 0.4989 - f1: 0.3023 - precision: 0.6601 - recall: 0.1983 - val_loss: 1.2234 - val_accuracy: 0.4617 - val_f1: 0.3203 - val_precision: 0.5587 - val_recall: 0.2250\n",
            "Epoch 6/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 1.0965 - accuracy: 0.5388 - f1: 0.4113 - precision: 0.6884 - recall: 0.2959 - val_loss: 1.2196 - val_accuracy: 0.4608 - val_f1: 0.3628 - val_precision: 0.5545 - val_recall: 0.2700\n",
            "Epoch 7/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 1.0477 - accuracy: 0.5732 - f1: 0.4638 - precision: 0.6981 - recall: 0.3487 - val_loss: 1.2074 - val_accuracy: 0.4767 - val_f1: 0.4017 - val_precision: 0.5712 - val_recall: 0.3100\n",
            "Epoch 8/60\n",
            "46/46 [==============================] - 5s 102ms/step - loss: 1.0121 - accuracy: 0.5934 - f1: 0.5134 - precision: 0.7222 - recall: 0.4002 - val_loss: 1.2064 - val_accuracy: 0.4717 - val_f1: 0.4086 - val_precision: 0.5752 - val_recall: 0.3175\n",
            "Epoch 9/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.9765 - accuracy: 0.6126 - f1: 0.5351 - precision: 0.7385 - recall: 0.4215 - val_loss: 1.2141 - val_accuracy: 0.4700 - val_f1: 0.4270 - val_precision: 0.5726 - val_recall: 0.3408\n",
            "Epoch 10/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.9285 - accuracy: 0.6346 - f1: 0.5663 - precision: 0.7489 - recall: 0.4567 - val_loss: 1.2400 - val_accuracy: 0.4867 - val_f1: 0.4276 - val_precision: 0.5334 - val_recall: 0.3575\n",
            "Epoch 11/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.9045 - accuracy: 0.6405 - f1: 0.5918 - precision: 0.7505 - recall: 0.4895 - val_loss: 1.2360 - val_accuracy: 0.4975 - val_f1: 0.4481 - val_precision: 0.5509 - val_recall: 0.3783\n",
            "Epoch 12/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.8749 - accuracy: 0.6594 - f1: 0.6085 - precision: 0.7661 - recall: 0.5056 - val_loss: 1.2570 - val_accuracy: 0.4800 - val_f1: 0.4448 - val_precision: 0.5408 - val_recall: 0.3783\n",
            "Epoch 13/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.8331 - accuracy: 0.6736 - f1: 0.6357 - precision: 0.7668 - recall: 0.5437 - val_loss: 1.2737 - val_accuracy: 0.4758 - val_f1: 0.4432 - val_precision: 0.5341 - val_recall: 0.3792\n",
            "Epoch 14/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.8064 - accuracy: 0.6917 - f1: 0.6611 - precision: 0.7907 - recall: 0.5686 - val_loss: 1.2887 - val_accuracy: 0.4817 - val_f1: 0.4528 - val_precision: 0.5315 - val_recall: 0.3950\n",
            "Epoch 15/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.7710 - accuracy: 0.7048 - f1: 0.6793 - precision: 0.7954 - recall: 0.5939 - val_loss: 1.3214 - val_accuracy: 0.4908 - val_f1: 0.4740 - val_precision: 0.5451 - val_recall: 0.4200\n",
            "Epoch 16/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.7324 - accuracy: 0.7250 - f1: 0.7012 - precision: 0.8078 - recall: 0.6209 - val_loss: 1.3809 - val_accuracy: 0.4892 - val_f1: 0.4565 - val_precision: 0.5269 - val_recall: 0.4033\n",
            "Epoch 17/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.7060 - accuracy: 0.7378 - f1: 0.7189 - precision: 0.8179 - recall: 0.6423 - val_loss: 1.4077 - val_accuracy: 0.4975 - val_f1: 0.4710 - val_precision: 0.5379 - val_recall: 0.4192\n",
            "Epoch 18/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.6587 - accuracy: 0.7568 - f1: 0.7421 - precision: 0.8338 - recall: 0.6698 - val_loss: 1.4928 - val_accuracy: 0.5050 - val_f1: 0.4946 - val_precision: 0.5422 - val_recall: 0.4550\n",
            "Epoch 19/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.6298 - accuracy: 0.7712 - f1: 0.7633 - precision: 0.8335 - recall: 0.7047 - val_loss: 1.5188 - val_accuracy: 0.5217 - val_f1: 0.4927 - val_precision: 0.5423 - val_recall: 0.4517\n",
            "Epoch 20/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.5880 - accuracy: 0.7834 - f1: 0.7742 - precision: 0.8430 - recall: 0.7161 - val_loss: 1.5319 - val_accuracy: 0.5117 - val_f1: 0.4856 - val_precision: 0.5313 - val_recall: 0.4475\n",
            "Epoch 21/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.5921 - accuracy: 0.7803 - f1: 0.7711 - precision: 0.8343 - recall: 0.7177 - val_loss: 1.6662 - val_accuracy: 0.5133 - val_f1: 0.5028 - val_precision: 0.5443 - val_recall: 0.4675\n",
            "Epoch 22/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.5218 - accuracy: 0.8087 - f1: 0.8031 - precision: 0.8570 - recall: 0.7560 - val_loss: 1.6515 - val_accuracy: 0.5317 - val_f1: 0.5157 - val_precision: 0.5562 - val_recall: 0.4808\n",
            "Epoch 23/60\n",
            "46/46 [==============================] - 5s 102ms/step - loss: 0.5272 - accuracy: 0.8093 - f1: 0.8026 - precision: 0.8581 - recall: 0.7545 - val_loss: 1.5045 - val_accuracy: 0.5283 - val_f1: 0.5208 - val_precision: 0.5608 - val_recall: 0.4867\n",
            "Epoch 24/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.4908 - accuracy: 0.8300 - f1: 0.8249 - precision: 0.8714 - recall: 0.7836 - val_loss: 1.6046 - val_accuracy: 0.5283 - val_f1: 0.5120 - val_precision: 0.5533 - val_recall: 0.4767\n",
            "Epoch 25/60\n",
            "46/46 [==============================] - 5s 102ms/step - loss: 0.4303 - accuracy: 0.8445 - f1: 0.8416 - precision: 0.8812 - recall: 0.8059 - val_loss: 1.6476 - val_accuracy: 0.5367 - val_f1: 0.5301 - val_precision: 0.5621 - val_recall: 0.5017\n",
            "Epoch 26/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.4059 - accuracy: 0.8610 - f1: 0.8544 - precision: 0.8913 - recall: 0.8209 - val_loss: 1.5337 - val_accuracy: 0.5425 - val_f1: 0.5262 - val_precision: 0.5585 - val_recall: 0.4975\n",
            "Epoch 27/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.4034 - accuracy: 0.8494 - f1: 0.8493 - precision: 0.8840 - recall: 0.8173 - val_loss: 1.6316 - val_accuracy: 0.5592 - val_f1: 0.5505 - val_precision: 0.5883 - val_recall: 0.5175\n",
            "Epoch 28/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.3452 - accuracy: 0.8777 - f1: 0.8708 - precision: 0.9017 - recall: 0.8422 - val_loss: 1.7346 - val_accuracy: 0.5408 - val_f1: 0.5341 - val_precision: 0.5618 - val_recall: 0.5092\n",
            "Epoch 29/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.3333 - accuracy: 0.8818 - f1: 0.8816 - precision: 0.9107 - recall: 0.8546 - val_loss: 1.6504 - val_accuracy: 0.5667 - val_f1: 0.5574 - val_precision: 0.5849 - val_recall: 0.5325\n",
            "Epoch 30/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.3529 - accuracy: 0.8703 - f1: 0.8687 - precision: 0.8941 - recall: 0.8449 - val_loss: 1.7747 - val_accuracy: 0.5742 - val_f1: 0.5678 - val_precision: 0.5919 - val_recall: 0.5458\n",
            "Epoch 31/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.3498 - accuracy: 0.8788 - f1: 0.8784 - precision: 0.9035 - recall: 0.8549 - val_loss: 1.6243 - val_accuracy: 0.5550 - val_f1: 0.5531 - val_precision: 0.5879 - val_recall: 0.5225\n",
            "Epoch 32/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.3450 - accuracy: 0.8744 - f1: 0.8750 - precision: 0.9044 - recall: 0.8477 - val_loss: 1.7392 - val_accuracy: 0.5575 - val_f1: 0.5560 - val_precision: 0.5810 - val_recall: 0.5333\n",
            "Epoch 33/60\n",
            "46/46 [==============================] - 5s 102ms/step - loss: 0.2913 - accuracy: 0.8995 - f1: 0.8995 - precision: 0.9198 - recall: 0.8802 - val_loss: 1.8024 - val_accuracy: 0.5708 - val_f1: 0.5656 - val_precision: 0.5879 - val_recall: 0.5450\n",
            "Epoch 34/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.2782 - accuracy: 0.9048 - f1: 0.9047 - precision: 0.9191 - recall: 0.8909 - val_loss: 1.8778 - val_accuracy: 0.5667 - val_f1: 0.5645 - val_precision: 0.5848 - val_recall: 0.5458\n",
            "Epoch 35/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.2764 - accuracy: 0.9059 - f1: 0.9063 - precision: 0.9230 - recall: 0.8903 - val_loss: 1.7745 - val_accuracy: 0.5758 - val_f1: 0.5720 - val_precision: 0.5912 - val_recall: 0.5542\n",
            "Epoch 36/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.2516 - accuracy: 0.9106 - f1: 0.9100 - precision: 0.9275 - recall: 0.8933 - val_loss: 1.9148 - val_accuracy: 0.5683 - val_f1: 0.5665 - val_precision: 0.5842 - val_recall: 0.5500\n",
            "Epoch 37/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.2406 - accuracy: 0.9183 - f1: 0.9188 - precision: 0.9323 - recall: 0.9057 - val_loss: 1.7662 - val_accuracy: 0.5550 - val_f1: 0.5582 - val_precision: 0.5780 - val_recall: 0.5400\n",
            "Epoch 38/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.3252 - accuracy: 0.8821 - f1: 0.8790 - precision: 0.8962 - recall: 0.8627 - val_loss: 1.9148 - val_accuracy: 0.5525 - val_f1: 0.5551 - val_precision: 0.5702 - val_recall: 0.5408\n",
            "Epoch 39/60\n",
            "46/46 [==============================] - 5s 104ms/step - loss: 0.2569 - accuracy: 0.9089 - f1: 0.9067 - precision: 0.9247 - recall: 0.8894 - val_loss: 2.1442 - val_accuracy: 0.5692 - val_f1: 0.5727 - val_precision: 0.5871 - val_recall: 0.5592\n",
            "Epoch 40/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.2125 - accuracy: 0.9242 - f1: 0.9230 - precision: 0.9353 - recall: 0.9111 - val_loss: 2.1353 - val_accuracy: 0.5800 - val_f1: 0.5797 - val_precision: 0.5944 - val_recall: 0.5658\n",
            "Epoch 41/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.2013 - accuracy: 0.9307 - f1: 0.9278 - precision: 0.9433 - recall: 0.9130 - val_loss: 2.1534 - val_accuracy: 0.5792 - val_f1: 0.5807 - val_precision: 0.5965 - val_recall: 0.5658\n",
            "Epoch 42/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.1935 - accuracy: 0.9329 - f1: 0.9300 - precision: 0.9430 - recall: 0.9173 - val_loss: 2.0180 - val_accuracy: 0.5867 - val_f1: 0.5865 - val_precision: 0.6004 - val_recall: 0.5733\n",
            "Epoch 43/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.1723 - accuracy: 0.9399 - f1: 0.9381 - precision: 0.9490 - recall: 0.9276 - val_loss: 2.2567 - val_accuracy: 0.5892 - val_f1: 0.5882 - val_precision: 0.6012 - val_recall: 0.5758\n",
            "Epoch 44/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.1719 - accuracy: 0.9402 - f1: 0.9385 - precision: 0.9494 - recall: 0.9280 - val_loss: 2.1791 - val_accuracy: 0.5983 - val_f1: 0.5941 - val_precision: 0.6100 - val_recall: 0.5792\n",
            "Epoch 45/60\n",
            "46/46 [==============================] - 4s 99ms/step - loss: 0.1874 - accuracy: 0.9331 - f1: 0.9342 - precision: 0.9444 - recall: 0.9244 - val_loss: 2.2689 - val_accuracy: 0.5908 - val_f1: 0.5898 - val_precision: 0.6027 - val_recall: 0.5775\n",
            "Epoch 46/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.1632 - accuracy: 0.9425 - f1: 0.9422 - precision: 0.9494 - recall: 0.9351 - val_loss: 2.2426 - val_accuracy: 0.5783 - val_f1: 0.5777 - val_precision: 0.5921 - val_recall: 0.5642\n",
            "Epoch 47/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.1891 - accuracy: 0.9428 - f1: 0.9413 - precision: 0.9481 - recall: 0.9346 - val_loss: 2.2638 - val_accuracy: 0.5917 - val_f1: 0.5916 - val_precision: 0.6022 - val_recall: 0.5817\n",
            "Epoch 48/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.1803 - accuracy: 0.9401 - f1: 0.9397 - precision: 0.9475 - recall: 0.9321 - val_loss: 2.2547 - val_accuracy: 0.5992 - val_f1: 0.6019 - val_precision: 0.6126 - val_recall: 0.5917\n",
            "Epoch 49/60\n",
            "46/46 [==============================] - 5s 103ms/step - loss: 0.1622 - accuracy: 0.9429 - f1: 0.9431 - precision: 0.9500 - recall: 0.9363 - val_loss: 2.2742 - val_accuracy: 0.5967 - val_f1: 0.5965 - val_precision: 0.6103 - val_recall: 0.5833\n",
            "Epoch 50/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.1408 - accuracy: 0.9533 - f1: 0.9543 - precision: 0.9606 - recall: 0.9481 - val_loss: 2.3767 - val_accuracy: 0.5925 - val_f1: 0.5900 - val_precision: 0.6005 - val_recall: 0.5800\n",
            "Epoch 51/60\n",
            "46/46 [==============================] - 5s 102ms/step - loss: 0.1165 - accuracy: 0.9596 - f1: 0.9594 - precision: 0.9638 - recall: 0.9551 - val_loss: 2.5665 - val_accuracy: 0.5892 - val_f1: 0.5886 - val_precision: 0.5974 - val_recall: 0.5800\n",
            "Epoch 52/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.1188 - accuracy: 0.9540 - f1: 0.9549 - precision: 0.9600 - recall: 0.9498 - val_loss: 2.3702 - val_accuracy: 0.5992 - val_f1: 0.5983 - val_precision: 0.6078 - val_recall: 0.5892\n",
            "Epoch 53/60\n",
            "46/46 [==============================] - 5s 103ms/step - loss: 0.1121 - accuracy: 0.9624 - f1: 0.9609 - precision: 0.9641 - recall: 0.9578 - val_loss: 2.4627 - val_accuracy: 0.5917 - val_f1: 0.5948 - val_precision: 0.6059 - val_recall: 0.5842\n",
            "Epoch 54/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.1012 - accuracy: 0.9640 - f1: 0.9633 - precision: 0.9665 - recall: 0.9602 - val_loss: 2.4756 - val_accuracy: 0.5883 - val_f1: 0.5881 - val_precision: 0.5965 - val_recall: 0.5800\n",
            "Epoch 55/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.1091 - accuracy: 0.9642 - f1: 0.9645 - precision: 0.9672 - recall: 0.9619 - val_loss: 2.6211 - val_accuracy: 0.5792 - val_f1: 0.5808 - val_precision: 0.5902 - val_recall: 0.5717\n",
            "Epoch 56/60\n",
            "46/46 [==============================] - 4s 99ms/step - loss: 0.1471 - accuracy: 0.9517 - f1: 0.9527 - precision: 0.9572 - recall: 0.9484 - val_loss: 2.4584 - val_accuracy: 0.5717 - val_f1: 0.5724 - val_precision: 0.5792 - val_recall: 0.5658\n",
            "Epoch 57/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.1346 - accuracy: 0.9548 - f1: 0.9550 - precision: 0.9598 - recall: 0.9503 - val_loss: 2.4371 - val_accuracy: 0.5850 - val_f1: 0.5866 - val_precision: 0.5942 - val_recall: 0.5792\n",
            "Epoch 58/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.1200 - accuracy: 0.9545 - f1: 0.9556 - precision: 0.9596 - recall: 0.9517 - val_loss: 2.2484 - val_accuracy: 0.5875 - val_f1: 0.5877 - val_precision: 0.5985 - val_recall: 0.5775\n",
            "Epoch 59/60\n",
            "46/46 [==============================] - 5s 104ms/step - loss: 0.1030 - accuracy: 0.9599 - f1: 0.9600 - precision: 0.9639 - recall: 0.9562 - val_loss: 2.1627 - val_accuracy: 0.5867 - val_f1: 0.5886 - val_precision: 0.5958 - val_recall: 0.5817\n",
            "Epoch 60/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.1215 - accuracy: 0.9559 - f1: 0.9574 - precision: 0.9610 - recall: 0.9538 - val_loss: 2.3578 - val_accuracy: 0.5992 - val_f1: 0.5984 - val_precision: 0.6079 - val_recall: 0.5892\n",
            "14/14 [==============================] - 1s 75ms/step - loss: 2.2095 - accuracy: 0.6043 - f1: 0.6046 - precision: 0.6117 - recall: 0.5979\n",
            "[2.2094671726226807, 0.604285717010498, 0.604649543762207, 0.6116565465927124, 0.5978571772575378]\n",
            "CBOW_BI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_G3Ff5r1bSD",
        "outputId": "649d2d50-1961-49c2-ce26-6e69c1f8ca8e"
      },
      "source": [
        "model_cbow_rnn = tf.keras.Sequential()\r\n",
        "model_cbow_rnn.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_cbow_rnn.add(tf.keras.layers.SimpleRNN(64))\r\n",
        "model_cbow_rnn.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_cbow_rnn.add(tf.keras.layers.Dense(64,activation='relu'))\r\n",
        "model_cbow_rnn.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_cbow_rnn.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_cbow_rnn.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy',f1,precision,recall])\r\n",
        "history_cbow_rnn = model_cbow_rnn.fit_generator(cbow_train_gen,validation_data=cbow_val_gen,validation_steps=int((len(X_val)/batch_size)+1),steps_per_epoch=int((len(X_train)/batch_size)+1),epochs=epochs)\r\n",
        "history = model_cbow_rnn.evaluate(x = vec_gen(w2v_cbow,vocab_cbow,X_test,y_test,batch_size,Max_input_size,Embedding_size),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table[5]=history[1]\r\n",
        "print(\"CBOW_RNN\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "46/46 [==============================] - 7s 137ms/step - loss: 1.3908 - accuracy: 0.2716 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3675 - val_accuracy: 0.3325 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/60\n",
            "46/46 [==============================] - 6s 127ms/step - loss: 1.3834 - accuracy: 0.2952 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3675 - val_accuracy: 0.3308 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/60\n",
            "46/46 [==============================] - 6s 129ms/step - loss: 1.3789 - accuracy: 0.3009 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3680 - val_accuracy: 0.3375 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/60\n",
            "46/46 [==============================] - 6s 131ms/step - loss: 1.3757 - accuracy: 0.2975 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3675 - val_accuracy: 0.3333 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 5/60\n",
            "46/46 [==============================] - 6s 133ms/step - loss: 1.3677 - accuracy: 0.3146 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3755 - val_accuracy: 0.3008 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 6/60\n",
            "46/46 [==============================] - 6s 131ms/step - loss: 1.3710 - accuracy: 0.2952 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3649 - val_accuracy: 0.3400 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 7/60\n",
            "46/46 [==============================] - 6s 131ms/step - loss: 1.3719 - accuracy: 0.3124 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3741 - val_accuracy: 0.3050 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 8/60\n",
            "46/46 [==============================] - 6s 134ms/step - loss: 1.3755 - accuracy: 0.3116 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3687 - val_accuracy: 0.3275 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 9/60\n",
            "46/46 [==============================] - 6s 127ms/step - loss: 1.3669 - accuracy: 0.3020 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3746 - val_accuracy: 0.3192 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 10/60\n",
            "46/46 [==============================] - 6s 129ms/step - loss: 1.3831 - accuracy: 0.2921 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3726 - val_accuracy: 0.3158 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 11/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 1.3720 - accuracy: 0.3134 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.4074 - val_accuracy: 0.2342 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 12/60\n",
            "46/46 [==============================] - 6s 127ms/step - loss: 1.3804 - accuracy: 0.2923 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3699 - val_accuracy: 0.3317 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 13/60\n",
            "46/46 [==============================] - 6s 127ms/step - loss: 1.3643 - accuracy: 0.3195 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3725 - val_accuracy: 0.3058 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 14/60\n",
            "46/46 [==============================] - 6s 126ms/step - loss: 1.3769 - accuracy: 0.2959 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3699 - val_accuracy: 0.3300 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 15/60\n",
            "46/46 [==============================] - 6s 131ms/step - loss: 1.3661 - accuracy: 0.3223 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3634 - val_accuracy: 0.3467 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 16/60\n",
            "46/46 [==============================] - 6s 129ms/step - loss: 1.3618 - accuracy: 0.3242 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3617 - val_accuracy: 0.3567 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 17/60\n",
            "46/46 [==============================] - 6s 134ms/step - loss: 1.3498 - accuracy: 0.3464 - f1: 0.0029 - precision: 0.0539 - recall: 0.0015 - val_loss: 1.3668 - val_accuracy: 0.3408 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 18/60\n",
            "46/46 [==============================] - 6s 135ms/step - loss: 1.3566 - accuracy: 0.3241 - f1: 0.0030 - precision: 0.1531 - recall: 0.0015 - val_loss: 1.3653 - val_accuracy: 0.3333 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 19/60\n",
            "46/46 [==============================] - 6s 136ms/step - loss: 1.3763 - accuracy: 0.3032 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3671 - val_accuracy: 0.3283 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 20/60\n",
            "46/46 [==============================] - 6s 136ms/step - loss: 1.3658 - accuracy: 0.3174 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3607 - val_accuracy: 0.3533 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 21/60\n",
            "46/46 [==============================] - 6s 128ms/step - loss: 1.3696 - accuracy: 0.3081 - f1: 5.7086e-05 - precision: 0.0029 - recall: 2.8828e-05 - val_loss: 1.3741 - val_accuracy: 0.3133 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 22/60\n",
            "46/46 [==============================] - 6s 132ms/step - loss: 1.3827 - accuracy: 0.2974 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3708 - val_accuracy: 0.3358 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 23/60\n",
            "46/46 [==============================] - 6s 132ms/step - loss: 1.3686 - accuracy: 0.3105 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3696 - val_accuracy: 0.3225 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 24/60\n",
            "46/46 [==============================] - 6s 132ms/step - loss: 1.3691 - accuracy: 0.3116 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3693 - val_accuracy: 0.3308 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 25/60\n",
            "46/46 [==============================] - 6s 131ms/step - loss: 1.3692 - accuracy: 0.3087 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3692 - val_accuracy: 0.3367 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 26/60\n",
            "46/46 [==============================] - 6s 129ms/step - loss: 1.3577 - accuracy: 0.3184 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3871 - val_accuracy: 0.2775 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 27/60\n",
            "46/46 [==============================] - 6s 128ms/step - loss: 1.3559 - accuracy: 0.3283 - f1: 2.7681e-05 - precision: 0.0014 - recall: 1.3979e-05 - val_loss: 1.3761 - val_accuracy: 0.3042 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 28/60\n",
            "46/46 [==============================] - 6s 136ms/step - loss: 1.3644 - accuracy: 0.3255 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3614 - val_accuracy: 0.3300 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 29/60\n",
            "46/46 [==============================] - 6s 135ms/step - loss: 1.3451 - accuracy: 0.3614 - f1: 0.0040 - precision: 0.1040 - recall: 0.0021 - val_loss: 1.3816 - val_accuracy: 0.3217 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 30/60\n",
            "46/46 [==============================] - 6s 131ms/step - loss: 1.3467 - accuracy: 0.3546 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.4078 - val_accuracy: 0.2475 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 31/60\n",
            "46/46 [==============================] - 6s 129ms/step - loss: 1.3674 - accuracy: 0.3128 - f1: 2.7196e-04 - precision: 0.0118 - recall: 1.3772e-04 - val_loss: 1.3848 - val_accuracy: 0.3067 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 32/60\n",
            "46/46 [==============================] - 6s 133ms/step - loss: 1.3420 - accuracy: 0.3532 - f1: 0.0087 - precision: 0.2151 - recall: 0.0045 - val_loss: 1.4080 - val_accuracy: 0.2500 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 33/60\n",
            "46/46 [==============================] - 6s 130ms/step - loss: 1.3845 - accuracy: 0.3077 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3887 - val_accuracy: 0.2758 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 34/60\n",
            "46/46 [==============================] - 6s 127ms/step - loss: 1.3792 - accuracy: 0.2933 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3689 - val_accuracy: 0.3200 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 35/60\n",
            "46/46 [==============================] - 6s 134ms/step - loss: 1.3564 - accuracy: 0.3333 - f1: 4.7196e-04 - precision: 0.0238 - recall: 2.3834e-04 - val_loss: 1.3733 - val_accuracy: 0.3217 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 36/60\n",
            "46/46 [==============================] - 6s 130ms/step - loss: 1.3436 - accuracy: 0.3490 - f1: 0.0023 - precision: 0.0972 - recall: 0.0012 - val_loss: 1.3849 - val_accuracy: 0.3175 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 37/60\n",
            "46/46 [==============================] - 6s 130ms/step - loss: 1.3448 - accuracy: 0.3509 - f1: 0.0055 - precision: 0.1398 - recall: 0.0028 - val_loss: 1.4021 - val_accuracy: 0.2550 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 38/60\n",
            "46/46 [==============================] - 6s 128ms/step - loss: 1.3644 - accuracy: 0.3223 - f1: 0.0061 - precision: 0.2266 - recall: 0.0031 - val_loss: 1.3642 - val_accuracy: 0.3350 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 39/60\n",
            "46/46 [==============================] - 6s 134ms/step - loss: 1.3476 - accuracy: 0.3470 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3638 - val_accuracy: 0.3300 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 40/60\n",
            "46/46 [==============================] - 6s 126ms/step - loss: 1.3716 - accuracy: 0.3236 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3688 - val_accuracy: 0.3292 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 41/60\n",
            "46/46 [==============================] - 6s 128ms/step - loss: 1.3524 - accuracy: 0.3457 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3763 - val_accuracy: 0.2992 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 42/60\n",
            "46/46 [==============================] - 6s 127ms/step - loss: 1.3681 - accuracy: 0.3202 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3726 - val_accuracy: 0.3208 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 43/60\n",
            "46/46 [==============================] - 6s 130ms/step - loss: 1.3744 - accuracy: 0.3170 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3654 - val_accuracy: 0.3300 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 44/60\n",
            "46/46 [==============================] - 6s 130ms/step - loss: 1.3519 - accuracy: 0.3435 - f1: 8.3587e-05 - precision: 0.0030 - recall: 4.2577e-05 - val_loss: 1.3978 - val_accuracy: 0.2825 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 45/60\n",
            "46/46 [==============================] - 6s 130ms/step - loss: 1.3522 - accuracy: 0.3528 - f1: 0.0065 - precision: 0.1823 - recall: 0.0033 - val_loss: 1.3909 - val_accuracy: 0.2883 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 46/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 1.3526 - accuracy: 0.3393 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3866 - val_accuracy: 0.2883 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 47/60\n",
            "46/46 [==============================] - 6s 127ms/step - loss: 1.3496 - accuracy: 0.3482 - f1: 9.1919e-04 - precision: 0.0437 - recall: 4.6501e-04 - val_loss: 1.3917 - val_accuracy: 0.2775 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 48/60\n",
            "46/46 [==============================] - 6s 128ms/step - loss: 1.3462 - accuracy: 0.3420 - f1: 0.0092 - precision: 0.2332 - recall: 0.0047 - val_loss: 1.4023 - val_accuracy: 0.2750 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 49/60\n",
            "46/46 [==============================] - 6s 133ms/step - loss: 1.3670 - accuracy: 0.3207 - f1: 0.0085 - precision: 0.2396 - recall: 0.0043 - val_loss: 1.3876 - val_accuracy: 0.2883 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 50/60\n",
            "46/46 [==============================] - 6s 132ms/step - loss: 1.3508 - accuracy: 0.3464 - f1: 1.2559e-04 - precision: 0.0054 - recall: 6.3607e-05 - val_loss: 1.3972 - val_accuracy: 0.2875 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 51/60\n",
            "46/46 [==============================] - 6s 133ms/step - loss: 1.3702 - accuracy: 0.3200 - f1: 0.0056 - precision: 0.1182 - recall: 0.0029 - val_loss: 1.3884 - val_accuracy: 0.2700 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 52/60\n",
            "46/46 [==============================] - 6s 126ms/step - loss: 1.3630 - accuracy: 0.3209 - f1: 8.3776e-04 - precision: 0.0423 - recall: 4.2307e-04 - val_loss: 1.3900 - val_accuracy: 0.2592 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 53/60\n",
            "46/46 [==============================] - 6s 129ms/step - loss: 1.3634 - accuracy: 0.3150 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3770 - val_accuracy: 0.3217 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 54/60\n",
            "46/46 [==============================] - 6s 135ms/step - loss: 1.3742 - accuracy: 0.3293 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3718 - val_accuracy: 0.3225 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 55/60\n",
            "46/46 [==============================] - 6s 126ms/step - loss: 1.3536 - accuracy: 0.3261 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3815 - val_accuracy: 0.3225 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 56/60\n",
            "46/46 [==============================] - 6s 129ms/step - loss: 1.3569 - accuracy: 0.3416 - f1: 0.0028 - precision: 0.1062 - recall: 0.0014 - val_loss: 1.3757 - val_accuracy: 0.3267 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 57/60\n",
            "46/46 [==============================] - 6s 133ms/step - loss: 1.3591 - accuracy: 0.3427 - f1: 2.7193e-04 - precision: 0.0123 - recall: 1.3761e-04 - val_loss: 1.3806 - val_accuracy: 0.3242 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 58/60\n",
            "46/46 [==============================] - 6s 135ms/step - loss: 1.3477 - accuracy: 0.3402 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3748 - val_accuracy: 0.3417 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 59/60\n",
            "46/46 [==============================] - 6s 137ms/step - loss: 1.3459 - accuracy: 0.3443 - f1: 0.0043 - precision: 0.1078 - recall: 0.0022 - val_loss: 1.4150 - val_accuracy: 0.2608 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 60/60\n",
            "46/46 [==============================] - 6s 126ms/step - loss: 1.3695 - accuracy: 0.3181 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3942 - val_accuracy: 0.2992 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "14/14 [==============================] - 1s 78ms/step - loss: 1.4024 - accuracy: 0.2814 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "[1.4023536443710327, 0.28142857551574707, 0.0, 0.0, 0.0]\n",
            "CBOW_RNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czoFmEwK1dWT",
        "outputId": "2cb4bf83-184d-4979-b4ff-b6689f33b5be"
      },
      "source": [
        "model_glove = tf.keras.Sequential()\r\n",
        "model_glove.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_glove.add(tf.keras.layers.LSTM(64))\r\n",
        "model_glove.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_glove.add(tf.keras.layers.Dense(64,activation='relu'))\r\n",
        "model_glove.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_glove.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_glove.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy',f1,precision,recall])\r\n",
        "glove_train_gen=glove_gen(vocab_glove,X_train,y_train,batch_size,Max_input_size,Embedding_size)\r\n",
        "glove_val_gen=glove_gen(vocab_glove,X_val,y_val,batch_size,Max_input_size,Embedding_size)\r\n",
        "history_glove_lstm = model_glove.fit_generator(glove_train_gen,validation_data=glove_val_gen,validation_steps=int((len(X_val)/batch_size)+1),steps_per_epoch=int((len(X_train)/batch_size)+1),epochs=epochs)\r\n",
        "history = model_glove.evaluate(x = glove_gen(vocab_glove,X_test,y_test,batch_size,Max_input_size,Embedding_size),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table[6]=history[1]\r\n",
        "print(\"GLOVE_LSTM\")\r\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "46/46 [==============================] - 3s 32ms/step - loss: 1.3819 - accuracy: 0.2954 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3110 - val_accuracy: 0.3300 - val_f1: 0.1811 - val_precision: 0.5889 - val_recall: 0.1075\n",
            "Epoch 2/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 1.3166 - accuracy: 0.3374 - f1: 0.1622 - precision: 0.6610 - recall: 0.0976 - val_loss: 1.2147 - val_accuracy: 0.4583 - val_f1: 0.4301 - val_precision: 0.5488 - val_recall: 0.3542\n",
            "Epoch 3/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 1.2031 - accuracy: 0.4485 - f1: 0.3272 - precision: 0.6126 - recall: 0.2383 - val_loss: 1.1613 - val_accuracy: 0.4675 - val_f1: 0.4410 - val_precision: 0.6053 - val_recall: 0.3483\n",
            "Epoch 4/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1.1015 - accuracy: 0.5021 - f1: 0.4175 - precision: 0.7163 - recall: 0.3012 - val_loss: 1.0685 - val_accuracy: 0.5150 - val_f1: 0.4122 - val_precision: 0.7576 - val_recall: 0.2850\n",
            "Epoch 5/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1.0218 - accuracy: 0.5365 - f1: 0.4327 - precision: 0.8056 - recall: 0.2985 - val_loss: 1.0376 - val_accuracy: 0.5308 - val_f1: 0.3909 - val_precision: 0.8449 - val_recall: 0.2575\n",
            "Epoch 6/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.9533 - accuracy: 0.5679 - f1: 0.4687 - precision: 0.8552 - recall: 0.3251 - val_loss: 1.1262 - val_accuracy: 0.4450 - val_f1: 0.2616 - val_precision: 0.9330 - val_recall: 0.1533\n",
            "Epoch 7/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.9524 - accuracy: 0.5551 - f1: 0.4511 - precision: 0.8882 - recall: 0.3097 - val_loss: 0.9924 - val_accuracy: 0.5400 - val_f1: 0.4184 - val_precision: 0.8880 - val_recall: 0.2767\n",
            "Epoch 8/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.8469 - accuracy: 0.6145 - f1: 0.5216 - precision: 0.9129 - recall: 0.3688 - val_loss: 0.9539 - val_accuracy: 0.5842 - val_f1: 0.4841 - val_precision: 0.8705 - val_recall: 0.3400\n",
            "Epoch 9/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.8024 - accuracy: 0.6504 - f1: 0.5533 - precision: 0.9085 - recall: 0.4003 - val_loss: 0.9562 - val_accuracy: 0.5617 - val_f1: 0.4682 - val_precision: 0.8723 - val_recall: 0.3233\n",
            "Epoch 10/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.7260 - accuracy: 0.6774 - f1: 0.5920 - precision: 0.9147 - recall: 0.4397 - val_loss: 0.9867 - val_accuracy: 0.5742 - val_f1: 0.4716 - val_precision: 0.8282 - val_recall: 0.3317\n",
            "Epoch 11/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.7224 - accuracy: 0.6836 - f1: 0.6062 - precision: 0.8845 - recall: 0.4638 - val_loss: 1.0898 - val_accuracy: 0.5750 - val_f1: 0.5609 - val_precision: 0.7049 - val_recall: 0.4667\n",
            "Epoch 12/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.7084 - accuracy: 0.6966 - f1: 0.6521 - precision: 0.8441 - recall: 0.5347 - val_loss: 0.8838 - val_accuracy: 0.6183 - val_f1: 0.6195 - val_precision: 0.7485 - val_recall: 0.5292\n",
            "Epoch 13/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.6270 - accuracy: 0.7258 - f1: 0.6820 - precision: 0.8377 - recall: 0.5763 - val_loss: 0.9007 - val_accuracy: 0.6517 - val_f1: 0.6362 - val_precision: 0.7522 - val_recall: 0.5525\n",
            "Epoch 14/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.5818 - accuracy: 0.7534 - f1: 0.7318 - precision: 0.8478 - recall: 0.6452 - val_loss: 0.9445 - val_accuracy: 0.6383 - val_f1: 0.6422 - val_precision: 0.7124 - val_recall: 0.5850\n",
            "Epoch 15/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.5520 - accuracy: 0.7776 - f1: 0.7581 - precision: 0.8336 - recall: 0.6960 - val_loss: 0.8740 - val_accuracy: 0.6833 - val_f1: 0.6800 - val_precision: 0.7405 - val_recall: 0.6292\n",
            "Epoch 16/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.4821 - accuracy: 0.8256 - f1: 0.8152 - precision: 0.8658 - recall: 0.7709 - val_loss: 0.9459 - val_accuracy: 0.6792 - val_f1: 0.6672 - val_precision: 0.7330 - val_recall: 0.6125\n",
            "Epoch 17/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.4730 - accuracy: 0.8329 - f1: 0.8222 - precision: 0.8843 - recall: 0.7702 - val_loss: 0.8581 - val_accuracy: 0.7050 - val_f1: 0.7054 - val_precision: 0.7580 - val_recall: 0.6600\n",
            "Epoch 18/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.4318 - accuracy: 0.8517 - f1: 0.8482 - precision: 0.8893 - recall: 0.8118 - val_loss: 0.8597 - val_accuracy: 0.7292 - val_f1: 0.7229 - val_precision: 0.7583 - val_recall: 0.6908\n",
            "Epoch 19/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.4036 - accuracy: 0.8599 - f1: 0.8556 - precision: 0.8831 - recall: 0.8301 - val_loss: 0.8807 - val_accuracy: 0.7275 - val_f1: 0.7243 - val_precision: 0.7698 - val_recall: 0.6842\n",
            "Epoch 20/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.3932 - accuracy: 0.8751 - f1: 0.8721 - precision: 0.8981 - recall: 0.8480 - val_loss: 0.8337 - val_accuracy: 0.7125 - val_f1: 0.7051 - val_precision: 0.7551 - val_recall: 0.6617\n",
            "Epoch 21/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.3895 - accuracy: 0.8690 - f1: 0.8666 - precision: 0.8963 - recall: 0.8397 - val_loss: 0.8545 - val_accuracy: 0.7300 - val_f1: 0.7184 - val_precision: 0.7556 - val_recall: 0.6850\n",
            "Epoch 22/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.3426 - accuracy: 0.8899 - f1: 0.8918 - precision: 0.9219 - recall: 0.8644 - val_loss: 0.9200 - val_accuracy: 0.7125 - val_f1: 0.7125 - val_precision: 0.7456 - val_recall: 0.6825\n",
            "Epoch 23/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.3335 - accuracy: 0.8937 - f1: 0.8950 - precision: 0.9152 - recall: 0.8759 - val_loss: 0.9383 - val_accuracy: 0.7283 - val_f1: 0.7223 - val_precision: 0.7511 - val_recall: 0.6958\n",
            "Epoch 24/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.3366 - accuracy: 0.8920 - f1: 0.8928 - precision: 0.9129 - recall: 0.8739 - val_loss: 0.8289 - val_accuracy: 0.7408 - val_f1: 0.7318 - val_precision: 0.7672 - val_recall: 0.7000\n",
            "Epoch 25/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.2989 - accuracy: 0.9156 - f1: 0.9092 - precision: 0.9287 - recall: 0.8909 - val_loss: 1.0476 - val_accuracy: 0.7267 - val_f1: 0.7263 - val_precision: 0.7581 - val_recall: 0.6975\n",
            "Epoch 26/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.2691 - accuracy: 0.9172 - f1: 0.9151 - precision: 0.9320 - recall: 0.8991 - val_loss: 0.8250 - val_accuracy: 0.7525 - val_f1: 0.7522 - val_precision: 0.7852 - val_recall: 0.7225\n",
            "Epoch 27/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.2926 - accuracy: 0.9136 - f1: 0.9074 - precision: 0.9355 - recall: 0.8816 - val_loss: 0.8491 - val_accuracy: 0.7258 - val_f1: 0.7195 - val_precision: 0.7520 - val_recall: 0.6900\n",
            "Epoch 28/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.3066 - accuracy: 0.9127 - f1: 0.9098 - precision: 0.9256 - recall: 0.8946 - val_loss: 0.8673 - val_accuracy: 0.7500 - val_f1: 0.7506 - val_precision: 0.7795 - val_recall: 0.7242\n",
            "Epoch 29/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.2534 - accuracy: 0.9290 - f1: 0.9314 - precision: 0.9491 - recall: 0.9147 - val_loss: 0.8156 - val_accuracy: 0.7525 - val_f1: 0.7523 - val_precision: 0.7841 - val_recall: 0.7233\n",
            "Epoch 30/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.2299 - accuracy: 0.9372 - f1: 0.9389 - precision: 0.9507 - recall: 0.9275 - val_loss: 0.8149 - val_accuracy: 0.7617 - val_f1: 0.7599 - val_precision: 0.7876 - val_recall: 0.7342\n",
            "Epoch 31/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.2070 - accuracy: 0.9448 - f1: 0.9448 - precision: 0.9553 - recall: 0.9346 - val_loss: 0.8100 - val_accuracy: 0.7358 - val_f1: 0.7409 - val_precision: 0.7780 - val_recall: 0.7075\n",
            "Epoch 32/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.1909 - accuracy: 0.9482 - f1: 0.9480 - precision: 0.9609 - recall: 0.9358 - val_loss: 0.9208 - val_accuracy: 0.7392 - val_f1: 0.7391 - val_precision: 0.7650 - val_recall: 0.7150\n",
            "Epoch 33/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.1814 - accuracy: 0.9502 - f1: 0.9495 - precision: 0.9589 - recall: 0.9403 - val_loss: 1.0007 - val_accuracy: 0.7475 - val_f1: 0.7452 - val_precision: 0.7698 - val_recall: 0.7225\n",
            "Epoch 34/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.1608 - accuracy: 0.9608 - f1: 0.9601 - precision: 0.9705 - recall: 0.9499 - val_loss: 0.9676 - val_accuracy: 0.7575 - val_f1: 0.7585 - val_precision: 0.7745 - val_recall: 0.7433\n",
            "Epoch 35/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.1792 - accuracy: 0.9549 - f1: 0.9551 - precision: 0.9649 - recall: 0.9455 - val_loss: 0.9088 - val_accuracy: 0.7692 - val_f1: 0.7683 - val_precision: 0.7813 - val_recall: 0.7558\n",
            "Epoch 36/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.1782 - accuracy: 0.9526 - f1: 0.9543 - precision: 0.9604 - recall: 0.9482 - val_loss: 0.9393 - val_accuracy: 0.7633 - val_f1: 0.7603 - val_precision: 0.7791 - val_recall: 0.7425\n",
            "Epoch 37/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.1754 - accuracy: 0.9558 - f1: 0.9546 - precision: 0.9637 - recall: 0.9457 - val_loss: 0.9377 - val_accuracy: 0.7767 - val_f1: 0.7799 - val_precision: 0.7875 - val_recall: 0.7725\n",
            "Epoch 38/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.1613 - accuracy: 0.9584 - f1: 0.9601 - precision: 0.9665 - recall: 0.9538 - val_loss: 0.9439 - val_accuracy: 0.7575 - val_f1: 0.7582 - val_precision: 0.7729 - val_recall: 0.7442\n",
            "Epoch 39/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.1565 - accuracy: 0.9571 - f1: 0.9589 - precision: 0.9653 - recall: 0.9526 - val_loss: 0.8870 - val_accuracy: 0.7633 - val_f1: 0.7650 - val_precision: 0.7835 - val_recall: 0.7475\n",
            "Epoch 40/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.1504 - accuracy: 0.9600 - f1: 0.9630 - precision: 0.9705 - recall: 0.9556 - val_loss: 0.9958 - val_accuracy: 0.7458 - val_f1: 0.7472 - val_precision: 0.7626 - val_recall: 0.7325\n",
            "Epoch 41/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.1592 - accuracy: 0.9584 - f1: 0.9588 - precision: 0.9671 - recall: 0.9508 - val_loss: 0.9305 - val_accuracy: 0.7625 - val_f1: 0.7633 - val_precision: 0.7771 - val_recall: 0.7500\n",
            "Epoch 42/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.1678 - accuracy: 0.9577 - f1: 0.9572 - precision: 0.9634 - recall: 0.9512 - val_loss: 0.9642 - val_accuracy: 0.7600 - val_f1: 0.7564 - val_precision: 0.7685 - val_recall: 0.7450\n",
            "Epoch 43/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.1825 - accuracy: 0.9485 - f1: 0.9502 - precision: 0.9562 - recall: 0.9443 - val_loss: 1.0584 - val_accuracy: 0.7392 - val_f1: 0.7400 - val_precision: 0.7575 - val_recall: 0.7233\n",
            "Epoch 44/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.1656 - accuracy: 0.9565 - f1: 0.9564 - precision: 0.9610 - recall: 0.9519 - val_loss: 1.0449 - val_accuracy: 0.7483 - val_f1: 0.7530 - val_precision: 0.7657 - val_recall: 0.7408\n",
            "Epoch 45/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.1646 - accuracy: 0.9621 - f1: 0.9607 - precision: 0.9668 - recall: 0.9547 - val_loss: 0.8927 - val_accuracy: 0.7483 - val_f1: 0.7476 - val_precision: 0.7707 - val_recall: 0.7258\n",
            "Epoch 46/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.1783 - accuracy: 0.9556 - f1: 0.9551 - precision: 0.9636 - recall: 0.9468 - val_loss: 0.8780 - val_accuracy: 0.7708 - val_f1: 0.7714 - val_precision: 0.7860 - val_recall: 0.7575\n",
            "Epoch 47/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.1905 - accuracy: 0.9507 - f1: 0.9519 - precision: 0.9621 - recall: 0.9420 - val_loss: 1.1552 - val_accuracy: 0.7275 - val_f1: 0.7264 - val_precision: 0.7338 - val_recall: 0.7192\n",
            "Epoch 48/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.1797 - accuracy: 0.9540 - f1: 0.9556 - precision: 0.9608 - recall: 0.9505 - val_loss: 0.8944 - val_accuracy: 0.7725 - val_f1: 0.7726 - val_precision: 0.7912 - val_recall: 0.7550\n",
            "Epoch 49/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.1843 - accuracy: 0.9497 - f1: 0.9499 - precision: 0.9557 - recall: 0.9443 - val_loss: 1.0095 - val_accuracy: 0.7533 - val_f1: 0.7516 - val_precision: 0.7701 - val_recall: 0.7342\n",
            "Epoch 50/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.1971 - accuracy: 0.9467 - f1: 0.9457 - precision: 0.9594 - recall: 0.9325 - val_loss: 0.8997 - val_accuracy: 0.7725 - val_f1: 0.7779 - val_precision: 0.7941 - val_recall: 0.7625\n",
            "Epoch 51/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.1547 - accuracy: 0.9599 - f1: 0.9592 - precision: 0.9646 - recall: 0.9539 - val_loss: 0.9109 - val_accuracy: 0.7692 - val_f1: 0.7683 - val_precision: 0.7886 - val_recall: 0.7492\n",
            "Epoch 52/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.1392 - accuracy: 0.9655 - f1: 0.9647 - precision: 0.9712 - recall: 0.9584 - val_loss: 0.9712 - val_accuracy: 0.7525 - val_f1: 0.7536 - val_precision: 0.7679 - val_recall: 0.7400\n",
            "Epoch 53/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.1304 - accuracy: 0.9635 - f1: 0.9648 - precision: 0.9731 - recall: 0.9567 - val_loss: 1.0088 - val_accuracy: 0.7517 - val_f1: 0.7550 - val_precision: 0.7716 - val_recall: 0.7392\n",
            "Epoch 54/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.1101 - accuracy: 0.9689 - f1: 0.9709 - precision: 0.9782 - recall: 0.9637 - val_loss: 1.0246 - val_accuracy: 0.7492 - val_f1: 0.7471 - val_precision: 0.7662 - val_recall: 0.7292\n",
            "Epoch 55/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.1054 - accuracy: 0.9699 - f1: 0.9726 - precision: 0.9788 - recall: 0.9664 - val_loss: 1.0765 - val_accuracy: 0.7467 - val_f1: 0.7455 - val_precision: 0.7626 - val_recall: 0.7292\n",
            "Epoch 56/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0938 - accuracy: 0.9736 - f1: 0.9731 - precision: 0.9790 - recall: 0.9673 - val_loss: 1.0293 - val_accuracy: 0.7625 - val_f1: 0.7618 - val_precision: 0.7732 - val_recall: 0.7508\n",
            "Epoch 57/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.1064 - accuracy: 0.9708 - f1: 0.9728 - precision: 0.9787 - recall: 0.9670 - val_loss: 1.0016 - val_accuracy: 0.7692 - val_f1: 0.7722 - val_precision: 0.7893 - val_recall: 0.7558\n",
            "Epoch 58/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.0996 - accuracy: 0.9747 - f1: 0.9743 - precision: 0.9798 - recall: 0.9689 - val_loss: 1.1303 - val_accuracy: 0.7467 - val_f1: 0.7490 - val_precision: 0.7636 - val_recall: 0.7350\n",
            "Epoch 59/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0934 - accuracy: 0.9736 - f1: 0.9751 - precision: 0.9837 - recall: 0.9668 - val_loss: 1.1193 - val_accuracy: 0.7650 - val_f1: 0.7685 - val_precision: 0.7809 - val_recall: 0.7567\n",
            "Epoch 60/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.0975 - accuracy: 0.9731 - f1: 0.9736 - precision: 0.9806 - recall: 0.9668 - val_loss: 1.0699 - val_accuracy: 0.7692 - val_f1: 0.7675 - val_precision: 0.7841 - val_recall: 0.7517\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.9915 - accuracy: 0.7800 - f1: 0.7863 - precision: 0.8019 - recall: 0.7714\n",
            "[0.991539716720581, 0.7799999713897705, 0.7862604856491089, 0.8018965125083923, 0.771428644657135]\n",
            "GLOVE_LSTM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKM9PEwm1fkb",
        "outputId": "be8ff3a1-9c4c-4ac1-e864-7903a4c74431"
      },
      "source": [
        "model_glove_bi = tf.keras.Sequential()\r\n",
        "model_glove_bi.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_glove_bi.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64),merge_mode='concat'))\r\n",
        "model_glove_bi.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_glove_bi.add(tf.keras.layers.Dense(64,activation='relu'))\r\n",
        "model_glove_bi.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_glove_bi.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_glove_bi.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy',f1,precision,recall])\r\n",
        "history_glove_bi = model_glove_bi.fit_generator(glove_train_gen,validation_data=glove_val_gen,validation_steps=int((len(X_val)/batch_size)+1),steps_per_epoch=int((len(X_train)/batch_size)+1),epochs=epochs)\r\n",
        "history = model_glove_bi.evaluate(x = glove_gen(vocab_glove,X_test,y_test,batch_size,Max_input_size,Embedding_size),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table[7]=history[1]\r\n",
        "print(\"GLOVE_BI\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "46/46 [==============================] - 4s 38ms/step - loss: 1.3730 - accuracy: 0.3103 - f1: 4.8058e-04 - precision: 0.0114 - recall: 2.4776e-04 - val_loss: 1.2795 - val_accuracy: 0.4100 - val_f1: 0.0691 - val_precision: 0.7375 - val_recall: 0.0367\n",
            "Epoch 2/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 1.2328 - accuracy: 0.4405 - f1: 0.1638 - precision: 0.6691 - recall: 0.0980 - val_loss: 1.1104 - val_accuracy: 0.5325 - val_f1: 0.4032 - val_precision: 0.6558 - val_recall: 0.2925\n",
            "Epoch 3/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1.0186 - accuracy: 0.5897 - f1: 0.4940 - precision: 0.6875 - recall: 0.3884 - val_loss: 0.9417 - val_accuracy: 0.6167 - val_f1: 0.5863 - val_precision: 0.6891 - val_recall: 0.5108\n",
            "Epoch 4/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.8110 - accuracy: 0.6886 - f1: 0.6573 - precision: 0.7567 - recall: 0.5819 - val_loss: 0.8401 - val_accuracy: 0.6583 - val_f1: 0.6413 - val_precision: 0.7298 - val_recall: 0.5725\n",
            "Epoch 5/60\n",
            "46/46 [==============================] - 1s 24ms/step - loss: 0.6892 - accuracy: 0.7447 - f1: 0.7264 - precision: 0.8034 - recall: 0.6640 - val_loss: 0.8106 - val_accuracy: 0.6792 - val_f1: 0.6630 - val_precision: 0.7250 - val_recall: 0.6108\n",
            "Epoch 6/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.5840 - accuracy: 0.7938 - f1: 0.7827 - precision: 0.8361 - recall: 0.7363 - val_loss: 0.8124 - val_accuracy: 0.6817 - val_f1: 0.6721 - val_precision: 0.7197 - val_recall: 0.6308\n",
            "Epoch 7/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.5230 - accuracy: 0.8098 - f1: 0.8084 - precision: 0.8516 - recall: 0.7695 - val_loss: 0.7202 - val_accuracy: 0.7158 - val_f1: 0.7077 - val_precision: 0.7566 - val_recall: 0.6650\n",
            "Epoch 8/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.4695 - accuracy: 0.8285 - f1: 0.8239 - precision: 0.8608 - recall: 0.7904 - val_loss: 0.6739 - val_accuracy: 0.7583 - val_f1: 0.7462 - val_precision: 0.7835 - val_recall: 0.7125\n",
            "Epoch 9/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.3635 - accuracy: 0.8711 - f1: 0.8700 - precision: 0.8958 - recall: 0.8459 - val_loss: 0.7165 - val_accuracy: 0.7483 - val_f1: 0.7480 - val_precision: 0.7735 - val_recall: 0.7242\n",
            "Epoch 10/60\n",
            "46/46 [==============================] - 1s 25ms/step - loss: 0.2909 - accuracy: 0.8986 - f1: 0.9007 - precision: 0.9194 - recall: 0.8829 - val_loss: 0.6723 - val_accuracy: 0.7392 - val_f1: 0.7349 - val_precision: 0.7708 - val_recall: 0.7025\n",
            "Epoch 11/60\n",
            "46/46 [==============================] - 1s 25ms/step - loss: 0.2809 - accuracy: 0.8960 - f1: 0.8934 - precision: 0.9115 - recall: 0.8762 - val_loss: 0.7298 - val_accuracy: 0.7475 - val_f1: 0.7410 - val_precision: 0.7645 - val_recall: 0.7192\n",
            "Epoch 12/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.2580 - accuracy: 0.9091 - f1: 0.9094 - precision: 0.9235 - recall: 0.8957 - val_loss: 0.8011 - val_accuracy: 0.7567 - val_f1: 0.7632 - val_precision: 0.7787 - val_recall: 0.7483\n",
            "Epoch 13/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.2398 - accuracy: 0.9159 - f1: 0.9165 - precision: 0.9321 - recall: 0.9016 - val_loss: 0.7361 - val_accuracy: 0.7567 - val_f1: 0.7543 - val_precision: 0.7758 - val_recall: 0.7342\n",
            "Epoch 14/60\n",
            "46/46 [==============================] - 1s 24ms/step - loss: 0.2239 - accuracy: 0.9205 - f1: 0.9185 - precision: 0.9309 - recall: 0.9065 - val_loss: 0.7104 - val_accuracy: 0.7850 - val_f1: 0.7836 - val_precision: 0.7961 - val_recall: 0.7717\n",
            "Epoch 15/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.1862 - accuracy: 0.9373 - f1: 0.9351 - precision: 0.9445 - recall: 0.9260 - val_loss: 0.8017 - val_accuracy: 0.7750 - val_f1: 0.7707 - val_precision: 0.7827 - val_recall: 0.7592\n",
            "Epoch 16/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.1496 - accuracy: 0.9430 - f1: 0.9446 - precision: 0.9535 - recall: 0.9360 - val_loss: 0.7907 - val_accuracy: 0.7675 - val_f1: 0.7666 - val_precision: 0.7778 - val_recall: 0.7558\n",
            "Epoch 17/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.1643 - accuracy: 0.9422 - f1: 0.9421 - precision: 0.9515 - recall: 0.9329 - val_loss: 0.8373 - val_accuracy: 0.7592 - val_f1: 0.7589 - val_precision: 0.7682 - val_recall: 0.7500\n",
            "Epoch 18/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.1674 - accuracy: 0.9359 - f1: 0.9369 - precision: 0.9453 - recall: 0.9287 - val_loss: 0.7075 - val_accuracy: 0.7858 - val_f1: 0.7845 - val_precision: 0.8025 - val_recall: 0.7675\n",
            "Epoch 19/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.1428 - accuracy: 0.9498 - f1: 0.9495 - precision: 0.9553 - recall: 0.9439 - val_loss: 0.8748 - val_accuracy: 0.7817 - val_f1: 0.7792 - val_precision: 0.7861 - val_recall: 0.7725\n",
            "Epoch 20/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.1248 - accuracy: 0.9527 - f1: 0.9528 - precision: 0.9568 - recall: 0.9490 - val_loss: 0.9178 - val_accuracy: 0.7792 - val_f1: 0.7773 - val_precision: 0.7841 - val_recall: 0.7708\n",
            "Epoch 21/60\n",
            "46/46 [==============================] - 1s 25ms/step - loss: 0.0951 - accuracy: 0.9593 - f1: 0.9592 - precision: 0.9636 - recall: 0.9549 - val_loss: 0.8475 - val_accuracy: 0.7842 - val_f1: 0.7835 - val_precision: 0.7871 - val_recall: 0.7800\n",
            "Epoch 22/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.0790 - accuracy: 0.9668 - f1: 0.9673 - precision: 0.9708 - recall: 0.9639 - val_loss: 0.8941 - val_accuracy: 0.7833 - val_f1: 0.7821 - val_precision: 0.7859 - val_recall: 0.7783\n",
            "Epoch 23/60\n",
            "46/46 [==============================] - 1s 24ms/step - loss: 0.0689 - accuracy: 0.9740 - f1: 0.9740 - precision: 0.9781 - recall: 0.9699 - val_loss: 0.9509 - val_accuracy: 0.7825 - val_f1: 0.7813 - val_precision: 0.7853 - val_recall: 0.7775\n",
            "Epoch 24/60\n",
            "46/46 [==============================] - 1s 25ms/step - loss: 0.0621 - accuracy: 0.9727 - f1: 0.9734 - precision: 0.9754 - recall: 0.9715 - val_loss: 0.9660 - val_accuracy: 0.7800 - val_f1: 0.7826 - val_precision: 0.7878 - val_recall: 0.7775\n",
            "Epoch 25/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.0615 - accuracy: 0.9746 - f1: 0.9756 - precision: 0.9777 - recall: 0.9736 - val_loss: 0.9487 - val_accuracy: 0.7825 - val_f1: 0.7841 - val_precision: 0.7874 - val_recall: 0.7808\n",
            "Epoch 26/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0592 - accuracy: 0.9734 - f1: 0.9729 - precision: 0.9742 - recall: 0.9716 - val_loss: 0.9579 - val_accuracy: 0.7817 - val_f1: 0.7837 - val_precision: 0.7892 - val_recall: 0.7783\n",
            "Epoch 27/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.0599 - accuracy: 0.9730 - f1: 0.9738 - precision: 0.9761 - recall: 0.9714 - val_loss: 1.0994 - val_accuracy: 0.7650 - val_f1: 0.7610 - val_precision: 0.7655 - val_recall: 0.7567\n",
            "Epoch 28/60\n",
            "46/46 [==============================] - 1s 25ms/step - loss: 0.0659 - accuracy: 0.9754 - f1: 0.9756 - precision: 0.9764 - recall: 0.9749 - val_loss: 1.0973 - val_accuracy: 0.7717 - val_f1: 0.7720 - val_precision: 0.7765 - val_recall: 0.7675\n",
            "Epoch 29/60\n",
            "46/46 [==============================] - 1s 24ms/step - loss: 0.0544 - accuracy: 0.9776 - f1: 0.9773 - precision: 0.9786 - recall: 0.9761 - val_loss: 1.1303 - val_accuracy: 0.7592 - val_f1: 0.7590 - val_precision: 0.7639 - val_recall: 0.7542\n",
            "Epoch 30/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.0541 - accuracy: 0.9767 - f1: 0.9774 - precision: 0.9793 - recall: 0.9755 - val_loss: 1.1183 - val_accuracy: 0.7608 - val_f1: 0.7612 - val_precision: 0.7650 - val_recall: 0.7575\n",
            "Epoch 31/60\n",
            "46/46 [==============================] - 1s 24ms/step - loss: 0.0607 - accuracy: 0.9711 - f1: 0.9714 - precision: 0.9730 - recall: 0.9699 - val_loss: 1.3068 - val_accuracy: 0.7392 - val_f1: 0.7384 - val_precision: 0.7443 - val_recall: 0.7325\n",
            "Epoch 32/60\n",
            "46/46 [==============================] - 1s 25ms/step - loss: 0.0597 - accuracy: 0.9739 - f1: 0.9751 - precision: 0.9773 - recall: 0.9730 - val_loss: 1.1472 - val_accuracy: 0.7617 - val_f1: 0.7615 - val_precision: 0.7699 - val_recall: 0.7533\n",
            "Epoch 33/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.0681 - accuracy: 0.9723 - f1: 0.9711 - precision: 0.9734 - recall: 0.9688 - val_loss: 1.1839 - val_accuracy: 0.7483 - val_f1: 0.7450 - val_precision: 0.7510 - val_recall: 0.7392\n",
            "Epoch 34/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0516 - accuracy: 0.9768 - f1: 0.9773 - precision: 0.9787 - recall: 0.9760 - val_loss: 1.1544 - val_accuracy: 0.7725 - val_f1: 0.7714 - val_precision: 0.7763 - val_recall: 0.7667\n",
            "Epoch 35/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0583 - accuracy: 0.9752 - f1: 0.9745 - precision: 0.9767 - recall: 0.9723 - val_loss: 0.9311 - val_accuracy: 0.7758 - val_f1: 0.7765 - val_precision: 0.7831 - val_recall: 0.7700\n",
            "Epoch 36/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0596 - accuracy: 0.9747 - f1: 0.9755 - precision: 0.9780 - recall: 0.9731 - val_loss: 1.0581 - val_accuracy: 0.7700 - val_f1: 0.7711 - val_precision: 0.7782 - val_recall: 0.7642\n",
            "Epoch 37/60\n",
            "46/46 [==============================] - 1s 24ms/step - loss: 0.0515 - accuracy: 0.9771 - f1: 0.9769 - precision: 0.9785 - recall: 0.9753 - val_loss: 1.2232 - val_accuracy: 0.7750 - val_f1: 0.7734 - val_precision: 0.7760 - val_recall: 0.7708\n",
            "Epoch 38/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.0487 - accuracy: 0.9709 - f1: 0.9723 - precision: 0.9740 - recall: 0.9706 - val_loss: 1.2196 - val_accuracy: 0.7717 - val_f1: 0.7705 - val_precision: 0.7743 - val_recall: 0.7667\n",
            "Epoch 39/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.0432 - accuracy: 0.9792 - f1: 0.9786 - precision: 0.9796 - recall: 0.9777 - val_loss: 1.2031 - val_accuracy: 0.7642 - val_f1: 0.7662 - val_precision: 0.7691 - val_recall: 0.7633\n",
            "Epoch 40/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0399 - accuracy: 0.9799 - f1: 0.9792 - precision: 0.9803 - recall: 0.9781 - val_loss: 1.3459 - val_accuracy: 0.7650 - val_f1: 0.7647 - val_precision: 0.7669 - val_recall: 0.7625\n",
            "Epoch 41/60\n",
            "46/46 [==============================] - 1s 24ms/step - loss: 0.0492 - accuracy: 0.9743 - f1: 0.9741 - precision: 0.9756 - recall: 0.9725 - val_loss: 1.2426 - val_accuracy: 0.7683 - val_f1: 0.7696 - val_precision: 0.7734 - val_recall: 0.7658\n",
            "Epoch 42/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.0465 - accuracy: 0.9770 - f1: 0.9758 - precision: 0.9779 - recall: 0.9737 - val_loss: 1.4315 - val_accuracy: 0.7667 - val_f1: 0.7695 - val_precision: 0.7723 - val_recall: 0.7667\n",
            "Epoch 43/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.0476 - accuracy: 0.9753 - f1: 0.9753 - precision: 0.9766 - recall: 0.9740 - val_loss: 1.3401 - val_accuracy: 0.7767 - val_f1: 0.7773 - val_precision: 0.7796 - val_recall: 0.7750\n",
            "Epoch 44/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.0551 - accuracy: 0.9733 - f1: 0.9727 - precision: 0.9751 - recall: 0.9704 - val_loss: 1.4239 - val_accuracy: 0.7750 - val_f1: 0.7737 - val_precision: 0.7775 - val_recall: 0.7700\n",
            "Epoch 45/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.0495 - accuracy: 0.9742 - f1: 0.9750 - precision: 0.9774 - recall: 0.9727 - val_loss: 1.2173 - val_accuracy: 0.7750 - val_f1: 0.7757 - val_precision: 0.7807 - val_recall: 0.7708\n",
            "Epoch 46/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.0529 - accuracy: 0.9729 - f1: 0.9729 - precision: 0.9741 - recall: 0.9717 - val_loss: 1.3564 - val_accuracy: 0.7850 - val_f1: 0.7869 - val_precision: 0.7889 - val_recall: 0.7850\n",
            "Epoch 47/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0476 - accuracy: 0.9762 - f1: 0.9767 - precision: 0.9791 - recall: 0.9744 - val_loss: 1.2227 - val_accuracy: 0.7800 - val_f1: 0.7790 - val_precision: 0.7822 - val_recall: 0.7758\n",
            "Epoch 48/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.0499 - accuracy: 0.9759 - f1: 0.9752 - precision: 0.9762 - recall: 0.9743 - val_loss: 1.1429 - val_accuracy: 0.7975 - val_f1: 0.7995 - val_precision: 0.8014 - val_recall: 0.7975\n",
            "Epoch 49/60\n",
            "46/46 [==============================] - 1s 25ms/step - loss: 0.0503 - accuracy: 0.9758 - f1: 0.9762 - precision: 0.9769 - recall: 0.9755 - val_loss: 1.5042 - val_accuracy: 0.7692 - val_f1: 0.7684 - val_precision: 0.7693 - val_recall: 0.7675\n",
            "Epoch 50/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.0583 - accuracy: 0.9765 - f1: 0.9758 - precision: 0.9769 - recall: 0.9747 - val_loss: 1.2854 - val_accuracy: 0.7775 - val_f1: 0.7784 - val_precision: 0.7810 - val_recall: 0.7758\n",
            "Epoch 51/60\n",
            "46/46 [==============================] - 1s 24ms/step - loss: 0.0487 - accuracy: 0.9771 - f1: 0.9771 - precision: 0.9783 - recall: 0.9760 - val_loss: 1.2335 - val_accuracy: 0.7775 - val_f1: 0.7781 - val_precision: 0.7803 - val_recall: 0.7758\n",
            "Epoch 52/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0469 - accuracy: 0.9758 - f1: 0.9759 - precision: 0.9782 - recall: 0.9735 - val_loss: 1.2245 - val_accuracy: 0.7917 - val_f1: 0.7923 - val_precision: 0.7947 - val_recall: 0.7900\n",
            "Epoch 53/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0493 - accuracy: 0.9733 - f1: 0.9732 - precision: 0.9745 - recall: 0.9718 - val_loss: 1.4706 - val_accuracy: 0.7725 - val_f1: 0.7734 - val_precision: 0.7743 - val_recall: 0.7725\n",
            "Epoch 54/60\n",
            "46/46 [==============================] - 1s 24ms/step - loss: 0.0421 - accuracy: 0.9792 - f1: 0.9788 - precision: 0.9797 - recall: 0.9779 - val_loss: 1.3187 - val_accuracy: 0.7775 - val_f1: 0.7779 - val_precision: 0.7792 - val_recall: 0.7767\n",
            "Epoch 55/60\n",
            "46/46 [==============================] - 1s 24ms/step - loss: 0.0406 - accuracy: 0.9785 - f1: 0.9783 - precision: 0.9790 - recall: 0.9775 - val_loss: 1.2785 - val_accuracy: 0.7875 - val_f1: 0.7869 - val_precision: 0.7905 - val_recall: 0.7833\n",
            "Epoch 56/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0352 - accuracy: 0.9813 - f1: 0.9817 - precision: 0.9821 - recall: 0.9812 - val_loss: 1.3444 - val_accuracy: 0.7858 - val_f1: 0.7868 - val_precision: 0.7878 - val_recall: 0.7858\n",
            "Epoch 57/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.0383 - accuracy: 0.9830 - f1: 0.9824 - precision: 0.9840 - recall: 0.9808 - val_loss: 1.3655 - val_accuracy: 0.7917 - val_f1: 0.7904 - val_precision: 0.7934 - val_recall: 0.7875\n",
            "Epoch 58/60\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.0354 - accuracy: 0.9820 - f1: 0.9815 - precision: 0.9835 - recall: 0.9795 - val_loss: 1.3472 - val_accuracy: 0.7825 - val_f1: 0.7827 - val_precision: 0.7846 - val_recall: 0.7808\n",
            "Epoch 59/60\n",
            "46/46 [==============================] - 1s 24ms/step - loss: 0.0327 - accuracy: 0.9829 - f1: 0.9827 - precision: 0.9838 - recall: 0.9817 - val_loss: 1.5505 - val_accuracy: 0.7783 - val_f1: 0.7790 - val_precision: 0.7796 - val_recall: 0.7783\n",
            "Epoch 60/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0539 - accuracy: 0.9736 - f1: 0.9741 - precision: 0.9759 - recall: 0.9724 - val_loss: 1.2892 - val_accuracy: 0.7825 - val_f1: 0.7817 - val_precision: 0.7843 - val_recall: 0.7792\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 1.1963 - accuracy: 0.7979 - f1: 0.8001 - precision: 0.8039 - recall: 0.7964\n",
            "[1.1962963342666626, 0.7978571653366089, 0.8001212477684021, 0.8038793206214905, 0.7964286208152771]\n",
            "GLOVE_BI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQBa5s4s1hNU",
        "outputId": "e490cc67-6814-40ce-bbab-89462a821c02"
      },
      "source": [
        "model_glove_rnn = tf.keras.Sequential()\r\n",
        "model_glove_rnn.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_glove_rnn.add(tf.keras.layers.SimpleRNN(64))\r\n",
        "model_glove_rnn.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_glove_rnn.add(tf.keras.layers.Dense(64,activation='relu'))\r\n",
        "model_glove_rnn.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_glove_rnn.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_glove_rnn.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy',f1,precision,recall])\r\n",
        "history_glove_rnn = model_glove_rnn.fit_generator(glove_train_gen,validation_data=glove_val_gen,validation_steps=int((len(X_val)/batch_size)+1),steps_per_epoch=int((len(X_train)/batch_size)+1),epochs=epochs)\r\n",
        "history = model_glove_rnn.evaluate(x = glove_gen(vocab_glove,X_test,y_test,batch_size,Max_input_size,Embedding_size),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table[8]=history[1]\r\n",
        "print(\"GLOVE_RNN\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "46/46 [==============================] - 4s 65ms/step - loss: 1.3884 - accuracy: 0.2682 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3729 - val_accuracy: 0.3308 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/60\n",
            "46/46 [==============================] - 3s 65ms/step - loss: 1.3694 - accuracy: 0.3112 - f1: 0.0040 - precision: 0.0636 - recall: 0.0021 - val_loss: 1.3798 - val_accuracy: 0.3167 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/60\n",
            "46/46 [==============================] - 3s 67ms/step - loss: 1.3770 - accuracy: 0.2978 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3717 - val_accuracy: 0.3383 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/60\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 1.3709 - accuracy: 0.3172 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3677 - val_accuracy: 0.3275 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 5/60\n",
            "46/46 [==============================] - 3s 67ms/step - loss: 1.3596 - accuracy: 0.3308 - f1: 0.0084 - precision: 0.0575 - recall: 0.0047 - val_loss: 1.3507 - val_accuracy: 0.3475 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 6/60\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 1.3509 - accuracy: 0.3415 - f1: 0.0018 - precision: 0.0585 - recall: 9.0215e-04 - val_loss: 1.3743 - val_accuracy: 0.3267 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 7/60\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 1.3498 - accuracy: 0.3472 - f1: 0.0031 - precision: 0.1011 - recall: 0.0016 - val_loss: 1.3576 - val_accuracy: 0.3275 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 8/60\n",
            "46/46 [==============================] - 3s 61ms/step - loss: 1.2912 - accuracy: 0.4039 - f1: 0.0547 - precision: 0.4796 - recall: 0.0303 - val_loss: 1.3193 - val_accuracy: 0.3558 - val_f1: 0.2066 - val_precision: 0.4498 - val_recall: 0.1350\n",
            "Epoch 9/60\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 1.2358 - accuracy: 0.4202 - f1: 0.1883 - precision: 0.5493 - recall: 0.1162 - val_loss: 1.2977 - val_accuracy: 0.3617 - val_f1: 0.0425 - val_precision: 0.4685 - val_recall: 0.0225\n",
            "Epoch 10/60\n",
            "46/46 [==============================] - 3s 62ms/step - loss: 1.2052 - accuracy: 0.4473 - f1: 0.1861 - precision: 0.5439 - recall: 0.1170 - val_loss: 1.2713 - val_accuracy: 0.3992 - val_f1: 0.1670 - val_precision: 0.5240 - val_recall: 0.1000\n",
            "Epoch 11/60\n",
            "46/46 [==============================] - 3s 61ms/step - loss: 1.2019 - accuracy: 0.4558 - f1: 0.2363 - precision: 0.5181 - recall: 0.1583 - val_loss: 1.2952 - val_accuracy: 0.3933 - val_f1: 0.2670 - val_precision: 0.4784 - val_recall: 0.1858\n",
            "Epoch 12/60\n",
            "46/46 [==============================] - 3s 68ms/step - loss: 1.1517 - accuracy: 0.4868 - f1: 0.3337 - precision: 0.5956 - recall: 0.2388 - val_loss: 1.2980 - val_accuracy: 0.3883 - val_f1: 0.2946 - val_precision: 0.4504 - val_recall: 0.2200\n",
            "Epoch 13/60\n",
            "46/46 [==============================] - 3s 66ms/step - loss: 1.1328 - accuracy: 0.4983 - f1: 0.3459 - precision: 0.6057 - recall: 0.2480 - val_loss: 1.3551 - val_accuracy: 0.3992 - val_f1: 0.3569 - val_precision: 0.4327 - val_recall: 0.3042\n",
            "Epoch 14/60\n",
            "46/46 [==============================] - 3s 61ms/step - loss: 1.0951 - accuracy: 0.5292 - f1: 0.4032 - precision: 0.6481 - recall: 0.3055 - val_loss: 1.2898 - val_accuracy: 0.3975 - val_f1: 0.2921 - val_precision: 0.4704 - val_recall: 0.2125\n",
            "Epoch 15/60\n",
            "46/46 [==============================] - 3s 73ms/step - loss: 1.0448 - accuracy: 0.5569 - f1: 0.4656 - precision: 0.6538 - recall: 0.3680 - val_loss: 1.3173 - val_accuracy: 0.3992 - val_f1: 0.3063 - val_precision: 0.4456 - val_recall: 0.2342\n",
            "Epoch 16/60\n",
            "46/46 [==============================] - 3s 62ms/step - loss: 1.0129 - accuracy: 0.5720 - f1: 0.4942 - precision: 0.6721 - recall: 0.3964 - val_loss: 1.3087 - val_accuracy: 0.4075 - val_f1: 0.3153 - val_precision: 0.4961 - val_recall: 0.2325\n",
            "Epoch 17/60\n",
            "46/46 [==============================] - 2s 53ms/step - loss: 0.9939 - accuracy: 0.5797 - f1: 0.5147 - precision: 0.6833 - recall: 0.4174 - val_loss: 1.3026 - val_accuracy: 0.4142 - val_f1: 0.3042 - val_precision: 0.4814 - val_recall: 0.2233\n",
            "Epoch 18/60\n",
            "46/46 [==============================] - 3s 58ms/step - loss: 0.9728 - accuracy: 0.5907 - f1: 0.5283 - precision: 0.6854 - recall: 0.4353 - val_loss: 1.3633 - val_accuracy: 0.4000 - val_f1: 0.3390 - val_precision: 0.4789 - val_recall: 0.2633\n",
            "Epoch 19/60\n",
            "46/46 [==============================] - 3s 65ms/step - loss: 1.0429 - accuracy: 0.5501 - f1: 0.4724 - precision: 0.6483 - recall: 0.3752 - val_loss: 1.2887 - val_accuracy: 0.4133 - val_f1: 0.2799 - val_precision: 0.4678 - val_recall: 0.2000\n",
            "Epoch 20/60\n",
            "46/46 [==============================] - 3s 56ms/step - loss: 0.9774 - accuracy: 0.6065 - f1: 0.5388 - precision: 0.7003 - recall: 0.4423 - val_loss: 1.4133 - val_accuracy: 0.3983 - val_f1: 0.3579 - val_precision: 0.4497 - val_recall: 0.2983\n",
            "Epoch 21/60\n",
            "46/46 [==============================] - 3s 58ms/step - loss: 1.0002 - accuracy: 0.5879 - f1: 0.5309 - precision: 0.6623 - recall: 0.4475 - val_loss: 1.2943 - val_accuracy: 0.4150 - val_f1: 0.3513 - val_precision: 0.4821 - val_recall: 0.2767\n",
            "Epoch 22/60\n",
            "46/46 [==============================] - 3s 61ms/step - loss: 0.9777 - accuracy: 0.6088 - f1: 0.5393 - precision: 0.6766 - recall: 0.4510 - val_loss: 1.3386 - val_accuracy: 0.4083 - val_f1: 0.2915 - val_precision: 0.4581 - val_recall: 0.2142\n",
            "Epoch 23/60\n",
            "46/46 [==============================] - 3s 73ms/step - loss: 0.9783 - accuracy: 0.5989 - f1: 0.5129 - precision: 0.6990 - recall: 0.4111 - val_loss: 1.3388 - val_accuracy: 0.3992 - val_f1: 0.3221 - val_precision: 0.4596 - val_recall: 0.2483\n",
            "Epoch 24/60\n",
            "46/46 [==============================] - 2s 54ms/step - loss: 0.9446 - accuracy: 0.6173 - f1: 0.5440 - precision: 0.7135 - recall: 0.4437 - val_loss: 1.3318 - val_accuracy: 0.4267 - val_f1: 0.3629 - val_precision: 0.4799 - val_recall: 0.2925\n",
            "Epoch 25/60\n",
            "46/46 [==============================] - 3s 62ms/step - loss: 0.9325 - accuracy: 0.6231 - f1: 0.5656 - precision: 0.7260 - recall: 0.4655 - val_loss: 1.4203 - val_accuracy: 0.4217 - val_f1: 0.3929 - val_precision: 0.4692 - val_recall: 0.3383\n",
            "Epoch 26/60\n",
            "46/46 [==============================] - 3s 58ms/step - loss: 0.9322 - accuracy: 0.6111 - f1: 0.5669 - precision: 0.7037 - recall: 0.4773 - val_loss: 1.3653 - val_accuracy: 0.4392 - val_f1: 0.3905 - val_precision: 0.4828 - val_recall: 0.3283\n",
            "Epoch 27/60\n",
            "46/46 [==============================] - 3s 66ms/step - loss: 0.8448 - accuracy: 0.6622 - f1: 0.6220 - precision: 0.7513 - recall: 0.5327 - val_loss: 1.4222 - val_accuracy: 0.4342 - val_f1: 0.4141 - val_precision: 0.4777 - val_recall: 0.3658\n",
            "Epoch 28/60\n",
            "46/46 [==============================] - 3s 71ms/step - loss: 0.7946 - accuracy: 0.6935 - f1: 0.6640 - precision: 0.7528 - recall: 0.5947 - val_loss: 1.6091 - val_accuracy: 0.3975 - val_f1: 0.3804 - val_precision: 0.4231 - val_recall: 0.3458\n",
            "Epoch 29/60\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.8095 - accuracy: 0.6904 - f1: 0.6554 - precision: 0.7439 - recall: 0.5874 - val_loss: 1.6012 - val_accuracy: 0.4392 - val_f1: 0.4239 - val_precision: 0.4623 - val_recall: 0.3917\n",
            "Epoch 30/60\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.8573 - accuracy: 0.6586 - f1: 0.6263 - precision: 0.7070 - recall: 0.5640 - val_loss: 1.8236 - val_accuracy: 0.3817 - val_f1: 0.3687 - val_precision: 0.3906 - val_recall: 0.3492\n",
            "Epoch 31/60\n",
            "46/46 [==============================] - 3s 58ms/step - loss: 0.8792 - accuracy: 0.6495 - f1: 0.6214 - precision: 0.6915 - recall: 0.5660 - val_loss: 1.6376 - val_accuracy: 0.4450 - val_f1: 0.4254 - val_precision: 0.4624 - val_recall: 0.3942\n",
            "Epoch 32/60\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.7821 - accuracy: 0.7093 - f1: 0.6855 - precision: 0.7478 - recall: 0.6334 - val_loss: 1.5429 - val_accuracy: 0.4592 - val_f1: 0.4411 - val_precision: 0.4872 - val_recall: 0.4033\n",
            "Epoch 33/60\n",
            "46/46 [==============================] - 3s 59ms/step - loss: 0.7373 - accuracy: 0.7232 - f1: 0.7087 - precision: 0.7675 - recall: 0.6592 - val_loss: 1.5909 - val_accuracy: 0.4367 - val_f1: 0.4159 - val_precision: 0.4549 - val_recall: 0.3833\n",
            "Epoch 34/60\n",
            "46/46 [==============================] - 3s 65ms/step - loss: 0.7460 - accuracy: 0.7233 - f1: 0.7124 - precision: 0.7726 - recall: 0.6613 - val_loss: 1.5137 - val_accuracy: 0.4342 - val_f1: 0.4208 - val_precision: 0.4609 - val_recall: 0.3875\n",
            "Epoch 35/60\n",
            "46/46 [==============================] - 3s 57ms/step - loss: 0.8017 - accuracy: 0.6965 - f1: 0.6821 - precision: 0.7335 - recall: 0.6383 - val_loss: 1.5288 - val_accuracy: 0.4617 - val_f1: 0.4260 - val_precision: 0.4746 - val_recall: 0.3867\n",
            "Epoch 36/60\n",
            "46/46 [==============================] - 3s 60ms/step - loss: 0.7669 - accuracy: 0.7069 - f1: 0.6874 - precision: 0.7524 - recall: 0.6334 - val_loss: 1.4819 - val_accuracy: 0.4758 - val_f1: 0.4497 - val_precision: 0.4956 - val_recall: 0.4117\n",
            "Epoch 37/60\n",
            "46/46 [==============================] - 3s 58ms/step - loss: 0.7143 - accuracy: 0.7308 - f1: 0.7169 - precision: 0.7659 - recall: 0.6741 - val_loss: 1.4950 - val_accuracy: 0.4517 - val_f1: 0.4208 - val_precision: 0.4681 - val_recall: 0.3825\n",
            "Epoch 38/60\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.7016 - accuracy: 0.7443 - f1: 0.7310 - precision: 0.7785 - recall: 0.6896 - val_loss: 1.4638 - val_accuracy: 0.4558 - val_f1: 0.4256 - val_precision: 0.4764 - val_recall: 0.3850\n",
            "Epoch 39/60\n",
            "46/46 [==============================] - 3s 60ms/step - loss: 0.7132 - accuracy: 0.7324 - f1: 0.7206 - precision: 0.7758 - recall: 0.6735 - val_loss: 1.5745 - val_accuracy: 0.4058 - val_f1: 0.3760 - val_precision: 0.4260 - val_recall: 0.3367\n",
            "Epoch 40/60\n",
            "46/46 [==============================] - 3s 68ms/step - loss: 0.7628 - accuracy: 0.7153 - f1: 0.7029 - precision: 0.7619 - recall: 0.6529 - val_loss: 1.5204 - val_accuracy: 0.4217 - val_f1: 0.3970 - val_precision: 0.4493 - val_recall: 0.3558\n",
            "Epoch 41/60\n",
            "46/46 [==============================] - 3s 67ms/step - loss: 0.6821 - accuracy: 0.7557 - f1: 0.7317 - precision: 0.7892 - recall: 0.6830 - val_loss: 1.6348 - val_accuracy: 0.4367 - val_f1: 0.4249 - val_precision: 0.4564 - val_recall: 0.3975\n",
            "Epoch 42/60\n",
            "46/46 [==============================] - 3s 65ms/step - loss: 0.6852 - accuracy: 0.7394 - f1: 0.7329 - precision: 0.7725 - recall: 0.6975 - val_loss: 1.7295 - val_accuracy: 0.4458 - val_f1: 0.4312 - val_precision: 0.4583 - val_recall: 0.4075\n",
            "Epoch 43/60\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.6035 - accuracy: 0.7890 - f1: 0.7805 - precision: 0.8137 - recall: 0.7503 - val_loss: 1.7955 - val_accuracy: 0.4667 - val_f1: 0.4507 - val_precision: 0.4678 - val_recall: 0.4350\n",
            "Epoch 44/60\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.5825 - accuracy: 0.7990 - f1: 0.7914 - precision: 0.8179 - recall: 0.7669 - val_loss: 1.8813 - val_accuracy: 0.4583 - val_f1: 0.4497 - val_precision: 0.4675 - val_recall: 0.4333\n",
            "Epoch 45/60\n",
            "46/46 [==============================] - 3s 57ms/step - loss: 0.6270 - accuracy: 0.7800 - f1: 0.7750 - precision: 0.7999 - recall: 0.7519 - val_loss: 1.7414 - val_accuracy: 0.4692 - val_f1: 0.4617 - val_precision: 0.4818 - val_recall: 0.4433\n",
            "Epoch 46/60\n",
            "46/46 [==============================] - 3s 59ms/step - loss: 0.6887 - accuracy: 0.7475 - f1: 0.7376 - precision: 0.7673 - recall: 0.7104 - val_loss: 1.6825 - val_accuracy: 0.4633 - val_f1: 0.4568 - val_precision: 0.4780 - val_recall: 0.4375\n",
            "Epoch 47/60\n",
            "46/46 [==============================] - 3s 65ms/step - loss: 0.6236 - accuracy: 0.7747 - f1: 0.7679 - precision: 0.7974 - recall: 0.7408 - val_loss: 1.7011 - val_accuracy: 0.4650 - val_f1: 0.4576 - val_precision: 0.4759 - val_recall: 0.4408\n",
            "Epoch 48/60\n",
            "46/46 [==============================] - 3s 60ms/step - loss: 0.5982 - accuracy: 0.7803 - f1: 0.7832 - precision: 0.8051 - recall: 0.7626 - val_loss: 1.7116 - val_accuracy: 0.4617 - val_f1: 0.4524 - val_precision: 0.4684 - val_recall: 0.4375\n",
            "Epoch 49/60\n",
            "46/46 [==============================] - 3s 65ms/step - loss: 0.5342 - accuracy: 0.8173 - f1: 0.8092 - precision: 0.8343 - recall: 0.7859 - val_loss: 1.7946 - val_accuracy: 0.4608 - val_f1: 0.4536 - val_precision: 0.4654 - val_recall: 0.4425\n",
            "Epoch 50/60\n",
            "46/46 [==============================] - 3s 68ms/step - loss: 0.5525 - accuracy: 0.8052 - f1: 0.8023 - precision: 0.8255 - recall: 0.7806 - val_loss: 1.7280 - val_accuracy: 0.4567 - val_f1: 0.4555 - val_precision: 0.4725 - val_recall: 0.4400\n",
            "Epoch 51/60\n",
            "46/46 [==============================] - 3s 73ms/step - loss: 0.5141 - accuracy: 0.8220 - f1: 0.8224 - precision: 0.8415 - recall: 0.8045 - val_loss: 1.9018 - val_accuracy: 0.4683 - val_f1: 0.4614 - val_precision: 0.4735 - val_recall: 0.4500\n",
            "Epoch 52/60\n",
            "46/46 [==============================] - 3s 71ms/step - loss: 0.5129 - accuracy: 0.8203 - f1: 0.8174 - precision: 0.8345 - recall: 0.8011 - val_loss: 1.8090 - val_accuracy: 0.4758 - val_f1: 0.4712 - val_precision: 0.4849 - val_recall: 0.4583\n",
            "Epoch 53/60\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.5586 - accuracy: 0.8152 - f1: 0.8095 - precision: 0.8320 - recall: 0.7885 - val_loss: 1.7265 - val_accuracy: 0.4800 - val_f1: 0.4682 - val_precision: 0.4853 - val_recall: 0.4525\n",
            "Epoch 54/60\n",
            "46/46 [==============================] - 3s 65ms/step - loss: 0.5699 - accuracy: 0.8015 - f1: 0.7963 - precision: 0.8192 - recall: 0.7748 - val_loss: 1.8152 - val_accuracy: 0.4608 - val_f1: 0.4581 - val_precision: 0.4702 - val_recall: 0.4467\n",
            "Epoch 55/60\n",
            "46/46 [==============================] - 3s 61ms/step - loss: 0.5598 - accuracy: 0.8096 - f1: 0.8074 - precision: 0.8254 - recall: 0.7905 - val_loss: 1.7740 - val_accuracy: 0.4367 - val_f1: 0.4257 - val_precision: 0.4500 - val_recall: 0.4042\n",
            "Epoch 56/60\n",
            "46/46 [==============================] - 3s 65ms/step - loss: 0.6397 - accuracy: 0.7756 - f1: 0.7668 - precision: 0.8071 - recall: 0.7306 - val_loss: 1.7546 - val_accuracy: 0.4442 - val_f1: 0.4344 - val_precision: 0.4579 - val_recall: 0.4133\n",
            "Epoch 57/60\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5921 - accuracy: 0.8046 - f1: 0.7944 - precision: 0.8299 - recall: 0.7620 - val_loss: 1.6948 - val_accuracy: 0.4617 - val_f1: 0.4544 - val_precision: 0.4748 - val_recall: 0.4358\n",
            "Epoch 58/60\n",
            "46/46 [==============================] - 3s 72ms/step - loss: 0.5718 - accuracy: 0.8032 - f1: 0.8009 - precision: 0.8278 - recall: 0.7759 - val_loss: 1.7265 - val_accuracy: 0.4558 - val_f1: 0.4461 - val_precision: 0.4656 - val_recall: 0.4283\n",
            "Epoch 59/60\n",
            "46/46 [==============================] - 3s 62ms/step - loss: 0.4939 - accuracy: 0.8320 - f1: 0.8251 - precision: 0.8479 - recall: 0.8039 - val_loss: 1.7241 - val_accuracy: 0.4550 - val_f1: 0.4449 - val_precision: 0.4680 - val_recall: 0.4242\n",
            "Epoch 60/60\n",
            "46/46 [==============================] - 2s 54ms/step - loss: 0.6043 - accuracy: 0.7846 - f1: 0.7790 - precision: 0.8034 - recall: 0.7563 - val_loss: 1.7134 - val_accuracy: 0.4425 - val_f1: 0.4258 - val_precision: 0.4482 - val_recall: 0.4058\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 1.6878 - accuracy: 0.4550 - f1: 0.4418 - precision: 0.4681 - recall: 0.4186\n",
            "[1.6877638101577759, 0.45500001311302185, 0.44180795550346375, 0.46808019280433655, 0.41857144236564636]\n",
            "GLOVE_RNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZqN_SaM3hs9",
        "outputId": "3158c2c3-120c-4b68-8bfd-e3ca7f115610"
      },
      "source": [
        "print(\"\\tLstm\\t\\t\\tBiLstm\\t\\t\\tRnn\")\r\n",
        "print(\"sg\",result_table[:3])\r\n",
        "print(\"cbow\",result_table[3:6])\r\n",
        "print(\"glove\",result_table[6:9])\r\n",
        "# print(history_sg_bi.history)\r\n",
        "# plt.title(\"Skip-Gram + Bi-LSTM accuracy, loss vs epochs Graph\")\r\n",
        "# plt.plot(history_sg_bi.history['loss'],c='b',label='loss')\r\n",
        "# plt.plot(history_sg_bi.history['accuracy'],c='r',label='accuracy')\r\n",
        "# plt.xlabel('epochs')\r\n",
        "# plt.legend()\r\n",
        "# # plt.yticks()\r\n",
        "# plt.show()\r\n",
        "# plt.title(\"GloVe + Bi-LSTM accuracy, loss vs epochs Graph\")\r\n",
        "# plt.plot(history_glove_bi.history['loss'],c='b',label='loss')\r\n",
        "# plt.plot(history_glove_bi.history['accuracy'],c='r',label='accuracy')\r\n",
        "# plt.xlabel('epochs')\r\n",
        "# plt.legend()\r\n",
        "# # plt.yticks()\r\n",
        "# plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tLstm\t\t\tBiLstm\t\t\tRnn\n",
            "sg [0.47357141971588135, 0.631428599357605, 0.334285706281662]\n",
            "cbow [0.579285740852356, 0.604285717010498, 0.28142857551574707]\n",
            "glove [0.7799999713897705, 0.7978571653366089, 0.45500001311302185]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}