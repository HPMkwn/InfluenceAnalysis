{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AllEmointGen_Amp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harrymkwn/InfluenceAnalysis/blob/master/AllEmointGen_Amp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkuKKcIUmM27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42db9e33-f953-4a33-c7b8-cc935009d664"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from gensim.models import Word2Vec\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import  drive\n",
        "drive.mount('/content/drive')\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('all')\n",
        "device_name = tf.test.gpu_device_name()\n",
        "print(device_name)\n",
        "df = pd.read_csv('/content/drive/MyDrive/InfluenceAnalysis/Data/Tweets_clean_data.csv')\n",
        "df = df.sample(frac=1,random_state=32)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n",
            "/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yV6_xYSnZHt"
      },
      "source": [
        "category_dict = {\"anger\":[1,0,0,0],\"sadness\":[0,1,0,0],\"fear\":[0,0,1,0],\"joy\":[0,0,0,1]}\n",
        "data_tweet = [x.lower().split() for x in df['Tweet']]\n",
        "data_cat = np.array([category_dict[x] for x in df['Emotion']])\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PmA3_Ihp-Ao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66d409f8-cd06-4e32-cd20-56842fbbc014"
      },
      "source": [
        "print(data_tweet[:5])\n",
        "print(data_cat[:5])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['with', 'their', 'faggy', 'colors', 'are', 'nice', 'is', 'ok', 'too', 'even', 'tho', 'some', 'might', 'take', 'offense', 'because', 'words', 'lol'], ['unbelievable', 'takes', '10', 'minutes', 'to', 'get', 'through', 'to', 'then', 'there', 'is', 'a', 'fault', 'and', 'the', 'call', 'hangs', 'up', 'treatcustomersfairly'], ['well', 'i', 'did', 'hear', 'once', 'before', 'that', 'girls', 'are', 'attracted', 'to', 'men', 'that', 'lok', 'like', 'their', 'dad', 'ok', 'hand'], ['agreed', 'so', 'tired', 'of', 'this', 'nonsense', 'soros', 'must', 'be', 'elated'], ['by', 'the', 'way', 'i', 'am', 'wearing', 'the', 'smile', 'you', 'gave', 'me', 'today', 'n', 'you', 'me']]\n",
            "[[1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [0 1 0 0]\n",
            " [0 0 0 1]\n",
            " [0 0 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mIV-pI5C44j"
      },
      "source": [
        "# Parameters\n",
        "Min_count = 0\n",
        "Embedding_size = 200\n",
        "Window_size = 5\n",
        "Negative_sampling = 00"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUSBfiE0nTVv"
      },
      "source": [
        "w2v_sg = Word2Vec(min_count=Min_count,\n",
        "                     window=Window_size,\n",
        "                     size=Embedding_size,\n",
        "                     negative=Negative_sampling,sg=1)\n",
        "w2v_sg.build_vocab(data_tweet)\n",
        "w2v_sg.train(data_tweet, total_examples=w2v_sg.corpus_count, epochs=5)\n",
        "w2v_cbow = Word2Vec(min_count=Min_count,\n",
        "                     window=Window_size,\n",
        "                     size=Embedding_size,\n",
        "                     negative=Negative_sampling,sg=0)\n",
        "w2v_cbow.build_vocab(data_tweet)\n",
        "w2v_cbow.train(data_tweet, total_examples=w2v_cbow.corpus_count, epochs=5)\n",
        "w2v_sg.wv.init_sims(True)\n",
        "w2v_cbow.wv.init_sims(True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVzquoxb6FQJ"
      },
      "source": [
        "vocab_sg = w2v_sg.wv.vocab\n",
        "vocab_sg = [x for x in vocab_sg]\n",
        "vocab_cbow = w2v_cbow.wv.vocab\n",
        "vocab_cbow = [x for x in vocab_cbow] \n",
        "vocab_glove = {}\n",
        "with open(\"/content/drive/My Drive/InfluenceAnalysis/glove/glove.twitter.27B.200d.txt\", 'r', encoding=\"utf-8\") as f:\n",
        "  for line in f:\n",
        "      values = line.split()\n",
        "      word = values[0]\n",
        "      vector = np.asarray(values[1:], \"float32\")\n",
        "      vocab_glove[word] = vector"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdgSI9FSmw60"
      },
      "source": [
        "batch_size = 100\r\n",
        "Max_input_size = max([len(x) for x in data_tweet])\r\n",
        "data_tweet = [nltk.pos_tag(x) for x in data_tweet]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArwAlW-wmZxv"
      },
      "source": [
        "def vec_gen(w2v,vocab,data_tweet,data_cat,batch_size,Max_input_size,Embedding_size,mul_factor=2):\r\n",
        "  while True:\r\n",
        "    for k in range(int(len(data_tweet)/batch_size)):\r\n",
        "      res=[]\r\n",
        "      for x in data_tweet[k*(batch_size):(k+1)*(batch_size)]:\r\n",
        "        tweet = [(w2v.wv.word_vec(i[0]),i[1]) for i in x if i[0] in vocab]\r\n",
        "        l=len(tweet)\r\n",
        "        for i in range(l):\r\n",
        "          if tweet[i][1][:2]=='JJ' or tweet[i][1][:2]=='RB' or tweet[i][1][:2]=='VB':\r\n",
        "            tweet[i]=((tweet[i][0])*mul_factor,tweet[i][1])\r\n",
        "        res+=[np.array([x[0] for x in tweet])]\r\n",
        "      temp = np.array([np.pad(z.flatten(),(0,Max_input_size*Embedding_size-len(z.flatten()))).reshape(Max_input_size,Embedding_size) for z in res])\r\n",
        "      tempres = data_cat[k*(batch_size):(k+1)*(batch_size)]\r\n",
        "      yield (temp,tempres)          \r\n",
        "      \r\n",
        "def glove_gen(vocab,data_tweet,data_cat,batch_size,Max_input_size,Embedding_size,mul_factor=2):\r\n",
        "  while True:\r\n",
        "    for k in range(int(len(data_tweet)/batch_size)):\r\n",
        "      res=[]\r\n",
        "      for x in data_tweet[k*(batch_size):(k+1)*(batch_size)]:\r\n",
        "        tweet = [(vocab[i[0]],i[1]) for i in x if i[0] in vocab.keys()]\r\n",
        "        l=len(tweet)\r\n",
        "        for i in range(l):\r\n",
        "          if tweet[i][1][:2]=='JJ' or tweet[i][1][:2]=='RB' or tweet[i][1][:2]=='VB':\r\n",
        "            tweet[i]=((tweet[i][0])*mul_factor,tweet[i][1])\r\n",
        "        res+=[np.array([x[0] for x in tweet])]\r\n",
        "      temp = np.array([np.pad(z.flatten(),(0,Max_input_size*Embedding_size-len(z.flatten()))).reshape(Max_input_size,Embedding_size) for z in res])\r\n",
        "      tempres = data_cat[k*(batch_size):(k+1)*(batch_size)]\r\n",
        "      yield (temp,tempres)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Fue2npdFINi"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data_tweet, data_cat, test_size=0.20, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42)\n",
        "result_table = [0,0,0,0,0,0,0,0,0]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0leTuTOb3naL"
      },
      "source": [
        "epochs = 60"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNj8uX_IBWt1"
      },
      "source": [
        "from keras import backend as K\r\n",
        "def recall(y_true, y_pred):\r\n",
        "        \"\"\"Recall metric.\r\n",
        "\r\n",
        "        Only computes a batch-wise average of recall.\r\n",
        "\r\n",
        "        Computes the recall, a metric for multi-label classification of\r\n",
        "        how many relevant items are selected.\r\n",
        "        \"\"\"\r\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\r\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\r\n",
        "        recalls = true_positives / (possible_positives + K.epsilon())\r\n",
        "        return recalls\r\n",
        "def precision(y_true, y_pred):\r\n",
        "        \"\"\"Precision metric.\r\n",
        "\r\n",
        "        Only computes a batch-wise average of precision.\r\n",
        "\r\n",
        "        Computes the precision, a metric for multi-label classification of\r\n",
        "        how many selected items are relevant.\r\n",
        "        \"\"\"\r\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\r\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\r\n",
        "        precisions = true_positives / (predicted_positives + K.epsilon())\r\n",
        "        return precisions\r\n",
        "def f1(y_true, y_pred):\r\n",
        "    precisions = precision(y_true, y_pred)\r\n",
        "    recalls = recall(y_true, y_pred)\r\n",
        "    return 2*((precisions*recalls)/(precisions+recalls+K.epsilon()))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GfgXfAFlD1J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21985ea7-5cea-46c2-ae8b-b794ba5181cc"
      },
      "source": [
        "model_sg = tf.keras.Sequential()\n",
        "model_sg.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\n",
        "model_sg.add(tf.keras.layers.LSTM(64))\n",
        "model_sg.add(tf.keras.layers.Dropout(0.2))\n",
        "model_sg.add(tf.keras.layers.Dense(64,activation='relu'))\n",
        "model_sg.add(tf.keras.layers.Dropout(0.2))\n",
        "model_sg.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
        "model_sg.compile(loss='categorical_crossentropy',optimizer='adam', \n",
        "                           metrics=['accuracy',f1,precision,recall])\n",
        "sg_train_gen=vec_gen(w2v_sg,vocab_sg,X_train,y_train,batch_size,Max_input_size,Embedding_size)\n",
        "sg_val_gen=vec_gen(w2v_sg,vocab_sg,X_val,y_val,batch_size,Max_input_size,Embedding_size)\n",
        "history_sg_lstm = model_sg.fit_generator(sg_train_gen,validation_data=sg_val_gen,validation_steps=int((len(X_val)/batch_size)+1),steps_per_epoch=int((len(X_train)/batch_size)+1),epochs=epochs)\n",
        "history = model_sg.evaluate(x = vec_gen(w2v_sg,vocab_sg,X_test,y_test,batch_size,Max_input_size,Embedding_size),steps=int(len(y_test)/batch_size))\n",
        "print(history)\n",
        "\n",
        "result_table[0]=history[1]\n",
        "print(\"SG_LSTM\")\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "46/46 [==============================] - 38s 112ms/step - loss: 1.3809 - accuracy: 0.3068 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3721 - val_accuracy: 0.3300 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.3781 - accuracy: 0.3054 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3709 - val_accuracy: 0.3367 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.3762 - accuracy: 0.3104 - f1: 0.0016 - precision: 0.0092 - recall: 8.9991e-04 - val_loss: 1.3771 - val_accuracy: 0.3350 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 1.3618 - accuracy: 0.3281 - f1: 0.0218 - precision: 0.1680 - recall: 0.0126 - val_loss: 1.3452 - val_accuracy: 0.3442 - val_f1: 0.0115 - val_precision: 0.4167 - val_recall: 0.0058\n",
            "Epoch 5/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.3242 - accuracy: 0.3568 - f1: 0.0985 - precision: 0.6254 - recall: 0.0580 - val_loss: 1.3272 - val_accuracy: 0.3567 - val_f1: 0.0307 - val_precision: 0.6125 - val_recall: 0.0158\n",
            "Epoch 6/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.2930 - accuracy: 0.3762 - f1: 0.1401 - precision: 0.6009 - recall: 0.0827 - val_loss: 1.3189 - val_accuracy: 0.3633 - val_f1: 0.1239 - val_precision: 0.5505 - val_recall: 0.0700\n",
            "Epoch 7/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.2774 - accuracy: 0.3916 - f1: 0.1853 - precision: 0.6160 - recall: 0.1118 - val_loss: 1.3200 - val_accuracy: 0.3525 - val_f1: 0.1743 - val_precision: 0.5617 - val_recall: 0.1033\n",
            "Epoch 8/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.2562 - accuracy: 0.4002 - f1: 0.2008 - precision: 0.6256 - recall: 0.1222 - val_loss: 1.3166 - val_accuracy: 0.3642 - val_f1: 0.1913 - val_precision: 0.5557 - val_recall: 0.1158\n",
            "Epoch 9/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.2433 - accuracy: 0.3997 - f1: 0.2292 - precision: 0.6236 - recall: 0.1423 - val_loss: 1.3116 - val_accuracy: 0.3442 - val_f1: 0.1691 - val_precision: 0.5825 - val_recall: 0.0992\n",
            "Epoch 10/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 1.2297 - accuracy: 0.4252 - f1: 0.2446 - precision: 0.5941 - recall: 0.1561 - val_loss: 1.3005 - val_accuracy: 0.3592 - val_f1: 0.1604 - val_precision: 0.6707 - val_recall: 0.0917\n",
            "Epoch 11/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.2028 - accuracy: 0.4401 - f1: 0.2607 - precision: 0.6481 - recall: 0.1675 - val_loss: 1.2793 - val_accuracy: 0.3783 - val_f1: 0.2139 - val_precision: 0.6088 - val_recall: 0.1300\n",
            "Epoch 12/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 1.1953 - accuracy: 0.4359 - f1: 0.2603 - precision: 0.6613 - recall: 0.1648 - val_loss: 1.2905 - val_accuracy: 0.3767 - val_f1: 0.2079 - val_precision: 0.6019 - val_recall: 0.1258\n",
            "Epoch 13/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.1543 - accuracy: 0.4581 - f1: 0.3169 - precision: 0.6370 - recall: 0.2136 - val_loss: 1.2566 - val_accuracy: 0.4142 - val_f1: 0.2537 - val_precision: 0.6124 - val_recall: 0.1608\n",
            "Epoch 14/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.1228 - accuracy: 0.4771 - f1: 0.3476 - precision: 0.6713 - recall: 0.2380 - val_loss: 1.2669 - val_accuracy: 0.3875 - val_f1: 0.2554 - val_precision: 0.6045 - val_recall: 0.1625\n",
            "Epoch 15/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.1138 - accuracy: 0.4898 - f1: 0.3526 - precision: 0.6959 - recall: 0.2436 - val_loss: 1.2445 - val_accuracy: 0.4250 - val_f1: 0.3155 - val_precision: 0.6151 - val_recall: 0.2133\n",
            "Epoch 16/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.0488 - accuracy: 0.5346 - f1: 0.4032 - precision: 0.7106 - recall: 0.2856 - val_loss: 1.2615 - val_accuracy: 0.4167 - val_f1: 0.2985 - val_precision: 0.5664 - val_recall: 0.2042\n",
            "Epoch 17/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.0077 - accuracy: 0.5569 - f1: 0.4429 - precision: 0.7374 - recall: 0.3200 - val_loss: 1.2661 - val_accuracy: 0.4325 - val_f1: 0.3182 - val_precision: 0.6180 - val_recall: 0.2158\n",
            "Epoch 18/60\n",
            "46/46 [==============================] - 4s 95ms/step - loss: 0.9598 - accuracy: 0.5896 - f1: 0.4754 - precision: 0.7440 - recall: 0.3519 - val_loss: 1.2715 - val_accuracy: 0.4283 - val_f1: 0.3611 - val_precision: 0.5204 - val_recall: 0.2775\n",
            "Epoch 19/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.9462 - accuracy: 0.6004 - f1: 0.5084 - precision: 0.7053 - recall: 0.4009 - val_loss: 1.2705 - val_accuracy: 0.4675 - val_f1: 0.4104 - val_precision: 0.5719 - val_recall: 0.3208\n",
            "Epoch 20/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.8970 - accuracy: 0.6430 - f1: 0.5513 - precision: 0.7520 - recall: 0.4374 - val_loss: 1.2473 - val_accuracy: 0.4525 - val_f1: 0.4288 - val_precision: 0.5043 - val_recall: 0.3742\n",
            "Epoch 21/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.8590 - accuracy: 0.6536 - f1: 0.6187 - precision: 0.7157 - recall: 0.5463 - val_loss: 1.2973 - val_accuracy: 0.4467 - val_f1: 0.4280 - val_precision: 0.4904 - val_recall: 0.3800\n",
            "Epoch 22/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.8837 - accuracy: 0.6437 - f1: 0.5910 - precision: 0.7160 - recall: 0.5053 - val_loss: 1.2428 - val_accuracy: 0.5058 - val_f1: 0.4864 - val_precision: 0.5507 - val_recall: 0.4358\n",
            "Epoch 23/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.7616 - accuracy: 0.7080 - f1: 0.6844 - precision: 0.7465 - recall: 0.6323 - val_loss: 1.2531 - val_accuracy: 0.5000 - val_f1: 0.4908 - val_precision: 0.5345 - val_recall: 0.4542\n",
            "Epoch 24/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.7290 - accuracy: 0.7276 - f1: 0.7065 - precision: 0.7592 - recall: 0.6613 - val_loss: 1.2780 - val_accuracy: 0.5283 - val_f1: 0.5226 - val_precision: 0.5559 - val_recall: 0.4933\n",
            "Epoch 25/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.6943 - accuracy: 0.7385 - f1: 0.7291 - precision: 0.7678 - recall: 0.6947 - val_loss: 1.2925 - val_accuracy: 0.5233 - val_f1: 0.5229 - val_precision: 0.5564 - val_recall: 0.4933\n",
            "Epoch 26/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.6937 - accuracy: 0.7462 - f1: 0.7380 - precision: 0.7763 - recall: 0.7039 - val_loss: 1.2755 - val_accuracy: 0.5417 - val_f1: 0.5377 - val_precision: 0.5765 - val_recall: 0.5042\n",
            "Epoch 27/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.6727 - accuracy: 0.7437 - f1: 0.7350 - precision: 0.7789 - recall: 0.6962 - val_loss: 1.3644 - val_accuracy: 0.4775 - val_f1: 0.4599 - val_precision: 0.5114 - val_recall: 0.4183\n",
            "Epoch 28/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.7350 - accuracy: 0.7220 - f1: 0.7125 - precision: 0.7665 - recall: 0.6672 - val_loss: 1.3846 - val_accuracy: 0.5008 - val_f1: 0.5032 - val_precision: 0.5342 - val_recall: 0.4758\n",
            "Epoch 29/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.6785 - accuracy: 0.7425 - f1: 0.7427 - precision: 0.7830 - recall: 0.7069 - val_loss: 1.3838 - val_accuracy: 0.5133 - val_f1: 0.5098 - val_precision: 0.5335 - val_recall: 0.4883\n",
            "Epoch 30/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.6751 - accuracy: 0.7419 - f1: 0.7352 - precision: 0.7707 - recall: 0.7034 - val_loss: 1.3908 - val_accuracy: 0.5158 - val_f1: 0.5161 - val_precision: 0.5373 - val_recall: 0.4967\n",
            "Epoch 31/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.6293 - accuracy: 0.7664 - f1: 0.7580 - precision: 0.7904 - recall: 0.7286 - val_loss: 1.3230 - val_accuracy: 0.5642 - val_f1: 0.5584 - val_precision: 0.5792 - val_recall: 0.5392\n",
            "Epoch 32/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.5767 - accuracy: 0.7988 - f1: 0.7951 - precision: 0.8203 - recall: 0.7717 - val_loss: 1.4676 - val_accuracy: 0.5258 - val_f1: 0.5243 - val_precision: 0.5357 - val_recall: 0.5133\n",
            "Epoch 33/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.7438 - accuracy: 0.7090 - f1: 0.7019 - precision: 0.7400 - recall: 0.6693 - val_loss: 1.3142 - val_accuracy: 0.5492 - val_f1: 0.5473 - val_precision: 0.5688 - val_recall: 0.5275\n",
            "Epoch 34/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.5895 - accuracy: 0.7968 - f1: 0.7929 - precision: 0.8182 - recall: 0.7694 - val_loss: 1.2351 - val_accuracy: 0.5367 - val_f1: 0.5361 - val_precision: 0.5685 - val_recall: 0.5075\n",
            "Epoch 35/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.5997 - accuracy: 0.7909 - f1: 0.7842 - precision: 0.8173 - recall: 0.7540 - val_loss: 1.3791 - val_accuracy: 0.5525 - val_f1: 0.5481 - val_precision: 0.5657 - val_recall: 0.5317\n",
            "Epoch 36/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.5365 - accuracy: 0.8190 - f1: 0.8156 - precision: 0.8409 - recall: 0.7922 - val_loss: 1.4142 - val_accuracy: 0.5767 - val_f1: 0.5745 - val_precision: 0.5890 - val_recall: 0.5608\n",
            "Epoch 37/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.5227 - accuracy: 0.8284 - f1: 0.8263 - precision: 0.8461 - recall: 0.8075 - val_loss: 1.4287 - val_accuracy: 0.5467 - val_f1: 0.5441 - val_precision: 0.5573 - val_recall: 0.5317\n",
            "Epoch 38/60\n",
            "46/46 [==============================] - 4s 95ms/step - loss: 0.4958 - accuracy: 0.8341 - f1: 0.8320 - precision: 0.8519 - recall: 0.8133 - val_loss: 1.4029 - val_accuracy: 0.5292 - val_f1: 0.5299 - val_precision: 0.5507 - val_recall: 0.5108\n",
            "Epoch 39/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.5270 - accuracy: 0.8194 - f1: 0.8158 - precision: 0.8370 - recall: 0.7961 - val_loss: 1.5260 - val_accuracy: 0.5283 - val_f1: 0.5262 - val_precision: 0.5446 - val_recall: 0.5092\n",
            "Epoch 40/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.6265 - accuracy: 0.7757 - f1: 0.7707 - precision: 0.7964 - recall: 0.7470 - val_loss: 1.3000 - val_accuracy: 0.5850 - val_f1: 0.5806 - val_precision: 0.6019 - val_recall: 0.5608\n",
            "Epoch 41/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.6355 - accuracy: 0.7645 - f1: 0.7575 - precision: 0.7895 - recall: 0.7283 - val_loss: 1.2837 - val_accuracy: 0.5633 - val_f1: 0.5594 - val_precision: 0.5815 - val_recall: 0.5392\n",
            "Epoch 42/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.6199 - accuracy: 0.7675 - f1: 0.7607 - precision: 0.7877 - recall: 0.7359 - val_loss: 1.2816 - val_accuracy: 0.5958 - val_f1: 0.5988 - val_precision: 0.6115 - val_recall: 0.5867\n",
            "Epoch 43/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.5260 - accuracy: 0.8101 - f1: 0.8052 - precision: 0.8264 - recall: 0.7854 - val_loss: 1.2608 - val_accuracy: 0.6100 - val_f1: 0.6060 - val_precision: 0.6250 - val_recall: 0.5883\n",
            "Epoch 44/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.5172 - accuracy: 0.8192 - f1: 0.8178 - precision: 0.8374 - recall: 0.7994 - val_loss: 1.1876 - val_accuracy: 0.6058 - val_f1: 0.6070 - val_precision: 0.6243 - val_recall: 0.5908\n",
            "Epoch 45/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.4825 - accuracy: 0.8423 - f1: 0.8401 - precision: 0.8635 - recall: 0.8181 - val_loss: 1.2808 - val_accuracy: 0.5833 - val_f1: 0.5848 - val_precision: 0.6032 - val_recall: 0.5675\n",
            "Epoch 46/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.4991 - accuracy: 0.8342 - f1: 0.8327 - precision: 0.8537 - recall: 0.8130 - val_loss: 1.2427 - val_accuracy: 0.5833 - val_f1: 0.5875 - val_precision: 0.6112 - val_recall: 0.5658\n",
            "Epoch 47/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.4046 - accuracy: 0.8745 - f1: 0.8747 - precision: 0.8903 - recall: 0.8599 - val_loss: 1.3852 - val_accuracy: 0.5850 - val_f1: 0.5820 - val_precision: 0.6005 - val_recall: 0.5650\n",
            "Epoch 48/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.3675 - accuracy: 0.8852 - f1: 0.8866 - precision: 0.8978 - recall: 0.8759 - val_loss: 1.3455 - val_accuracy: 0.5900 - val_f1: 0.5850 - val_precision: 0.6027 - val_recall: 0.5683\n",
            "Epoch 49/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.3736 - accuracy: 0.8875 - f1: 0.8859 - precision: 0.8982 - recall: 0.8740 - val_loss: 1.3852 - val_accuracy: 0.5975 - val_f1: 0.6017 - val_precision: 0.6131 - val_recall: 0.5908\n",
            "Epoch 50/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.3557 - accuracy: 0.8926 - f1: 0.8934 - precision: 0.9022 - recall: 0.8849 - val_loss: 1.5041 - val_accuracy: 0.5950 - val_f1: 0.5918 - val_precision: 0.6007 - val_recall: 0.5833\n",
            "Epoch 51/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.3286 - accuracy: 0.8995 - f1: 0.9015 - precision: 0.9086 - recall: 0.8946 - val_loss: 1.4094 - val_accuracy: 0.6058 - val_f1: 0.6078 - val_precision: 0.6186 - val_recall: 0.5975\n",
            "Epoch 52/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.3206 - accuracy: 0.9062 - f1: 0.9069 - precision: 0.9151 - recall: 0.8989 - val_loss: 1.4123 - val_accuracy: 0.6042 - val_f1: 0.6006 - val_precision: 0.6145 - val_recall: 0.5875\n",
            "Epoch 53/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.2921 - accuracy: 0.9174 - f1: 0.9165 - precision: 0.9253 - recall: 0.9079 - val_loss: 1.3970 - val_accuracy: 0.5917 - val_f1: 0.5939 - val_precision: 0.6115 - val_recall: 0.5775\n",
            "Epoch 54/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.3111 - accuracy: 0.9021 - f1: 0.9041 - precision: 0.9148 - recall: 0.8937 - val_loss: 1.3900 - val_accuracy: 0.5817 - val_f1: 0.5782 - val_precision: 0.5978 - val_recall: 0.5600\n",
            "Epoch 55/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.3547 - accuracy: 0.8937 - f1: 0.8931 - precision: 0.9028 - recall: 0.8837 - val_loss: 1.4208 - val_accuracy: 0.5925 - val_f1: 0.5928 - val_precision: 0.6063 - val_recall: 0.5800\n",
            "Epoch 56/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.2868 - accuracy: 0.9223 - f1: 0.9211 - precision: 0.9305 - recall: 0.9120 - val_loss: 1.4236 - val_accuracy: 0.6092 - val_f1: 0.6028 - val_precision: 0.6199 - val_recall: 0.5867\n",
            "Epoch 57/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.2883 - accuracy: 0.9208 - f1: 0.9206 - precision: 0.9294 - recall: 0.9121 - val_loss: 1.4486 - val_accuracy: 0.6050 - val_f1: 0.6094 - val_precision: 0.6200 - val_recall: 0.5992\n",
            "Epoch 58/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.2808 - accuracy: 0.9189 - f1: 0.9218 - precision: 0.9301 - recall: 0.9139 - val_loss: 1.5062 - val_accuracy: 0.5992 - val_f1: 0.5991 - val_precision: 0.6113 - val_recall: 0.5875\n",
            "Epoch 59/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.2834 - accuracy: 0.9212 - f1: 0.9199 - precision: 0.9300 - recall: 0.9101 - val_loss: 1.5309 - val_accuracy: 0.6100 - val_f1: 0.6060 - val_precision: 0.6184 - val_recall: 0.5942\n",
            "Epoch 60/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.2915 - accuracy: 0.9166 - f1: 0.9206 - precision: 0.9310 - recall: 0.9107 - val_loss: 1.4863 - val_accuracy: 0.6058 - val_f1: 0.6110 - val_precision: 0.6253 - val_recall: 0.5975\n",
            "14/14 [==============================] - 1s 77ms/step - loss: 1.5863 - accuracy: 0.5879 - f1: 0.5880 - precision: 0.6009 - recall: 0.5757\n",
            "[1.5863149166107178, 0.5878571271896362, 0.5879764556884766, 0.6009017825126648, 0.5757142305374146]\n",
            "SG_LSTM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJHtKjzc1SA8",
        "outputId": "6afcde47-297f-4213-9a66-25f713a6a251"
      },
      "source": [
        "model_sg_bi = tf.keras.Sequential()\r\n",
        "model_sg_bi.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_sg_bi.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64),merge_mode='concat'))\r\n",
        "model_sg_bi.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_sg_bi.add(tf.keras.layers.Dense(64,activation='relu'))\r\n",
        "model_sg_bi.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_sg_bi.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_sg_bi.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy',f1,precision,recall])\r\n",
        "history_sg_bi = model_sg_bi.fit_generator(sg_train_gen,validation_data=sg_val_gen,validation_steps=int((len(X_val)/batch_size)+1),steps_per_epoch=int((len(X_train)/batch_size)+1),epochs=epochs)\r\n",
        "history = model_sg_bi.evaluate(x = vec_gen(w2v_sg,vocab_sg,X_test,y_test,batch_size,Max_input_size,Embedding_size),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table[1]=history[1]\r\n",
        "print(\"SG_BI\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "46/46 [==============================] - 8s 113ms/step - loss: 1.3775 - accuracy: 0.3177 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3622 - val_accuracy: 0.3292 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 1.3532 - accuracy: 0.3291 - f1: 0.0017 - precision: 0.0642 - recall: 8.8184e-04 - val_loss: 1.3270 - val_accuracy: 0.3925 - val_f1: 0.0099 - val_precision: 0.4167 - val_recall: 0.0050\n",
            "Epoch 3/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.2811 - accuracy: 0.4204 - f1: 0.0988 - precision: 0.6624 - recall: 0.0553 - val_loss: 1.2765 - val_accuracy: 0.4208 - val_f1: 0.1303 - val_precision: 0.6568 - val_recall: 0.0733\n",
            "Epoch 4/60\n",
            "46/46 [==============================] - 4s 99ms/step - loss: 1.2134 - accuracy: 0.4596 - f1: 0.2211 - precision: 0.6896 - recall: 0.1358 - val_loss: 1.2385 - val_accuracy: 0.4408 - val_f1: 0.2803 - val_precision: 0.5761 - val_recall: 0.1858\n",
            "Epoch 5/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.1328 - accuracy: 0.5269 - f1: 0.3552 - precision: 0.6911 - recall: 0.2412 - val_loss: 1.2263 - val_accuracy: 0.4625 - val_f1: 0.3536 - val_precision: 0.5691 - val_recall: 0.2575\n",
            "Epoch 6/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 1.0742 - accuracy: 0.5580 - f1: 0.4257 - precision: 0.7113 - recall: 0.3072 - val_loss: 1.2358 - val_accuracy: 0.4842 - val_f1: 0.4045 - val_precision: 0.5706 - val_recall: 0.3142\n",
            "Epoch 7/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.0187 - accuracy: 0.5817 - f1: 0.4845 - precision: 0.7250 - recall: 0.3667 - val_loss: 1.2462 - val_accuracy: 0.4842 - val_f1: 0.4294 - val_precision: 0.5630 - val_recall: 0.3475\n",
            "Epoch 8/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.9656 - accuracy: 0.6129 - f1: 0.5464 - precision: 0.7389 - recall: 0.4349 - val_loss: 1.2423 - val_accuracy: 0.4950 - val_f1: 0.4309 - val_precision: 0.5570 - val_recall: 0.3517\n",
            "Epoch 9/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.9268 - accuracy: 0.6408 - f1: 0.5858 - precision: 0.7461 - recall: 0.4834 - val_loss: 1.2603 - val_accuracy: 0.4983 - val_f1: 0.4403 - val_precision: 0.5621 - val_recall: 0.3625\n",
            "Epoch 10/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.8836 - accuracy: 0.6621 - f1: 0.6072 - precision: 0.7624 - recall: 0.5055 - val_loss: 1.2752 - val_accuracy: 0.5142 - val_f1: 0.4643 - val_precision: 0.5664 - val_recall: 0.3942\n",
            "Epoch 11/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.8580 - accuracy: 0.6678 - f1: 0.6296 - precision: 0.7819 - recall: 0.5285 - val_loss: 1.2825 - val_accuracy: 0.5125 - val_f1: 0.4808 - val_precision: 0.5659 - val_recall: 0.4183\n",
            "Epoch 12/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.7919 - accuracy: 0.7010 - f1: 0.6646 - precision: 0.7919 - recall: 0.5737 - val_loss: 1.3221 - val_accuracy: 0.5158 - val_f1: 0.4863 - val_precision: 0.5763 - val_recall: 0.4208\n",
            "Epoch 13/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.7291 - accuracy: 0.7323 - f1: 0.7089 - precision: 0.8174 - recall: 0.6266 - val_loss: 1.3083 - val_accuracy: 0.5200 - val_f1: 0.5026 - val_precision: 0.5909 - val_recall: 0.4375\n",
            "Epoch 14/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.6782 - accuracy: 0.7541 - f1: 0.7328 - precision: 0.8281 - recall: 0.6580 - val_loss: 1.3356 - val_accuracy: 0.5150 - val_f1: 0.4892 - val_precision: 0.5722 - val_recall: 0.4275\n",
            "Epoch 15/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.6335 - accuracy: 0.7656 - f1: 0.7520 - precision: 0.8381 - recall: 0.6827 - val_loss: 1.3723 - val_accuracy: 0.5400 - val_f1: 0.5182 - val_precision: 0.5845 - val_recall: 0.4658\n",
            "Epoch 16/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.5760 - accuracy: 0.7983 - f1: 0.7859 - precision: 0.8568 - recall: 0.7266 - val_loss: 1.4255 - val_accuracy: 0.5467 - val_f1: 0.5293 - val_precision: 0.5915 - val_recall: 0.4792\n",
            "Epoch 17/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.5481 - accuracy: 0.7982 - f1: 0.7947 - precision: 0.8595 - recall: 0.7395 - val_loss: 1.4626 - val_accuracy: 0.5458 - val_f1: 0.5208 - val_precision: 0.5780 - val_recall: 0.4742\n",
            "Epoch 18/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.5202 - accuracy: 0.8166 - f1: 0.8050 - precision: 0.8692 - recall: 0.7503 - val_loss: 1.3943 - val_accuracy: 0.5775 - val_f1: 0.5585 - val_precision: 0.6070 - val_recall: 0.5175\n",
            "Epoch 19/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.4929 - accuracy: 0.8232 - f1: 0.8205 - precision: 0.8732 - recall: 0.7744 - val_loss: 1.3730 - val_accuracy: 0.5667 - val_f1: 0.5506 - val_precision: 0.6010 - val_recall: 0.5083\n",
            "Epoch 20/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.4480 - accuracy: 0.8505 - f1: 0.8459 - precision: 0.8901 - recall: 0.8060 - val_loss: 1.6708 - val_accuracy: 0.5575 - val_f1: 0.5356 - val_precision: 0.5714 - val_recall: 0.5042\n",
            "Epoch 21/60\n",
            "46/46 [==============================] - 5s 102ms/step - loss: 0.4577 - accuracy: 0.8377 - f1: 0.8344 - precision: 0.8728 - recall: 0.7996 - val_loss: 1.6389 - val_accuracy: 0.5542 - val_f1: 0.5456 - val_precision: 0.5826 - val_recall: 0.5133\n",
            "Epoch 22/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.4362 - accuracy: 0.8435 - f1: 0.8409 - precision: 0.8798 - recall: 0.8055 - val_loss: 1.5379 - val_accuracy: 0.5667 - val_f1: 0.5541 - val_precision: 0.5971 - val_recall: 0.5175\n",
            "Epoch 23/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.4115 - accuracy: 0.8566 - f1: 0.8524 - precision: 0.8846 - recall: 0.8227 - val_loss: 1.5845 - val_accuracy: 0.5592 - val_f1: 0.5495 - val_precision: 0.5840 - val_recall: 0.5192\n",
            "Epoch 24/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.3601 - accuracy: 0.8749 - f1: 0.8736 - precision: 0.9046 - recall: 0.8449 - val_loss: 1.6907 - val_accuracy: 0.5642 - val_f1: 0.5570 - val_precision: 0.5870 - val_recall: 0.5300\n",
            "Epoch 25/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.3311 - accuracy: 0.8744 - f1: 0.8741 - precision: 0.9037 - recall: 0.8466 - val_loss: 1.6666 - val_accuracy: 0.5717 - val_f1: 0.5567 - val_precision: 0.5854 - val_recall: 0.5308\n",
            "Epoch 26/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.2826 - accuracy: 0.8985 - f1: 0.8992 - precision: 0.9204 - recall: 0.8791 - val_loss: 1.8084 - val_accuracy: 0.5633 - val_f1: 0.5556 - val_precision: 0.5800 - val_recall: 0.5333\n",
            "Epoch 27/60\n",
            "46/46 [==============================] - 4s 99ms/step - loss: 0.2544 - accuracy: 0.9111 - f1: 0.9100 - precision: 0.9266 - recall: 0.8942 - val_loss: 1.7990 - val_accuracy: 0.5767 - val_f1: 0.5694 - val_precision: 0.5933 - val_recall: 0.5475\n",
            "Epoch 28/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.2322 - accuracy: 0.9244 - f1: 0.9237 - precision: 0.9395 - recall: 0.9085 - val_loss: 1.6711 - val_accuracy: 0.5950 - val_f1: 0.5910 - val_precision: 0.6128 - val_recall: 0.5708\n",
            "Epoch 29/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.2282 - accuracy: 0.9175 - f1: 0.9198 - precision: 0.9353 - recall: 0.9049 - val_loss: 1.8370 - val_accuracy: 0.5917 - val_f1: 0.5845 - val_precision: 0.6036 - val_recall: 0.5667\n",
            "Epoch 30/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.2077 - accuracy: 0.9310 - f1: 0.9328 - precision: 0.9480 - recall: 0.9182 - val_loss: 2.0522 - val_accuracy: 0.5817 - val_f1: 0.5775 - val_precision: 0.5934 - val_recall: 0.5625\n",
            "Epoch 31/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.2420 - accuracy: 0.9127 - f1: 0.9135 - precision: 0.9273 - recall: 0.9002 - val_loss: 1.9090 - val_accuracy: 0.5783 - val_f1: 0.5759 - val_precision: 0.5909 - val_recall: 0.5617\n",
            "Epoch 32/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.2108 - accuracy: 0.9245 - f1: 0.9236 - precision: 0.9379 - recall: 0.9100 - val_loss: 2.1503 - val_accuracy: 0.5975 - val_f1: 0.5954 - val_precision: 0.6127 - val_recall: 0.5792\n",
            "Epoch 33/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.2111 - accuracy: 0.9264 - f1: 0.9279 - precision: 0.9376 - recall: 0.9186 - val_loss: 1.9226 - val_accuracy: 0.5892 - val_f1: 0.5808 - val_precision: 0.6005 - val_recall: 0.5625\n",
            "Epoch 34/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.1797 - accuracy: 0.9386 - f1: 0.9367 - precision: 0.9478 - recall: 0.9260 - val_loss: 1.8674 - val_accuracy: 0.5883 - val_f1: 0.5792 - val_precision: 0.6000 - val_recall: 0.5600\n",
            "Epoch 35/60\n",
            "46/46 [==============================] - 5s 98ms/step - loss: 0.2299 - accuracy: 0.9195 - f1: 0.9132 - precision: 0.9307 - recall: 0.8966 - val_loss: 2.0290 - val_accuracy: 0.5917 - val_f1: 0.5901 - val_precision: 0.6042 - val_recall: 0.5767\n",
            "Epoch 36/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.1618 - accuracy: 0.9390 - f1: 0.9396 - precision: 0.9494 - recall: 0.9300 - val_loss: 2.1338 - val_accuracy: 0.6108 - val_f1: 0.6040 - val_precision: 0.6171 - val_recall: 0.5917\n",
            "Epoch 37/60\n",
            "46/46 [==============================] - 4s 99ms/step - loss: 0.1370 - accuracy: 0.9497 - f1: 0.9503 - precision: 0.9568 - recall: 0.9440 - val_loss: 2.1187 - val_accuracy: 0.6192 - val_f1: 0.6171 - val_precision: 0.6317 - val_recall: 0.6033\n",
            "Epoch 38/60\n",
            "46/46 [==============================] - 4s 99ms/step - loss: 0.1363 - accuracy: 0.9574 - f1: 0.9569 - precision: 0.9642 - recall: 0.9498 - val_loss: 2.3501 - val_accuracy: 0.5858 - val_f1: 0.5843 - val_precision: 0.5950 - val_recall: 0.5742\n",
            "Epoch 39/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.1392 - accuracy: 0.9540 - f1: 0.9543 - precision: 0.9609 - recall: 0.9479 - val_loss: 2.1565 - val_accuracy: 0.6108 - val_f1: 0.6134 - val_precision: 0.6258 - val_recall: 0.6017\n",
            "Epoch 40/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.1293 - accuracy: 0.9594 - f1: 0.9583 - precision: 0.9642 - recall: 0.9525 - val_loss: 2.2800 - val_accuracy: 0.6133 - val_f1: 0.6116 - val_precision: 0.6201 - val_recall: 0.6033\n",
            "Epoch 41/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.1300 - accuracy: 0.9542 - f1: 0.9554 - precision: 0.9605 - recall: 0.9505 - val_loss: 2.1277 - val_accuracy: 0.6067 - val_f1: 0.6090 - val_precision: 0.6211 - val_recall: 0.5975\n",
            "Epoch 42/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.1229 - accuracy: 0.9662 - f1: 0.9646 - precision: 0.9706 - recall: 0.9589 - val_loss: 2.4400 - val_accuracy: 0.5933 - val_f1: 0.5941 - val_precision: 0.6026 - val_recall: 0.5858\n",
            "Epoch 43/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.1050 - accuracy: 0.9659 - f1: 0.9649 - precision: 0.9699 - recall: 0.9599 - val_loss: 2.4001 - val_accuracy: 0.5850 - val_f1: 0.5869 - val_precision: 0.5958 - val_recall: 0.5783\n",
            "Epoch 44/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.1451 - accuracy: 0.9481 - f1: 0.9496 - precision: 0.9538 - recall: 0.9456 - val_loss: 2.3863 - val_accuracy: 0.5983 - val_f1: 0.5912 - val_precision: 0.6002 - val_recall: 0.5825\n",
            "Epoch 45/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.1258 - accuracy: 0.9578 - f1: 0.9592 - precision: 0.9642 - recall: 0.9543 - val_loss: 2.4323 - val_accuracy: 0.5925 - val_f1: 0.5904 - val_precision: 0.5995 - val_recall: 0.5817\n",
            "Epoch 46/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.1580 - accuracy: 0.9505 - f1: 0.9499 - precision: 0.9535 - recall: 0.9465 - val_loss: 2.2640 - val_accuracy: 0.5967 - val_f1: 0.5932 - val_precision: 0.6035 - val_recall: 0.5833\n",
            "Epoch 47/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.1449 - accuracy: 0.9514 - f1: 0.9504 - precision: 0.9567 - recall: 0.9443 - val_loss: 2.3048 - val_accuracy: 0.5800 - val_f1: 0.5799 - val_precision: 0.5904 - val_recall: 0.5700\n",
            "Epoch 48/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.1772 - accuracy: 0.9345 - f1: 0.9353 - precision: 0.9422 - recall: 0.9285 - val_loss: 2.2622 - val_accuracy: 0.5958 - val_f1: 0.5936 - val_precision: 0.6044 - val_recall: 0.5833\n",
            "Epoch 49/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.1204 - accuracy: 0.9606 - f1: 0.9594 - precision: 0.9651 - recall: 0.9538 - val_loss: 2.3791 - val_accuracy: 0.6025 - val_f1: 0.6001 - val_precision: 0.6098 - val_recall: 0.5908\n",
            "Epoch 50/60\n",
            "46/46 [==============================] - 4s 99ms/step - loss: 0.0996 - accuracy: 0.9641 - f1: 0.9651 - precision: 0.9673 - recall: 0.9629 - val_loss: 2.3953 - val_accuracy: 0.5917 - val_f1: 0.5916 - val_precision: 0.5967 - val_recall: 0.5867\n",
            "Epoch 51/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.0871 - accuracy: 0.9705 - f1: 0.9698 - precision: 0.9736 - recall: 0.9661 - val_loss: 2.4729 - val_accuracy: 0.5908 - val_f1: 0.5896 - val_precision: 0.5960 - val_recall: 0.5833\n",
            "Epoch 52/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.0905 - accuracy: 0.9676 - f1: 0.9674 - precision: 0.9714 - recall: 0.9634 - val_loss: 2.5167 - val_accuracy: 0.5950 - val_f1: 0.5896 - val_precision: 0.5978 - val_recall: 0.5817\n",
            "Epoch 53/60\n",
            "46/46 [==============================] - 5s 102ms/step - loss: 0.1007 - accuracy: 0.9665 - f1: 0.9651 - precision: 0.9673 - recall: 0.9629 - val_loss: 2.6642 - val_accuracy: 0.5842 - val_f1: 0.5829 - val_precision: 0.5893 - val_recall: 0.5767\n",
            "Epoch 54/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.0862 - accuracy: 0.9694 - f1: 0.9700 - precision: 0.9720 - recall: 0.9680 - val_loss: 2.6064 - val_accuracy: 0.5900 - val_f1: 0.5906 - val_precision: 0.5999 - val_recall: 0.5817\n",
            "Epoch 55/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.0952 - accuracy: 0.9684 - f1: 0.9683 - precision: 0.9709 - recall: 0.9658 - val_loss: 2.4000 - val_accuracy: 0.6083 - val_f1: 0.6093 - val_precision: 0.6147 - val_recall: 0.6042\n",
            "Epoch 56/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.0961 - accuracy: 0.9678 - f1: 0.9680 - precision: 0.9709 - recall: 0.9651 - val_loss: 2.3360 - val_accuracy: 0.5708 - val_f1: 0.5658 - val_precision: 0.5743 - val_recall: 0.5575\n",
            "Epoch 57/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.1944 - accuracy: 0.9347 - f1: 0.9356 - precision: 0.9419 - recall: 0.9294 - val_loss: 2.0420 - val_accuracy: 0.6025 - val_f1: 0.5978 - val_precision: 0.6050 - val_recall: 0.5908\n",
            "Epoch 58/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.1070 - accuracy: 0.9682 - f1: 0.9672 - precision: 0.9715 - recall: 0.9629 - val_loss: 2.1861 - val_accuracy: 0.6100 - val_f1: 0.6098 - val_precision: 0.6192 - val_recall: 0.6008\n",
            "Epoch 59/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.0948 - accuracy: 0.9688 - f1: 0.9681 - precision: 0.9711 - recall: 0.9653 - val_loss: 2.3251 - val_accuracy: 0.6075 - val_f1: 0.6079 - val_precision: 0.6160 - val_recall: 0.6000\n",
            "Epoch 60/60\n",
            "46/46 [==============================] - 4s 99ms/step - loss: 0.0932 - accuracy: 0.9687 - f1: 0.9693 - precision: 0.9739 - recall: 0.9649 - val_loss: 2.4427 - val_accuracy: 0.5950 - val_f1: 0.5960 - val_precision: 0.6039 - val_recall: 0.5883\n",
            "14/14 [==============================] - 1s 77ms/step - loss: 2.3253 - accuracy: 0.6257 - f1: 0.6273 - precision: 0.6364 - recall: 0.6186\n",
            "[2.3252761363983154, 0.6257143020629883, 0.627327024936676, 0.6363924741744995, 0.6185714602470398]\n",
            "SG_BI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opfhhYPH1VoL",
        "outputId": "620234de-f393-40c4-d15f-ea830b8b93c5"
      },
      "source": [
        "model_sg_rnn = tf.keras.Sequential()\r\n",
        "model_sg_rnn.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_sg_rnn.add(tf.keras.layers.SimpleRNN(64))\r\n",
        "model_sg_rnn.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_sg_rnn.add(tf.keras.layers.Dense(64,activation='relu'))\r\n",
        "model_sg_rnn.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_sg_rnn.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_sg_rnn.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy',f1,precision,recall])\r\n",
        "history_sg_rnn = model_sg_rnn.fit_generator(sg_train_gen,validation_data=sg_val_gen,validation_steps=int((len(X_val)/batch_size)+1),steps_per_epoch=int((len(X_train)/batch_size)+1),epochs=epochs)\r\n",
        "history = model_sg_rnn.evaluate(x = vec_gen(w2v_sg,vocab_sg,X_test,y_test,batch_size,Max_input_size,Embedding_size),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "\r\n",
        "result_table[2]=history[1]\r\n",
        "print(\"SG_RNN\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "46/46 [==============================] - 7s 130ms/step - loss: 1.3898 - accuracy: 0.2661 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3733 - val_accuracy: 0.3242 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 1.3830 - accuracy: 0.2934 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3706 - val_accuracy: 0.3300 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 1.3790 - accuracy: 0.3008 - f1: 2.0429e-04 - precision: 0.0052 - recall: 1.0465e-04 - val_loss: 1.3635 - val_accuracy: 0.3225 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 1.3650 - accuracy: 0.3274 - f1: 0.0073 - precision: 0.0993 - recall: 0.0038 - val_loss: 1.3830 - val_accuracy: 0.3233 - val_f1: 0.1066 - val_precision: 0.3429 - val_recall: 0.0633\n",
            "Epoch 5/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 1.3605 - accuracy: 0.3306 - f1: 0.0541 - precision: 0.2438 - recall: 0.0314 - val_loss: 1.3723 - val_accuracy: 0.3342 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 6/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 1.3713 - accuracy: 0.3077 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3702 - val_accuracy: 0.3392 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 7/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 1.3678 - accuracy: 0.3169 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3748 - val_accuracy: 0.3292 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 8/60\n",
            "46/46 [==============================] - 6s 123ms/step - loss: 1.3600 - accuracy: 0.3324 - f1: 0.0013 - precision: 0.0452 - recall: 6.7827e-04 - val_loss: 1.3767 - val_accuracy: 0.3142 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 9/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 1.3429 - accuracy: 0.3506 - f1: 0.0095 - precision: 0.2404 - recall: 0.0049 - val_loss: 1.3636 - val_accuracy: 0.3258 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 10/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 1.3392 - accuracy: 0.3642 - f1: 0.0250 - precision: 0.4154 - recall: 0.0132 - val_loss: 1.3659 - val_accuracy: 0.3275 - val_f1: 0.0049 - val_precision: 0.1667 - val_recall: 0.0025\n",
            "Epoch 11/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 1.3452 - accuracy: 0.3396 - f1: 0.0605 - precision: 0.5537 - recall: 0.0330 - val_loss: 1.3791 - val_accuracy: 0.3217 - val_f1: 0.0269 - val_precision: 0.3119 - val_recall: 0.0142\n",
            "Epoch 12/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 1.3251 - accuracy: 0.3642 - f1: 0.0649 - precision: 0.5485 - recall: 0.0348 - val_loss: 1.3686 - val_accuracy: 0.3392 - val_f1: 0.0252 - val_precision: 0.3284 - val_recall: 0.0133\n",
            "Epoch 13/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 1.2898 - accuracy: 0.3972 - f1: 0.1180 - precision: 0.5821 - recall: 0.0680 - val_loss: 1.3778 - val_accuracy: 0.3217 - val_f1: 0.0395 - val_precision: 0.4597 - val_recall: 0.0208\n",
            "Epoch 14/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 1.2776 - accuracy: 0.4142 - f1: 0.1556 - precision: 0.6064 - recall: 0.0930 - val_loss: 1.3797 - val_accuracy: 0.3267 - val_f1: 0.0298 - val_precision: 0.2875 - val_recall: 0.0158\n",
            "Epoch 15/60\n",
            "46/46 [==============================] - 6s 123ms/step - loss: 1.3048 - accuracy: 0.3996 - f1: 0.0943 - precision: 0.5205 - recall: 0.0533 - val_loss: 1.3645 - val_accuracy: 0.3150 - val_f1: 0.0353 - val_precision: 0.5389 - val_recall: 0.0183\n",
            "Epoch 16/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 1.2808 - accuracy: 0.4115 - f1: 0.1243 - precision: 0.5162 - recall: 0.0735 - val_loss: 1.3969 - val_accuracy: 0.2867 - val_f1: 0.0224 - val_precision: 0.3810 - val_recall: 0.0117\n",
            "Epoch 17/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 1.2848 - accuracy: 0.4081 - f1: 0.0765 - precision: 0.6215 - recall: 0.0421 - val_loss: 1.4462 - val_accuracy: 0.2675 - val_f1: 0.0603 - val_precision: 0.3225 - val_recall: 0.0333\n",
            "Epoch 18/60\n",
            "46/46 [==============================] - 6s 123ms/step - loss: 1.3077 - accuracy: 0.3931 - f1: 0.1509 - precision: 0.5097 - recall: 0.0895 - val_loss: 1.4096 - val_accuracy: 0.2883 - val_f1: 0.0438 - val_precision: 0.4565 - val_recall: 0.0233\n",
            "Epoch 19/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 1.3049 - accuracy: 0.3971 - f1: 0.1142 - precision: 0.5743 - recall: 0.0657 - val_loss: 1.4117 - val_accuracy: 0.2842 - val_f1: 0.0241 - val_precision: 0.3819 - val_recall: 0.0125\n",
            "Epoch 20/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 1.2707 - accuracy: 0.4224 - f1: 0.1213 - precision: 0.6275 - recall: 0.0685 - val_loss: 1.3972 - val_accuracy: 0.3083 - val_f1: 0.0599 - val_precision: 0.4240 - val_recall: 0.0325\n",
            "Epoch 21/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 1.3052 - accuracy: 0.3972 - f1: 0.1341 - precision: 0.5456 - recall: 0.0778 - val_loss: 1.4076 - val_accuracy: 0.3025 - val_f1: 0.0737 - val_precision: 0.4273 - val_recall: 0.0408\n",
            "Epoch 22/60\n",
            "46/46 [==============================] - 6s 123ms/step - loss: 1.2702 - accuracy: 0.4194 - f1: 0.1782 - precision: 0.5830 - recall: 0.1060 - val_loss: 1.4265 - val_accuracy: 0.3150 - val_f1: 0.1116 - val_precision: 0.3373 - val_recall: 0.0675\n",
            "Epoch 23/60\n",
            "46/46 [==============================] - 6s 127ms/step - loss: 1.2452 - accuracy: 0.4292 - f1: 0.2570 - precision: 0.6043 - recall: 0.1641 - val_loss: 1.4362 - val_accuracy: 0.3008 - val_f1: 0.1111 - val_precision: 0.3465 - val_recall: 0.0667\n",
            "Epoch 24/60\n",
            "46/46 [==============================] - 6s 126ms/step - loss: 1.2417 - accuracy: 0.4446 - f1: 0.2535 - precision: 0.5958 - recall: 0.1625 - val_loss: 1.4292 - val_accuracy: 0.3025 - val_f1: 0.1081 - val_precision: 0.3488 - val_recall: 0.0642\n",
            "Epoch 25/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 1.2174 - accuracy: 0.4569 - f1: 0.2790 - precision: 0.6055 - recall: 0.1827 - val_loss: 1.4143 - val_accuracy: 0.3233 - val_f1: 0.1522 - val_precision: 0.3745 - val_recall: 0.0958\n",
            "Epoch 26/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 1.2474 - accuracy: 0.4354 - f1: 0.2693 - precision: 0.5951 - recall: 0.1755 - val_loss: 1.4328 - val_accuracy: 0.3033 - val_f1: 0.1338 - val_precision: 0.3760 - val_recall: 0.0817\n",
            "Epoch 27/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 1.2730 - accuracy: 0.4138 - f1: 0.2179 - precision: 0.5415 - recall: 0.1376 - val_loss: 1.4180 - val_accuracy: 0.3075 - val_f1: 0.1170 - val_precision: 0.3870 - val_recall: 0.0692\n",
            "Epoch 28/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 1.2251 - accuracy: 0.4509 - f1: 0.2365 - precision: 0.5677 - recall: 0.1508 - val_loss: 1.4442 - val_accuracy: 0.3342 - val_f1: 0.1265 - val_precision: 0.3687 - val_recall: 0.0767\n",
            "Epoch 29/60\n",
            "46/46 [==============================] - 6s 123ms/step - loss: 1.2154 - accuracy: 0.4626 - f1: 0.2750 - precision: 0.5859 - recall: 0.1815 - val_loss: 1.4354 - val_accuracy: 0.3142 - val_f1: 0.1667 - val_precision: 0.3966 - val_recall: 0.1058\n",
            "Epoch 30/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 1.1510 - accuracy: 0.5098 - f1: 0.3508 - precision: 0.6418 - recall: 0.2429 - val_loss: 1.4608 - val_accuracy: 0.3100 - val_f1: 0.1869 - val_precision: 0.3592 - val_recall: 0.1267\n",
            "Epoch 31/60\n",
            "46/46 [==============================] - 6s 123ms/step - loss: 1.1168 - accuracy: 0.5169 - f1: 0.3971 - precision: 0.6421 - recall: 0.2884 - val_loss: 1.4983 - val_accuracy: 0.3092 - val_f1: 0.2048 - val_precision: 0.3514 - val_recall: 0.1450\n",
            "Epoch 32/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 1.1888 - accuracy: 0.4763 - f1: 0.3467 - precision: 0.6045 - recall: 0.2443 - val_loss: 1.5050 - val_accuracy: 0.2850 - val_f1: 0.1511 - val_precision: 0.2958 - val_recall: 0.1017\n",
            "Epoch 33/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 1.1739 - accuracy: 0.4914 - f1: 0.3614 - precision: 0.6149 - recall: 0.2572 - val_loss: 1.5418 - val_accuracy: 0.2858 - val_f1: 0.1607 - val_precision: 0.3002 - val_recall: 0.1100\n",
            "Epoch 34/60\n",
            "46/46 [==============================] - 6s 127ms/step - loss: 1.2884 - accuracy: 0.4205 - f1: 0.2447 - precision: 0.5003 - recall: 0.1643 - val_loss: 1.4971 - val_accuracy: 0.2842 - val_f1: 0.0998 - val_precision: 0.2834 - val_recall: 0.0608\n",
            "Epoch 35/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 1.2989 - accuracy: 0.3881 - f1: 0.1929 - precision: 0.4999 - recall: 0.1208 - val_loss: 1.4922 - val_accuracy: 0.2858 - val_f1: 0.0975 - val_precision: 0.2688 - val_recall: 0.0600\n",
            "Epoch 36/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 1.2876 - accuracy: 0.4091 - f1: 0.1925 - precision: 0.5349 - recall: 0.1191 - val_loss: 1.4370 - val_accuracy: 0.3150 - val_f1: 0.1198 - val_precision: 0.3623 - val_recall: 0.0725\n",
            "Epoch 37/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 1.1821 - accuracy: 0.4790 - f1: 0.3165 - precision: 0.6242 - recall: 0.2146 - val_loss: 1.4977 - val_accuracy: 0.3017 - val_f1: 0.1516 - val_precision: 0.3267 - val_recall: 0.0992\n",
            "Epoch 38/60\n",
            "46/46 [==============================] - 6s 126ms/step - loss: 1.1353 - accuracy: 0.5086 - f1: 0.3483 - precision: 0.6699 - recall: 0.2372 - val_loss: 1.5433 - val_accuracy: 0.2775 - val_f1: 0.1836 - val_precision: 0.3172 - val_recall: 0.1300\n",
            "Epoch 39/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 1.0899 - accuracy: 0.5357 - f1: 0.4340 - precision: 0.6722 - recall: 0.3222 - val_loss: 1.5530 - val_accuracy: 0.2867 - val_f1: 0.1973 - val_precision: 0.3213 - val_recall: 0.1425\n",
            "Epoch 40/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 1.1427 - accuracy: 0.4971 - f1: 0.3826 - precision: 0.6198 - recall: 0.2782 - val_loss: 1.5822 - val_accuracy: 0.2892 - val_f1: 0.2032 - val_precision: 0.3277 - val_recall: 0.1475\n",
            "Epoch 41/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 1.0521 - accuracy: 0.5514 - f1: 0.4543 - precision: 0.6672 - recall: 0.3465 - val_loss: 1.6131 - val_accuracy: 0.2817 - val_f1: 0.2032 - val_precision: 0.3174 - val_recall: 0.1500\n",
            "Epoch 42/60\n",
            "46/46 [==============================] - 6s 126ms/step - loss: 1.0669 - accuracy: 0.5406 - f1: 0.4557 - precision: 0.6716 - recall: 0.3462 - val_loss: 1.5907 - val_accuracy: 0.3067 - val_f1: 0.2149 - val_precision: 0.3226 - val_recall: 0.1617\n",
            "Epoch 43/60\n",
            "46/46 [==============================] - 6s 126ms/step - loss: 1.0699 - accuracy: 0.5413 - f1: 0.4596 - precision: 0.6471 - recall: 0.3576 - val_loss: 1.6445 - val_accuracy: 0.3008 - val_f1: 0.2151 - val_precision: 0.3170 - val_recall: 0.1633\n",
            "Epoch 44/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 1.0374 - accuracy: 0.5667 - f1: 0.4894 - precision: 0.6713 - recall: 0.3866 - val_loss: 1.6960 - val_accuracy: 0.2900 - val_f1: 0.2194 - val_precision: 0.3053 - val_recall: 0.1717\n",
            "Epoch 45/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 1.1364 - accuracy: 0.5130 - f1: 0.4442 - precision: 0.6191 - recall: 0.3481 - val_loss: 1.5841 - val_accuracy: 0.3083 - val_f1: 0.2216 - val_precision: 0.3295 - val_recall: 0.1675\n",
            "Epoch 46/60\n",
            "46/46 [==============================] - 6s 123ms/step - loss: 1.0385 - accuracy: 0.5612 - f1: 0.4882 - precision: 0.6652 - recall: 0.3866 - val_loss: 1.6815 - val_accuracy: 0.2892 - val_f1: 0.2344 - val_precision: 0.3274 - val_recall: 0.1833\n",
            "Epoch 47/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 1.0200 - accuracy: 0.5809 - f1: 0.5137 - precision: 0.6675 - recall: 0.4184 - val_loss: 1.6888 - val_accuracy: 0.3033 - val_f1: 0.2544 - val_precision: 0.3496 - val_recall: 0.2008\n",
            "Epoch 48/60\n",
            "46/46 [==============================] - 6s 126ms/step - loss: 1.0030 - accuracy: 0.5877 - f1: 0.5234 - precision: 0.6781 - recall: 0.4272 - val_loss: 1.6902 - val_accuracy: 0.3158 - val_f1: 0.2491 - val_precision: 0.3359 - val_recall: 0.1983\n",
            "Epoch 49/60\n",
            "46/46 [==============================] - 6s 126ms/step - loss: 1.1252 - accuracy: 0.5164 - f1: 0.4463 - precision: 0.6104 - recall: 0.3524 - val_loss: 1.5831 - val_accuracy: 0.3050 - val_f1: 0.2309 - val_precision: 0.3467 - val_recall: 0.1733\n",
            "Epoch 50/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 1.0601 - accuracy: 0.5563 - f1: 0.4765 - precision: 0.6583 - recall: 0.3744 - val_loss: 1.5898 - val_accuracy: 0.2925 - val_f1: 0.2021 - val_precision: 0.3115 - val_recall: 0.1500\n",
            "Epoch 51/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 1.0619 - accuracy: 0.5416 - f1: 0.4665 - precision: 0.6547 - recall: 0.3631 - val_loss: 1.6204 - val_accuracy: 0.2850 - val_f1: 0.2143 - val_precision: 0.3321 - val_recall: 0.1583\n",
            "Epoch 52/60\n",
            "46/46 [==============================] - 6s 127ms/step - loss: 0.9900 - accuracy: 0.5990 - f1: 0.5134 - precision: 0.6907 - recall: 0.4106 - val_loss: 1.6870 - val_accuracy: 0.2967 - val_f1: 0.2274 - val_precision: 0.3171 - val_recall: 0.1775\n",
            "Epoch 53/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 0.9315 - accuracy: 0.6273 - f1: 0.5779 - precision: 0.7271 - recall: 0.4816 - val_loss: 1.7322 - val_accuracy: 0.2925 - val_f1: 0.2369 - val_precision: 0.3130 - val_recall: 0.1908\n",
            "Epoch 54/60\n",
            "46/46 [==============================] - 6s 128ms/step - loss: 0.9429 - accuracy: 0.6136 - f1: 0.5737 - precision: 0.7111 - recall: 0.4816 - val_loss: 1.7469 - val_accuracy: 0.2975 - val_f1: 0.2369 - val_precision: 0.3156 - val_recall: 0.1900\n",
            "Epoch 55/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 0.9964 - accuracy: 0.5783 - f1: 0.5200 - precision: 0.6775 - recall: 0.4228 - val_loss: 1.6978 - val_accuracy: 0.3008 - val_f1: 0.2206 - val_precision: 0.3040 - val_recall: 0.1733\n",
            "Epoch 56/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 1.0208 - accuracy: 0.5734 - f1: 0.5148 - precision: 0.6772 - recall: 0.4158 - val_loss: 1.6846 - val_accuracy: 0.3092 - val_f1: 0.2507 - val_precision: 0.3390 - val_recall: 0.1992\n",
            "Epoch 57/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 0.9180 - accuracy: 0.6325 - f1: 0.5751 - precision: 0.7224 - recall: 0.4788 - val_loss: 1.7390 - val_accuracy: 0.3092 - val_f1: 0.2467 - val_precision: 0.3254 - val_recall: 0.1992\n",
            "Epoch 58/60\n",
            "46/46 [==============================] - 6s 126ms/step - loss: 0.9508 - accuracy: 0.6128 - f1: 0.5590 - precision: 0.7085 - recall: 0.4629 - val_loss: 1.7153 - val_accuracy: 0.3167 - val_f1: 0.2589 - val_precision: 0.3394 - val_recall: 0.2100\n",
            "Epoch 59/60\n",
            "46/46 [==============================] - 6s 127ms/step - loss: 0.9437 - accuracy: 0.6051 - f1: 0.5594 - precision: 0.7131 - recall: 0.4618 - val_loss: 1.7754 - val_accuracy: 0.3042 - val_f1: 0.2522 - val_precision: 0.3242 - val_recall: 0.2067\n",
            "Epoch 60/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 0.8684 - accuracy: 0.6424 - f1: 0.5927 - precision: 0.7347 - recall: 0.4979 - val_loss: 1.8458 - val_accuracy: 0.3167 - val_f1: 0.2674 - val_precision: 0.3345 - val_recall: 0.2233\n",
            "14/14 [==============================] - 1s 75ms/step - loss: 1.7921 - accuracy: 0.3300 - f1: 0.2858 - precision: 0.3559 - recall: 0.2393\n",
            "[1.792137622833252, 0.33000001311302185, 0.28581157326698303, 0.3559053838253021, 0.23928572237491608]\n",
            "SG_RNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YumD1M9Y1Xxr",
        "outputId": "9a1d42d4-c8b6-47a2-d9fa-4ff7bee659c9"
      },
      "source": [
        "model_cbow = tf.keras.Sequential()\r\n",
        "model_cbow.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_cbow.add(tf.keras.layers.LSTM(64))\r\n",
        "model_cbow.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_cbow.add(tf.keras.layers.Dense(64,activation='relu'))\r\n",
        "model_cbow.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_cbow.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_cbow.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy',f1,precision,recall])\r\n",
        "cbow_train_gen=vec_gen(w2v_cbow,vocab_cbow,X_train,y_train,batch_size,Max_input_size,Embedding_size)\r\n",
        "cbow_val_gen=vec_gen(w2v_cbow,vocab_cbow,X_val,y_val,batch_size,Max_input_size,Embedding_size)\r\n",
        "history_cbow_lstm = model_cbow.fit_generator(cbow_train_gen,validation_data=cbow_val_gen,validation_steps=int((len(X_val)/batch_size)+1),steps_per_epoch=int((len(X_train)/batch_size)+1),epochs=epochs)\r\n",
        "history = model_cbow.evaluate(x = vec_gen(w2v_cbow,vocab_cbow,X_test,y_test,batch_size,Max_input_size,Embedding_size),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table[3]=history[1]\r\n",
        "print(\"CBOW_LSTM\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "46/46 [==============================] - 6s 106ms/step - loss: 1.3816 - accuracy: 0.3078 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3724 - val_accuracy: 0.3300 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.3775 - accuracy: 0.3054 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3697 - val_accuracy: 0.3367 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.3764 - accuracy: 0.3105 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3703 - val_accuracy: 0.3333 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 1.3744 - accuracy: 0.3164 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3707 - val_accuracy: 0.3350 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 5/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.3708 - accuracy: 0.3185 - f1: 0.0222 - precision: 0.0732 - recall: 0.0136 - val_loss: 1.3540 - val_accuracy: 0.3583 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 6/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.3385 - accuracy: 0.3591 - f1: 0.0562 - precision: 0.2646 - recall: 0.0340 - val_loss: 1.3389 - val_accuracy: 0.3692 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 7/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.3045 - accuracy: 0.3863 - f1: 0.1061 - precision: 0.6117 - recall: 0.0627 - val_loss: 1.3339 - val_accuracy: 0.3583 - val_f1: 0.2117 - val_precision: 0.5048 - val_recall: 0.1342\n",
            "Epoch 8/60\n",
            "46/46 [==============================] - 4s 95ms/step - loss: 1.2865 - accuracy: 0.3826 - f1: 0.1832 - precision: 0.6471 - recall: 0.1106 - val_loss: 1.3126 - val_accuracy: 0.3767 - val_f1: 0.2107 - val_precision: 0.5323 - val_recall: 0.1317\n",
            "Epoch 9/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.2916 - accuracy: 0.3755 - f1: 0.1957 - precision: 0.6027 - recall: 0.1199 - val_loss: 1.3211 - val_accuracy: 0.3375 - val_f1: 0.1899 - val_precision: 0.5283 - val_recall: 0.1158\n",
            "Epoch 10/60\n",
            "46/46 [==============================] - 4s 95ms/step - loss: 1.2958 - accuracy: 0.3693 - f1: 0.1872 - precision: 0.6287 - recall: 0.1132 - val_loss: 1.3163 - val_accuracy: 0.3758 - val_f1: 0.2339 - val_precision: 0.5149 - val_recall: 0.1517\n",
            "Epoch 11/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.2632 - accuracy: 0.3995 - f1: 0.2186 - precision: 0.6395 - recall: 0.1361 - val_loss: 1.3148 - val_accuracy: 0.3625 - val_f1: 0.2035 - val_precision: 0.5541 - val_recall: 0.1250\n",
            "Epoch 12/60\n",
            "46/46 [==============================] - 4s 95ms/step - loss: 1.2576 - accuracy: 0.4099 - f1: 0.2399 - precision: 0.6617 - recall: 0.1498 - val_loss: 1.3194 - val_accuracy: 0.3575 - val_f1: 0.2217 - val_precision: 0.5478 - val_recall: 0.1392\n",
            "Epoch 13/60\n",
            "46/46 [==============================] - 4s 95ms/step - loss: 1.2674 - accuracy: 0.4055 - f1: 0.1919 - precision: 0.6380 - recall: 0.1207 - val_loss: 1.3150 - val_accuracy: 0.3675 - val_f1: 0.2080 - val_precision: 0.5521 - val_recall: 0.1283\n",
            "Epoch 14/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.2733 - accuracy: 0.3997 - f1: 0.1882 - precision: 0.6770 - recall: 0.1181 - val_loss: 1.3332 - val_accuracy: 0.3742 - val_f1: 0.2724 - val_precision: 0.4953 - val_recall: 0.1883\n",
            "Epoch 15/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.2551 - accuracy: 0.4211 - f1: 0.2356 - precision: 0.6295 - recall: 0.1494 - val_loss: 1.3390 - val_accuracy: 0.3825 - val_f1: 0.2841 - val_precision: 0.4889 - val_recall: 0.2008\n",
            "Epoch 16/60\n",
            "46/46 [==============================] - 4s 95ms/step - loss: 1.2675 - accuracy: 0.4228 - f1: 0.1998 - precision: 0.6213 - recall: 0.1260 - val_loss: 1.3219 - val_accuracy: 0.3950 - val_f1: 0.2787 - val_precision: 0.4798 - val_recall: 0.1975\n",
            "Epoch 17/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.2403 - accuracy: 0.4290 - f1: 0.2814 - precision: 0.6126 - recall: 0.1855 - val_loss: 1.3521 - val_accuracy: 0.3733 - val_f1: 0.2872 - val_precision: 0.4567 - val_recall: 0.2108\n",
            "Epoch 18/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.2349 - accuracy: 0.4349 - f1: 0.2848 - precision: 0.6026 - recall: 0.1892 - val_loss: 1.3351 - val_accuracy: 0.3592 - val_f1: 0.2443 - val_precision: 0.5021 - val_recall: 0.1617\n",
            "Epoch 19/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.2215 - accuracy: 0.4389 - f1: 0.2831 - precision: 0.6506 - recall: 0.1828 - val_loss: 1.3367 - val_accuracy: 0.3683 - val_f1: 0.2628 - val_precision: 0.5021 - val_recall: 0.1783\n",
            "Epoch 20/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.2074 - accuracy: 0.4502 - f1: 0.2824 - precision: 0.6445 - recall: 0.1832 - val_loss: 1.3378 - val_accuracy: 0.3675 - val_f1: 0.2570 - val_precision: 0.5078 - val_recall: 0.1725\n",
            "Epoch 21/60\n",
            "46/46 [==============================] - 4s 95ms/step - loss: 1.1996 - accuracy: 0.4514 - f1: 0.3028 - precision: 0.6401 - recall: 0.2004 - val_loss: 1.3453 - val_accuracy: 0.3767 - val_f1: 0.2871 - val_precision: 0.4963 - val_recall: 0.2025\n",
            "Epoch 22/60\n",
            "46/46 [==============================] - 4s 99ms/step - loss: 1.1687 - accuracy: 0.4617 - f1: 0.3297 - precision: 0.6530 - recall: 0.2221 - val_loss: 1.3370 - val_accuracy: 0.3800 - val_f1: 0.2902 - val_precision: 0.5058 - val_recall: 0.2042\n",
            "Epoch 23/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.1600 - accuracy: 0.4705 - f1: 0.3486 - precision: 0.6341 - recall: 0.2424 - val_loss: 1.3459 - val_accuracy: 0.3933 - val_f1: 0.3029 - val_precision: 0.4805 - val_recall: 0.2217\n",
            "Epoch 24/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 1.1733 - accuracy: 0.4612 - f1: 0.3342 - precision: 0.6457 - recall: 0.2288 - val_loss: 1.3725 - val_accuracy: 0.4175 - val_f1: 0.4015 - val_precision: 0.4865 - val_recall: 0.3425\n",
            "Epoch 25/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 1.1321 - accuracy: 0.4991 - f1: 0.4024 - precision: 0.6453 - recall: 0.3022 - val_loss: 1.3773 - val_accuracy: 0.4017 - val_f1: 0.3809 - val_precision: 0.4614 - val_recall: 0.3250\n",
            "Epoch 26/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.1221 - accuracy: 0.4919 - f1: 0.4035 - precision: 0.6519 - recall: 0.3005 - val_loss: 1.3453 - val_accuracy: 0.4250 - val_f1: 0.3884 - val_precision: 0.5089 - val_recall: 0.3150\n",
            "Epoch 27/60\n",
            "46/46 [==============================] - 4s 95ms/step - loss: 1.0840 - accuracy: 0.5261 - f1: 0.4492 - precision: 0.6696 - recall: 0.3412 - val_loss: 1.4129 - val_accuracy: 0.4133 - val_f1: 0.3840 - val_precision: 0.4874 - val_recall: 0.3175\n",
            "Epoch 28/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 1.0477 - accuracy: 0.5468 - f1: 0.4714 - precision: 0.7035 - recall: 0.3590 - val_loss: 1.4130 - val_accuracy: 0.4117 - val_f1: 0.3852 - val_precision: 0.4810 - val_recall: 0.3217\n",
            "Epoch 29/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.0444 - accuracy: 0.5530 - f1: 0.4501 - precision: 0.7090 - recall: 0.3344 - val_loss: 1.3446 - val_accuracy: 0.4383 - val_f1: 0.3566 - val_precision: 0.5482 - val_recall: 0.2650\n",
            "Epoch 30/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 1.0242 - accuracy: 0.5782 - f1: 0.4823 - precision: 0.7260 - recall: 0.3640 - val_loss: 1.2822 - val_accuracy: 0.4558 - val_f1: 0.3430 - val_precision: 0.6310 - val_recall: 0.2367\n",
            "Epoch 31/60\n",
            "46/46 [==============================] - 4s 95ms/step - loss: 0.9724 - accuracy: 0.6044 - f1: 0.4985 - precision: 0.7642 - recall: 0.3721 - val_loss: 1.2776 - val_accuracy: 0.4558 - val_f1: 0.3836 - val_precision: 0.6021 - val_recall: 0.2833\n",
            "Epoch 32/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.9148 - accuracy: 0.6378 - f1: 0.5405 - precision: 0.7523 - recall: 0.4230 - val_loss: 1.2758 - val_accuracy: 0.4792 - val_f1: 0.4036 - val_precision: 0.6130 - val_recall: 0.3025\n",
            "Epoch 33/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.9174 - accuracy: 0.6395 - f1: 0.5717 - precision: 0.7427 - recall: 0.4662 - val_loss: 1.3348 - val_accuracy: 0.4717 - val_f1: 0.4190 - val_precision: 0.5579 - val_recall: 0.3367\n",
            "Epoch 34/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.9650 - accuracy: 0.6080 - f1: 0.5519 - precision: 0.7159 - recall: 0.4506 - val_loss: 1.3190 - val_accuracy: 0.4883 - val_f1: 0.4374 - val_precision: 0.5798 - val_recall: 0.3525\n",
            "Epoch 35/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.8900 - accuracy: 0.6572 - f1: 0.5833 - precision: 0.7410 - recall: 0.4830 - val_loss: 1.2773 - val_accuracy: 0.4817 - val_f1: 0.4361 - val_precision: 0.5537 - val_recall: 0.3608\n",
            "Epoch 36/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.8297 - accuracy: 0.6886 - f1: 0.6374 - precision: 0.7603 - recall: 0.5504 - val_loss: 1.3501 - val_accuracy: 0.4758 - val_f1: 0.4619 - val_precision: 0.5126 - val_recall: 0.4208\n",
            "Epoch 37/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.8149 - accuracy: 0.6882 - f1: 0.6531 - precision: 0.7429 - recall: 0.5835 - val_loss: 1.2934 - val_accuracy: 0.5117 - val_f1: 0.5077 - val_precision: 0.5469 - val_recall: 0.4742\n",
            "Epoch 38/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.8520 - accuracy: 0.6747 - f1: 0.6528 - precision: 0.7124 - recall: 0.6036 - val_loss: 1.2604 - val_accuracy: 0.5283 - val_f1: 0.5192 - val_precision: 0.5794 - val_recall: 0.4708\n",
            "Epoch 39/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.8713 - accuracy: 0.6611 - f1: 0.6429 - precision: 0.7023 - recall: 0.5935 - val_loss: 1.2871 - val_accuracy: 0.3833 - val_f1: 0.2533 - val_precision: 0.5187 - val_recall: 0.1692\n",
            "Epoch 40/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 1.0382 - accuracy: 0.5296 - f1: 0.4030 - precision: 0.6617 - recall: 0.2927 - val_loss: 1.2072 - val_accuracy: 0.4525 - val_f1: 0.3664 - val_precision: 0.5648 - val_recall: 0.2717\n",
            "Epoch 41/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.9018 - accuracy: 0.6053 - f1: 0.5197 - precision: 0.7197 - recall: 0.4082 - val_loss: 1.2202 - val_accuracy: 0.4700 - val_f1: 0.4059 - val_precision: 0.5495 - val_recall: 0.3225\n",
            "Epoch 42/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.8251 - accuracy: 0.6495 - f1: 0.5875 - precision: 0.7253 - recall: 0.4962 - val_loss: 1.2006 - val_accuracy: 0.4858 - val_f1: 0.4535 - val_precision: 0.5289 - val_recall: 0.3975\n",
            "Epoch 43/60\n",
            "46/46 [==============================] - 4s 95ms/step - loss: 0.7778 - accuracy: 0.6874 - f1: 0.6595 - precision: 0.7382 - recall: 0.5973 - val_loss: 1.2069 - val_accuracy: 0.4917 - val_f1: 0.4788 - val_precision: 0.5340 - val_recall: 0.4342\n",
            "Epoch 44/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.7440 - accuracy: 0.7129 - f1: 0.6918 - precision: 0.7496 - recall: 0.6430 - val_loss: 1.2006 - val_accuracy: 0.4975 - val_f1: 0.4843 - val_precision: 0.5221 - val_recall: 0.4517\n",
            "Epoch 45/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.7407 - accuracy: 0.7099 - f1: 0.6953 - precision: 0.7442 - recall: 0.6533 - val_loss: 1.2201 - val_accuracy: 0.5200 - val_f1: 0.5112 - val_precision: 0.5437 - val_recall: 0.4825\n",
            "Epoch 46/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.7007 - accuracy: 0.7301 - f1: 0.7203 - precision: 0.7607 - recall: 0.6845 - val_loss: 1.1725 - val_accuracy: 0.5258 - val_f1: 0.5091 - val_precision: 0.5412 - val_recall: 0.4808\n",
            "Epoch 47/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.6798 - accuracy: 0.7431 - f1: 0.7249 - precision: 0.7726 - recall: 0.6835 - val_loss: 1.2773 - val_accuracy: 0.5150 - val_f1: 0.5079 - val_precision: 0.5284 - val_recall: 0.4892\n",
            "Epoch 48/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.6638 - accuracy: 0.7508 - f1: 0.7433 - precision: 0.7715 - recall: 0.7174 - val_loss: 1.3095 - val_accuracy: 0.5500 - val_f1: 0.5469 - val_precision: 0.5642 - val_recall: 0.5308\n",
            "Epoch 49/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.6374 - accuracy: 0.7662 - f1: 0.7567 - precision: 0.7831 - recall: 0.7324 - val_loss: 1.3642 - val_accuracy: 0.5508 - val_f1: 0.5441 - val_precision: 0.5546 - val_recall: 0.5342\n",
            "Epoch 50/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.5881 - accuracy: 0.7931 - f1: 0.7889 - precision: 0.8091 - recall: 0.7699 - val_loss: 1.4332 - val_accuracy: 0.5383 - val_f1: 0.5330 - val_precision: 0.5439 - val_recall: 0.5225\n",
            "Epoch 51/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.5770 - accuracy: 0.8019 - f1: 0.8010 - precision: 0.8131 - recall: 0.7893 - val_loss: 1.3356 - val_accuracy: 0.5158 - val_f1: 0.5192 - val_precision: 0.5352 - val_recall: 0.5042\n",
            "Epoch 52/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.6079 - accuracy: 0.7868 - f1: 0.7806 - precision: 0.7989 - recall: 0.7633 - val_loss: 1.3969 - val_accuracy: 0.5117 - val_f1: 0.5084 - val_precision: 0.5218 - val_recall: 0.4958\n",
            "Epoch 53/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.5375 - accuracy: 0.8218 - f1: 0.8186 - precision: 0.8319 - recall: 0.8057 - val_loss: 1.4659 - val_accuracy: 0.5158 - val_f1: 0.5042 - val_precision: 0.5184 - val_recall: 0.4908\n",
            "Epoch 54/60\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 0.5509 - accuracy: 0.8121 - f1: 0.8059 - precision: 0.8184 - recall: 0.7939 - val_loss: 1.4392 - val_accuracy: 0.4983 - val_f1: 0.5015 - val_precision: 0.5147 - val_recall: 0.4892\n",
            "Epoch 55/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.5999 - accuracy: 0.7840 - f1: 0.7835 - precision: 0.7978 - recall: 0.7698 - val_loss: 1.3876 - val_accuracy: 0.5050 - val_f1: 0.4957 - val_precision: 0.5117 - val_recall: 0.4808\n",
            "Epoch 56/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 0.5826 - accuracy: 0.7943 - f1: 0.7906 - precision: 0.8090 - recall: 0.7731 - val_loss: 1.2668 - val_accuracy: 0.5333 - val_f1: 0.5328 - val_precision: 0.5448 - val_recall: 0.5217\n",
            "Epoch 57/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.4985 - accuracy: 0.8373 - f1: 0.8330 - precision: 0.8480 - recall: 0.8187 - val_loss: 1.3929 - val_accuracy: 0.5483 - val_f1: 0.5484 - val_precision: 0.5571 - val_recall: 0.5400\n",
            "Epoch 58/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.4971 - accuracy: 0.8378 - f1: 0.8349 - precision: 0.8466 - recall: 0.8236 - val_loss: 1.4219 - val_accuracy: 0.5400 - val_f1: 0.5343 - val_precision: 0.5459 - val_recall: 0.5233\n",
            "Epoch 59/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.5082 - accuracy: 0.8412 - f1: 0.8384 - precision: 0.8513 - recall: 0.8260 - val_loss: 1.3193 - val_accuracy: 0.5500 - val_f1: 0.5485 - val_precision: 0.5609 - val_recall: 0.5367\n",
            "Epoch 60/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.5555 - accuracy: 0.8155 - f1: 0.8130 - precision: 0.8267 - recall: 0.7999 - val_loss: 1.4261 - val_accuracy: 0.4775 - val_f1: 0.4676 - val_precision: 0.4917 - val_recall: 0.4458\n",
            "14/14 [==============================] - 1s 75ms/step - loss: 1.3929 - accuracy: 0.4886 - f1: 0.4810 - precision: 0.5070 - recall: 0.4579\n",
            "[1.3928663730621338, 0.488571435213089, 0.48104196786880493, 0.5069935917854309, 0.4578571319580078]\n",
            "CBOW_LSTM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01yVMiF41ZtT",
        "outputId": "7734351c-223a-4f9b-8a0b-c8afcb2807df"
      },
      "source": [
        "model_cbow_bi = tf.keras.Sequential()\r\n",
        "model_cbow_bi.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_cbow_bi.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64),merge_mode='concat'))\r\n",
        "model_cbow_bi.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_cbow_bi.add(tf.keras.layers.Dense(64,activation='relu'))\r\n",
        "model_cbow_bi.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_cbow_bi.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_cbow_bi.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy',f1,precision,recall])\r\n",
        "history_cbow_bi = model_cbow_bi.fit_generator(cbow_train_gen,validation_data=cbow_val_gen,validation_steps=int((len(X_val)/batch_size)+1),steps_per_epoch=int((len(X_train)/batch_size)+1),epochs=epochs)\r\n",
        "history = model_cbow_bi.evaluate(x = vec_gen(w2v_cbow,vocab_cbow,X_test,y_test,batch_size,Max_input_size,Embedding_size),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table[4]=history[1]\r\n",
        "print(\"CBOW_BI\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "46/46 [==============================] - 8s 115ms/step - loss: 1.3774 - accuracy: 0.3183 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3548 - val_accuracy: 0.3558 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 1.3331 - accuracy: 0.3653 - f1: 0.0119 - precision: 0.2218 - recall: 0.0062 - val_loss: 1.3284 - val_accuracy: 0.3817 - val_f1: 0.0879 - val_precision: 0.5748 - val_recall: 0.0483\n",
            "Epoch 3/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 1.2785 - accuracy: 0.4064 - f1: 0.0769 - precision: 0.7568 - recall: 0.0417 - val_loss: 1.2828 - val_accuracy: 0.3992 - val_f1: 0.1211 - val_precision: 0.6015 - val_recall: 0.0683\n",
            "Epoch 4/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 1.2035 - accuracy: 0.4680 - f1: 0.1857 - precision: 0.6737 - recall: 0.1095 - val_loss: 1.2534 - val_accuracy: 0.4242 - val_f1: 0.2065 - val_precision: 0.6295 - val_recall: 0.1250\n",
            "Epoch 5/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 1.1350 - accuracy: 0.5217 - f1: 0.3058 - precision: 0.7003 - recall: 0.1992 - val_loss: 1.2311 - val_accuracy: 0.4333 - val_f1: 0.3121 - val_precision: 0.5480 - val_recall: 0.2192\n",
            "Epoch 6/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1.0780 - accuracy: 0.5511 - f1: 0.4202 - precision: 0.6965 - recall: 0.3039 - val_loss: 1.2252 - val_accuracy: 0.4633 - val_f1: 0.3723 - val_precision: 0.5498 - val_recall: 0.2825\n",
            "Epoch 7/60\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 1.0314 - accuracy: 0.5747 - f1: 0.4784 - precision: 0.6946 - recall: 0.3673 - val_loss: 1.2049 - val_accuracy: 0.4725 - val_f1: 0.4027 - val_precision: 0.5729 - val_recall: 0.3117\n",
            "Epoch 8/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.9744 - accuracy: 0.6132 - f1: 0.5324 - precision: 0.7285 - recall: 0.4219 - val_loss: 1.2531 - val_accuracy: 0.5000 - val_f1: 0.4478 - val_precision: 0.5585 - val_recall: 0.3750\n",
            "Epoch 9/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.9346 - accuracy: 0.6335 - f1: 0.5803 - precision: 0.7384 - recall: 0.4795 - val_loss: 1.2779 - val_accuracy: 0.4900 - val_f1: 0.4614 - val_precision: 0.5577 - val_recall: 0.3942\n",
            "Epoch 10/60\n",
            "46/46 [==============================] - 4s 99ms/step - loss: 0.8641 - accuracy: 0.6711 - f1: 0.6199 - precision: 0.7582 - recall: 0.5257 - val_loss: 1.2431 - val_accuracy: 0.5067 - val_f1: 0.4682 - val_precision: 0.5573 - val_recall: 0.4042\n",
            "Epoch 11/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.8085 - accuracy: 0.6812 - f1: 0.6475 - precision: 0.7753 - recall: 0.5566 - val_loss: 1.2853 - val_accuracy: 0.5183 - val_f1: 0.4865 - val_precision: 0.5754 - val_recall: 0.4225\n",
            "Epoch 12/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.7550 - accuracy: 0.7070 - f1: 0.6780 - precision: 0.7997 - recall: 0.5894 - val_loss: 1.3446 - val_accuracy: 0.5167 - val_f1: 0.5014 - val_precision: 0.5692 - val_recall: 0.4483\n",
            "Epoch 13/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.6899 - accuracy: 0.7319 - f1: 0.7212 - precision: 0.8202 - recall: 0.6445 - val_loss: 1.3410 - val_accuracy: 0.5325 - val_f1: 0.5135 - val_precision: 0.5725 - val_recall: 0.4658\n",
            "Epoch 14/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.6541 - accuracy: 0.7462 - f1: 0.7345 - precision: 0.8235 - recall: 0.6638 - val_loss: 1.3922 - val_accuracy: 0.5417 - val_f1: 0.5227 - val_precision: 0.5755 - val_recall: 0.4792\n",
            "Epoch 15/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.6239 - accuracy: 0.7625 - f1: 0.7531 - precision: 0.8258 - recall: 0.6929 - val_loss: 1.2578 - val_accuracy: 0.5367 - val_f1: 0.5167 - val_precision: 0.5803 - val_recall: 0.4658\n",
            "Epoch 16/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.5751 - accuracy: 0.7951 - f1: 0.7788 - precision: 0.8498 - recall: 0.7193 - val_loss: 1.2652 - val_accuracy: 0.5542 - val_f1: 0.5371 - val_precision: 0.5925 - val_recall: 0.4917\n",
            "Epoch 17/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.5246 - accuracy: 0.8064 - f1: 0.8027 - precision: 0.8579 - recall: 0.7547 - val_loss: 1.3445 - val_accuracy: 0.5517 - val_f1: 0.5265 - val_precision: 0.5807 - val_recall: 0.4817\n",
            "Epoch 18/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.5227 - accuracy: 0.8136 - f1: 0.8086 - precision: 0.8676 - recall: 0.7574 - val_loss: 1.3095 - val_accuracy: 0.5800 - val_f1: 0.5595 - val_precision: 0.6059 - val_recall: 0.5200\n",
            "Epoch 19/60\n",
            "46/46 [==============================] - 4s 99ms/step - loss: 0.4384 - accuracy: 0.8354 - f1: 0.8362 - precision: 0.8784 - recall: 0.7983 - val_loss: 1.3769 - val_accuracy: 0.5642 - val_f1: 0.5487 - val_precision: 0.5894 - val_recall: 0.5133\n",
            "Epoch 20/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.4205 - accuracy: 0.8522 - f1: 0.8460 - precision: 0.8896 - recall: 0.8067 - val_loss: 1.5356 - val_accuracy: 0.5542 - val_f1: 0.5439 - val_precision: 0.5842 - val_recall: 0.5092\n",
            "Epoch 21/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.4174 - accuracy: 0.8502 - f1: 0.8482 - precision: 0.8886 - recall: 0.8116 - val_loss: 1.4485 - val_accuracy: 0.5558 - val_f1: 0.5434 - val_precision: 0.5799 - val_recall: 0.5117\n",
            "Epoch 22/60\n",
            "46/46 [==============================] - 4s 99ms/step - loss: 0.3687 - accuracy: 0.8680 - f1: 0.8682 - precision: 0.9026 - recall: 0.8367 - val_loss: 1.4795 - val_accuracy: 0.5767 - val_f1: 0.5712 - val_precision: 0.6043 - val_recall: 0.5417\n",
            "Epoch 23/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.3344 - accuracy: 0.8867 - f1: 0.8841 - precision: 0.9145 - recall: 0.8560 - val_loss: 1.5267 - val_accuracy: 0.5933 - val_f1: 0.5819 - val_precision: 0.6088 - val_recall: 0.5575\n",
            "Epoch 24/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.3380 - accuracy: 0.8783 - f1: 0.8788 - precision: 0.9064 - recall: 0.8529 - val_loss: 1.4216 - val_accuracy: 0.5667 - val_f1: 0.5662 - val_precision: 0.5997 - val_recall: 0.5367\n",
            "Epoch 25/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.3057 - accuracy: 0.8954 - f1: 0.8920 - precision: 0.9166 - recall: 0.8690 - val_loss: 1.5673 - val_accuracy: 0.5833 - val_f1: 0.5840 - val_precision: 0.6104 - val_recall: 0.5600\n",
            "Epoch 26/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.2651 - accuracy: 0.9080 - f1: 0.9052 - precision: 0.9265 - recall: 0.8851 - val_loss: 1.5267 - val_accuracy: 0.5925 - val_f1: 0.5789 - val_precision: 0.6022 - val_recall: 0.5575\n",
            "Epoch 27/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.2356 - accuracy: 0.9209 - f1: 0.9216 - precision: 0.9396 - recall: 0.9044 - val_loss: 1.6834 - val_accuracy: 0.5983 - val_f1: 0.5890 - val_precision: 0.6085 - val_recall: 0.5708\n",
            "Epoch 28/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.2290 - accuracy: 0.9246 - f1: 0.9218 - precision: 0.9371 - recall: 0.9071 - val_loss: 1.5927 - val_accuracy: 0.5925 - val_f1: 0.5842 - val_precision: 0.6069 - val_recall: 0.5633\n",
            "Epoch 29/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.2257 - accuracy: 0.9189 - f1: 0.9216 - precision: 0.9363 - recall: 0.9075 - val_loss: 1.6819 - val_accuracy: 0.5950 - val_f1: 0.5852 - val_precision: 0.6043 - val_recall: 0.5675\n",
            "Epoch 30/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.1952 - accuracy: 0.9296 - f1: 0.9306 - precision: 0.9446 - recall: 0.9171 - val_loss: 1.7292 - val_accuracy: 0.5858 - val_f1: 0.5784 - val_precision: 0.5965 - val_recall: 0.5617\n",
            "Epoch 31/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.2415 - accuracy: 0.9147 - f1: 0.9158 - precision: 0.9273 - recall: 0.9047 - val_loss: 1.6802 - val_accuracy: 0.5892 - val_f1: 0.5857 - val_precision: 0.6044 - val_recall: 0.5683\n",
            "Epoch 32/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.2101 - accuracy: 0.9227 - f1: 0.9234 - precision: 0.9394 - recall: 0.9082 - val_loss: 1.5840 - val_accuracy: 0.6208 - val_f1: 0.6142 - val_precision: 0.6319 - val_recall: 0.5975\n",
            "Epoch 33/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.1640 - accuracy: 0.9397 - f1: 0.9400 - precision: 0.9550 - recall: 0.9256 - val_loss: 1.7687 - val_accuracy: 0.6025 - val_f1: 0.6031 - val_precision: 0.6257 - val_recall: 0.5825\n",
            "Epoch 34/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.1666 - accuracy: 0.9384 - f1: 0.9369 - precision: 0.9476 - recall: 0.9265 - val_loss: 1.9105 - val_accuracy: 0.6225 - val_f1: 0.6193 - val_precision: 0.6308 - val_recall: 0.6083\n",
            "Epoch 35/60\n",
            "46/46 [==============================] - 5s 98ms/step - loss: 0.1465 - accuracy: 0.9455 - f1: 0.9451 - precision: 0.9557 - recall: 0.9349 - val_loss: 1.8057 - val_accuracy: 0.6292 - val_f1: 0.6257 - val_precision: 0.6378 - val_recall: 0.6142\n",
            "Epoch 36/60\n",
            "46/46 [==============================] - 4s 99ms/step - loss: 0.1551 - accuracy: 0.9393 - f1: 0.9396 - precision: 0.9479 - recall: 0.9316 - val_loss: 1.8064 - val_accuracy: 0.6150 - val_f1: 0.6135 - val_precision: 0.6315 - val_recall: 0.5967\n",
            "Epoch 37/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.1305 - accuracy: 0.9538 - f1: 0.9542 - precision: 0.9616 - recall: 0.9470 - val_loss: 2.0125 - val_accuracy: 0.6200 - val_f1: 0.6149 - val_precision: 0.6262 - val_recall: 0.6042\n",
            "Epoch 38/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.1233 - accuracy: 0.9543 - f1: 0.9547 - precision: 0.9609 - recall: 0.9486 - val_loss: 1.7754 - val_accuracy: 0.6058 - val_f1: 0.6040 - val_precision: 0.6198 - val_recall: 0.5892\n",
            "Epoch 39/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.1748 - accuracy: 0.9403 - f1: 0.9416 - precision: 0.9500 - recall: 0.9335 - val_loss: 1.8495 - val_accuracy: 0.6233 - val_f1: 0.6209 - val_precision: 0.6314 - val_recall: 0.6108\n",
            "Epoch 40/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.1540 - accuracy: 0.9424 - f1: 0.9418 - precision: 0.9514 - recall: 0.9325 - val_loss: 1.9054 - val_accuracy: 0.6300 - val_f1: 0.6251 - val_precision: 0.6357 - val_recall: 0.6150\n",
            "Epoch 41/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.1304 - accuracy: 0.9549 - f1: 0.9533 - precision: 0.9596 - recall: 0.9470 - val_loss: 2.1367 - val_accuracy: 0.6433 - val_f1: 0.6394 - val_precision: 0.6520 - val_recall: 0.6275\n",
            "Epoch 42/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.1066 - accuracy: 0.9612 - f1: 0.9611 - precision: 0.9669 - recall: 0.9554 - val_loss: 2.2319 - val_accuracy: 0.6017 - val_f1: 0.5948 - val_precision: 0.6051 - val_recall: 0.5850\n",
            "Epoch 43/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.1210 - accuracy: 0.9536 - f1: 0.9558 - precision: 0.9613 - recall: 0.9503 - val_loss: 2.0609 - val_accuracy: 0.6342 - val_f1: 0.6352 - val_precision: 0.6468 - val_recall: 0.6242\n",
            "Epoch 44/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.0989 - accuracy: 0.9607 - f1: 0.9613 - precision: 0.9660 - recall: 0.9567 - val_loss: 2.4995 - val_accuracy: 0.6200 - val_f1: 0.6173 - val_precision: 0.6295 - val_recall: 0.6058\n",
            "Epoch 45/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.0838 - accuracy: 0.9667 - f1: 0.9682 - precision: 0.9733 - recall: 0.9631 - val_loss: 2.5238 - val_accuracy: 0.6233 - val_f1: 0.6176 - val_precision: 0.6264 - val_recall: 0.6092\n",
            "Epoch 46/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.1016 - accuracy: 0.9599 - f1: 0.9601 - precision: 0.9648 - recall: 0.9555 - val_loss: 2.2977 - val_accuracy: 0.6042 - val_f1: 0.6009 - val_precision: 0.6104 - val_recall: 0.5917\n",
            "Epoch 47/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.1051 - accuracy: 0.9582 - f1: 0.9589 - precision: 0.9642 - recall: 0.9536 - val_loss: 2.1727 - val_accuracy: 0.6200 - val_f1: 0.6200 - val_precision: 0.6314 - val_recall: 0.6092\n",
            "Epoch 48/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.1102 - accuracy: 0.9539 - f1: 0.9547 - precision: 0.9612 - recall: 0.9483 - val_loss: 2.4934 - val_accuracy: 0.6208 - val_f1: 0.6179 - val_precision: 0.6243 - val_recall: 0.6117\n",
            "Epoch 49/60\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 0.1010 - accuracy: 0.9608 - f1: 0.9600 - precision: 0.9648 - recall: 0.9553 - val_loss: 2.3413 - val_accuracy: 0.6117 - val_f1: 0.6133 - val_precision: 0.6219 - val_recall: 0.6050\n",
            "Epoch 50/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.0984 - accuracy: 0.9625 - f1: 0.9635 - precision: 0.9677 - recall: 0.9594 - val_loss: 2.3658 - val_accuracy: 0.6267 - val_f1: 0.6245 - val_precision: 0.6319 - val_recall: 0.6175\n",
            "Epoch 51/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.1692 - accuracy: 0.9456 - f1: 0.9446 - precision: 0.9501 - recall: 0.9392 - val_loss: 2.1350 - val_accuracy: 0.6075 - val_f1: 0.6099 - val_precision: 0.6203 - val_recall: 0.6000\n",
            "Epoch 52/60\n",
            "46/46 [==============================] - 5s 102ms/step - loss: 0.1290 - accuracy: 0.9530 - f1: 0.9544 - precision: 0.9600 - recall: 0.9488 - val_loss: 2.5561 - val_accuracy: 0.6025 - val_f1: 0.6013 - val_precision: 0.6095 - val_recall: 0.5933\n",
            "Epoch 53/60\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 0.0910 - accuracy: 0.9660 - f1: 0.9655 - precision: 0.9712 - recall: 0.9599 - val_loss: 2.4934 - val_accuracy: 0.6033 - val_f1: 0.5992 - val_precision: 0.6078 - val_recall: 0.5908\n",
            "Epoch 54/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.0841 - accuracy: 0.9668 - f1: 0.9665 - precision: 0.9708 - recall: 0.9622 - val_loss: 2.5053 - val_accuracy: 0.6258 - val_f1: 0.6237 - val_precision: 0.6292 - val_recall: 0.6183\n",
            "Epoch 55/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.0724 - accuracy: 0.9683 - f1: 0.9694 - precision: 0.9730 - recall: 0.9658 - val_loss: 2.5598 - val_accuracy: 0.6200 - val_f1: 0.6199 - val_precision: 0.6258 - val_recall: 0.6142\n",
            "Epoch 56/60\n",
            "46/46 [==============================] - 4s 99ms/step - loss: 0.0628 - accuracy: 0.9742 - f1: 0.9737 - precision: 0.9779 - recall: 0.9695 - val_loss: 2.6727 - val_accuracy: 0.6258 - val_f1: 0.6259 - val_precision: 0.6320 - val_recall: 0.6200\n",
            "Epoch 57/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.0615 - accuracy: 0.9754 - f1: 0.9749 - precision: 0.9791 - recall: 0.9708 - val_loss: 2.6622 - val_accuracy: 0.6133 - val_f1: 0.6111 - val_precision: 0.6174 - val_recall: 0.6050\n",
            "Epoch 58/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.0523 - accuracy: 0.9751 - f1: 0.9768 - precision: 0.9803 - recall: 0.9733 - val_loss: 2.7301 - val_accuracy: 0.6175 - val_f1: 0.6181 - val_precision: 0.6239 - val_recall: 0.6125\n",
            "Epoch 59/60\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 0.0647 - accuracy: 0.9752 - f1: 0.9743 - precision: 0.9782 - recall: 0.9704 - val_loss: 2.8596 - val_accuracy: 0.6150 - val_f1: 0.6128 - val_precision: 0.6182 - val_recall: 0.6075\n",
            "Epoch 60/60\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 0.1020 - accuracy: 0.9598 - f1: 0.9601 - precision: 0.9664 - recall: 0.9539 - val_loss: 2.4417 - val_accuracy: 0.6192 - val_f1: 0.6189 - val_precision: 0.6237 - val_recall: 0.6142\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 2.5817 - accuracy: 0.6150 - f1: 0.6164 - precision: 0.6259 - recall: 0.6071\n",
            "[2.5816996097564697, 0.6150000095367432, 0.6163631677627563, 0.6259156465530396, 0.6071428656578064]\n",
            "CBOW_BI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_G3Ff5r1bSD",
        "outputId": "95254f7b-b652-474e-8a42-e7f02fea7e9a"
      },
      "source": [
        "model_cbow_rnn = tf.keras.Sequential()\r\n",
        "model_cbow_rnn.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_cbow_rnn.add(tf.keras.layers.SimpleRNN(64))\r\n",
        "model_cbow_rnn.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_cbow_rnn.add(tf.keras.layers.Dense(64,activation='relu'))\r\n",
        "model_cbow_rnn.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_cbow_rnn.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_cbow_rnn.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy',f1,precision,recall])\r\n",
        "history_cbow_rnn = model_cbow_rnn.fit_generator(cbow_train_gen,validation_data=cbow_val_gen,validation_steps=int((len(X_val)/batch_size)+1),steps_per_epoch=int((len(X_train)/batch_size)+1),epochs=epochs)\r\n",
        "history = model_cbow_rnn.evaluate(x = vec_gen(w2v_cbow,vocab_cbow,X_test,y_test,batch_size,Max_input_size,Embedding_size),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table[5]=history[1]\r\n",
        "print(\"CBOW_RNN\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "46/46 [==============================] - 7s 131ms/step - loss: 1.3898 - accuracy: 0.2715 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3672 - val_accuracy: 0.3350 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 1.3804 - accuracy: 0.2979 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3696 - val_accuracy: 0.3242 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/60\n",
            "46/46 [==============================] - 6s 126ms/step - loss: 1.3779 - accuracy: 0.2987 - f1: 1.5518e-04 - precision: 0.0050 - recall: 7.9785e-05 - val_loss: 1.3640 - val_accuracy: 0.3208 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/60\n",
            "46/46 [==============================] - 6s 126ms/step - loss: 1.3570 - accuracy: 0.3394 - f1: 0.0063 - precision: 0.1000 - recall: 0.0034 - val_loss: 1.3555 - val_accuracy: 0.3400 - val_f1: 0.0336 - val_precision: 0.6181 - val_recall: 0.0175\n",
            "Epoch 5/60\n",
            "46/46 [==============================] - 6s 126ms/step - loss: 1.3295 - accuracy: 0.3684 - f1: 0.0790 - precision: 0.5469 - recall: 0.0444 - val_loss: 1.3530 - val_accuracy: 0.3492 - val_f1: 0.0210 - val_precision: 0.4028 - val_recall: 0.0108\n",
            "Epoch 6/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 1.2966 - accuracy: 0.4032 - f1: 0.1201 - precision: 0.5345 - recall: 0.0720 - val_loss: 1.3659 - val_accuracy: 0.3333 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 7/60\n",
            "46/46 [==============================] - 6s 123ms/step - loss: 1.2982 - accuracy: 0.3831 - f1: 0.0879 - precision: 0.4803 - recall: 0.0508 - val_loss: 1.3850 - val_accuracy: 0.3350 - val_f1: 0.0330 - val_precision: 0.3431 - val_recall: 0.0175\n",
            "Epoch 8/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 1.2768 - accuracy: 0.4054 - f1: 0.1655 - precision: 0.5576 - recall: 0.1045 - val_loss: 1.3402 - val_accuracy: 0.3425 - val_f1: 0.0287 - val_precision: 0.3514 - val_recall: 0.0150\n",
            "Epoch 9/60\n",
            "46/46 [==============================] - 6s 126ms/step - loss: 1.2718 - accuracy: 0.4140 - f1: 0.1391 - precision: 0.5594 - recall: 0.0877 - val_loss: 1.3443 - val_accuracy: 0.3517 - val_f1: 0.0673 - val_precision: 0.6148 - val_recall: 0.0358\n",
            "Epoch 10/60\n",
            "46/46 [==============================] - 6s 127ms/step - loss: 1.2590 - accuracy: 0.4164 - f1: 0.1774 - precision: 0.6282 - recall: 0.1121 - val_loss: 1.3284 - val_accuracy: 0.3692 - val_f1: 0.1465 - val_precision: 0.5377 - val_recall: 0.0850\n",
            "Epoch 11/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 1.2591 - accuracy: 0.4202 - f1: 0.1766 - precision: 0.5482 - recall: 0.1120 - val_loss: 1.3562 - val_accuracy: 0.3558 - val_f1: 0.0910 - val_precision: 0.5586 - val_recall: 0.0500\n",
            "Epoch 12/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 1.2460 - accuracy: 0.4326 - f1: 0.1986 - precision: 0.5476 - recall: 0.1268 - val_loss: 1.3610 - val_accuracy: 0.3450 - val_f1: 0.1191 - val_precision: 0.4916 - val_recall: 0.0683\n",
            "Epoch 13/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 1.2453 - accuracy: 0.4412 - f1: 0.2199 - precision: 0.5525 - recall: 0.1455 - val_loss: 1.3547 - val_accuracy: 0.3525 - val_f1: 0.1683 - val_precision: 0.5012 - val_recall: 0.1025\n",
            "Epoch 14/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 1.2716 - accuracy: 0.4197 - f1: 0.1877 - precision: 0.5654 - recall: 0.1182 - val_loss: 1.3583 - val_accuracy: 0.3550 - val_f1: 0.1292 - val_precision: 0.4961 - val_recall: 0.0750\n",
            "Epoch 15/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 1.2502 - accuracy: 0.4261 - f1: 0.2112 - precision: 0.5871 - recall: 0.1310 - val_loss: 1.3481 - val_accuracy: 0.3575 - val_f1: 0.1053 - val_precision: 0.5769 - val_recall: 0.0583\n",
            "Epoch 16/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 1.2284 - accuracy: 0.4476 - f1: 0.1911 - precision: 0.5841 - recall: 0.1174 - val_loss: 1.3436 - val_accuracy: 0.3675 - val_f1: 0.1558 - val_precision: 0.5307 - val_recall: 0.0917\n",
            "Epoch 17/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 1.1783 - accuracy: 0.4827 - f1: 0.2743 - precision: 0.6170 - recall: 0.1800 - val_loss: 1.3634 - val_accuracy: 0.3450 - val_f1: 0.1720 - val_precision: 0.4394 - val_recall: 0.1075\n",
            "Epoch 18/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 1.1692 - accuracy: 0.4924 - f1: 0.3198 - precision: 0.5949 - recall: 0.2230 - val_loss: 1.3616 - val_accuracy: 0.3725 - val_f1: 0.1862 - val_precision: 0.4690 - val_recall: 0.1167\n",
            "Epoch 19/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 1.1361 - accuracy: 0.5155 - f1: 0.3185 - precision: 0.6325 - recall: 0.2167 - val_loss: 1.3655 - val_accuracy: 0.3475 - val_f1: 0.1823 - val_precision: 0.4958 - val_recall: 0.1125\n",
            "Epoch 20/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 1.1069 - accuracy: 0.5292 - f1: 0.3778 - precision: 0.6566 - recall: 0.2690 - val_loss: 1.3689 - val_accuracy: 0.3633 - val_f1: 0.2093 - val_precision: 0.4405 - val_recall: 0.1383\n",
            "Epoch 21/60\n",
            "46/46 [==============================] - 6s 127ms/step - loss: 1.1019 - accuracy: 0.5256 - f1: 0.3836 - precision: 0.6358 - recall: 0.2781 - val_loss: 1.3864 - val_accuracy: 0.3633 - val_f1: 0.2471 - val_precision: 0.4509 - val_recall: 0.1708\n",
            "Epoch 22/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 1.0416 - accuracy: 0.5663 - f1: 0.4707 - precision: 0.6725 - recall: 0.3645 - val_loss: 1.3985 - val_accuracy: 0.3417 - val_f1: 0.2342 - val_precision: 0.4270 - val_recall: 0.1625\n",
            "Epoch 23/60\n",
            "46/46 [==============================] - 6s 126ms/step - loss: 1.0918 - accuracy: 0.5285 - f1: 0.4249 - precision: 0.6281 - recall: 0.3237 - val_loss: 1.4055 - val_accuracy: 0.3600 - val_f1: 0.2585 - val_precision: 0.4469 - val_recall: 0.1825\n",
            "Epoch 24/60\n",
            "46/46 [==============================] - 6s 126ms/step - loss: 1.0498 - accuracy: 0.5503 - f1: 0.4416 - precision: 0.6484 - recall: 0.3368 - val_loss: 1.4321 - val_accuracy: 0.3617 - val_f1: 0.2643 - val_precision: 0.4126 - val_recall: 0.1950\n",
            "Epoch 25/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 1.0375 - accuracy: 0.5614 - f1: 0.4750 - precision: 0.6599 - recall: 0.3730 - val_loss: 1.4471 - val_accuracy: 0.3550 - val_f1: 0.2503 - val_precision: 0.3963 - val_recall: 0.1833\n",
            "Epoch 26/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 1.0424 - accuracy: 0.5573 - f1: 0.4650 - precision: 0.6395 - recall: 0.3682 - val_loss: 1.5171 - val_accuracy: 0.3442 - val_f1: 0.2564 - val_precision: 0.3696 - val_recall: 0.1967\n",
            "Epoch 27/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 0.9960 - accuracy: 0.5761 - f1: 0.5101 - precision: 0.6670 - recall: 0.4157 - val_loss: 1.4889 - val_accuracy: 0.3658 - val_f1: 0.2789 - val_precision: 0.4051 - val_recall: 0.2133\n",
            "Epoch 28/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 1.0490 - accuracy: 0.5530 - f1: 0.4672 - precision: 0.6394 - recall: 0.3720 - val_loss: 1.4981 - val_accuracy: 0.3483 - val_f1: 0.2783 - val_precision: 0.4024 - val_recall: 0.2133\n",
            "Epoch 29/60\n",
            "46/46 [==============================] - 6s 126ms/step - loss: 1.0383 - accuracy: 0.5627 - f1: 0.4818 - precision: 0.6469 - recall: 0.3855 - val_loss: 1.5716 - val_accuracy: 0.3367 - val_f1: 0.2685 - val_precision: 0.3780 - val_recall: 0.2083\n",
            "Epoch 30/60\n",
            "46/46 [==============================] - 6s 128ms/step - loss: 1.1055 - accuracy: 0.5262 - f1: 0.4272 - precision: 0.6085 - recall: 0.3305 - val_loss: 1.5198 - val_accuracy: 0.3733 - val_f1: 0.2827 - val_precision: 0.3799 - val_recall: 0.2258\n",
            "Epoch 31/60\n",
            "46/46 [==============================] - 6s 127ms/step - loss: 0.9930 - accuracy: 0.5826 - f1: 0.5110 - precision: 0.6762 - recall: 0.4138 - val_loss: 1.4974 - val_accuracy: 0.3442 - val_f1: 0.2920 - val_precision: 0.3979 - val_recall: 0.2317\n",
            "Epoch 32/60\n",
            "46/46 [==============================] - 6s 127ms/step - loss: 0.9943 - accuracy: 0.5784 - f1: 0.5139 - precision: 0.6717 - recall: 0.4178 - val_loss: 1.5413 - val_accuracy: 0.3758 - val_f1: 0.3169 - val_precision: 0.4007 - val_recall: 0.2625\n",
            "Epoch 33/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 0.8748 - accuracy: 0.6402 - f1: 0.5944 - precision: 0.7231 - recall: 0.5056 - val_loss: 1.6734 - val_accuracy: 0.3633 - val_f1: 0.3172 - val_precision: 0.3836 - val_recall: 0.2708\n",
            "Epoch 34/60\n",
            "46/46 [==============================] - 6s 126ms/step - loss: 0.8655 - accuracy: 0.6350 - f1: 0.6104 - precision: 0.7099 - recall: 0.5366 - val_loss: 1.6265 - val_accuracy: 0.3767 - val_f1: 0.3327 - val_precision: 0.3975 - val_recall: 0.2867\n",
            "Epoch 35/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 0.8823 - accuracy: 0.6381 - f1: 0.6035 - precision: 0.7014 - recall: 0.5304 - val_loss: 1.6745 - val_accuracy: 0.3817 - val_f1: 0.3503 - val_precision: 0.4166 - val_recall: 0.3025\n",
            "Epoch 36/60\n",
            "46/46 [==============================] - 6s 126ms/step - loss: 0.8532 - accuracy: 0.6463 - f1: 0.6123 - precision: 0.7041 - recall: 0.5425 - val_loss: 1.7403 - val_accuracy: 0.3808 - val_f1: 0.3552 - val_precision: 0.4074 - val_recall: 0.3150\n",
            "Epoch 37/60\n",
            "46/46 [==============================] - 6s 128ms/step - loss: 0.8388 - accuracy: 0.6551 - f1: 0.6288 - precision: 0.7090 - recall: 0.5660 - val_loss: 1.6871 - val_accuracy: 0.3692 - val_f1: 0.3319 - val_precision: 0.3943 - val_recall: 0.2867\n",
            "Epoch 38/60\n",
            "46/46 [==============================] - 6s 126ms/step - loss: 0.8617 - accuracy: 0.6388 - f1: 0.6211 - precision: 0.7040 - recall: 0.5565 - val_loss: 1.6779 - val_accuracy: 0.3683 - val_f1: 0.3319 - val_precision: 0.3930 - val_recall: 0.2875\n",
            "Epoch 39/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 0.7866 - accuracy: 0.6739 - f1: 0.6531 - precision: 0.7355 - recall: 0.5881 - val_loss: 1.7305 - val_accuracy: 0.3342 - val_f1: 0.3116 - val_precision: 0.3689 - val_recall: 0.2700\n",
            "Epoch 40/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 0.8104 - accuracy: 0.6774 - f1: 0.6540 - precision: 0.7309 - recall: 0.5926 - val_loss: 1.7301 - val_accuracy: 0.3042 - val_f1: 0.2797 - val_precision: 0.3425 - val_recall: 0.2367\n",
            "Epoch 41/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 0.9112 - accuracy: 0.6229 - f1: 0.5912 - precision: 0.6887 - recall: 0.5186 - val_loss: 1.7103 - val_accuracy: 0.3558 - val_f1: 0.3345 - val_precision: 0.3865 - val_recall: 0.2950\n",
            "Epoch 42/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 0.8072 - accuracy: 0.6777 - f1: 0.6465 - precision: 0.7234 - recall: 0.5851 - val_loss: 1.7607 - val_accuracy: 0.3725 - val_f1: 0.3539 - val_precision: 0.4028 - val_recall: 0.3158\n",
            "Epoch 43/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 0.7538 - accuracy: 0.6978 - f1: 0.6719 - precision: 0.7421 - recall: 0.6141 - val_loss: 1.7165 - val_accuracy: 0.3592 - val_f1: 0.3232 - val_precision: 0.3739 - val_recall: 0.2850\n",
            "Epoch 44/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 0.7469 - accuracy: 0.6998 - f1: 0.6882 - precision: 0.7473 - recall: 0.6386 - val_loss: 1.7476 - val_accuracy: 0.3800 - val_f1: 0.3454 - val_precision: 0.3973 - val_recall: 0.3058\n",
            "Epoch 45/60\n",
            "46/46 [==============================] - 6s 126ms/step - loss: 0.6604 - accuracy: 0.7409 - f1: 0.7236 - precision: 0.7825 - recall: 0.6734 - val_loss: 1.8355 - val_accuracy: 0.3725 - val_f1: 0.3490 - val_precision: 0.3866 - val_recall: 0.3183\n",
            "Epoch 46/60\n",
            "46/46 [==============================] - 6s 128ms/step - loss: 0.6842 - accuracy: 0.7238 - f1: 0.7092 - precision: 0.7580 - recall: 0.6671 - val_loss: 1.7877 - val_accuracy: 0.3525 - val_f1: 0.3261 - val_precision: 0.3785 - val_recall: 0.2867\n",
            "Epoch 47/60\n",
            "46/46 [==============================] - 6s 128ms/step - loss: 0.7336 - accuracy: 0.7001 - f1: 0.6898 - precision: 0.7463 - recall: 0.6419 - val_loss: 1.8976 - val_accuracy: 0.3367 - val_f1: 0.3174 - val_precision: 0.3518 - val_recall: 0.2892\n",
            "Epoch 48/60\n",
            "46/46 [==============================] - 6s 126ms/step - loss: 0.7417 - accuracy: 0.7021 - f1: 0.6885 - precision: 0.7440 - recall: 0.6411 - val_loss: 2.0298 - val_accuracy: 0.3425 - val_f1: 0.3183 - val_precision: 0.3556 - val_recall: 0.2883\n",
            "Epoch 49/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 0.7418 - accuracy: 0.7038 - f1: 0.6812 - precision: 0.7434 - recall: 0.6292 - val_loss: 2.0200 - val_accuracy: 0.3175 - val_f1: 0.2927 - val_precision: 0.3366 - val_recall: 0.2592\n",
            "Epoch 50/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 0.7639 - accuracy: 0.6863 - f1: 0.6646 - precision: 0.7265 - recall: 0.6127 - val_loss: 2.1087 - val_accuracy: 0.3117 - val_f1: 0.2823 - val_precision: 0.3166 - val_recall: 0.2550\n",
            "Epoch 51/60\n",
            "46/46 [==============================] - 6s 127ms/step - loss: 0.8358 - accuracy: 0.6635 - f1: 0.6438 - precision: 0.7066 - recall: 0.5922 - val_loss: 1.8792 - val_accuracy: 0.3333 - val_f1: 0.2857 - val_precision: 0.3373 - val_recall: 0.2483\n",
            "Epoch 52/60\n",
            "46/46 [==============================] - 6s 127ms/step - loss: 0.9193 - accuracy: 0.6174 - f1: 0.5990 - precision: 0.6804 - recall: 0.5359 - val_loss: 1.5986 - val_accuracy: 0.3783 - val_f1: 0.3344 - val_precision: 0.4051 - val_recall: 0.2850\n",
            "Epoch 53/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 0.7838 - accuracy: 0.6763 - f1: 0.6555 - precision: 0.7423 - recall: 0.5875 - val_loss: 1.6887 - val_accuracy: 0.3683 - val_f1: 0.3359 - val_precision: 0.3921 - val_recall: 0.2942\n",
            "Epoch 54/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 0.6878 - accuracy: 0.7326 - f1: 0.7075 - precision: 0.7768 - recall: 0.6502 - val_loss: 1.8224 - val_accuracy: 0.3792 - val_f1: 0.3549 - val_precision: 0.3937 - val_recall: 0.3233\n",
            "Epoch 55/60\n",
            "46/46 [==============================] - 6s 125ms/step - loss: 0.6513 - accuracy: 0.7435 - f1: 0.7285 - precision: 0.7793 - recall: 0.6844 - val_loss: 1.9783 - val_accuracy: 0.3675 - val_f1: 0.3414 - val_precision: 0.3754 - val_recall: 0.3133\n",
            "Epoch 56/60\n",
            "46/46 [==============================] - 6s 126ms/step - loss: 0.6248 - accuracy: 0.7606 - f1: 0.7510 - precision: 0.7948 - recall: 0.7120 - val_loss: 2.0683 - val_accuracy: 0.3675 - val_f1: 0.3480 - val_precision: 0.3782 - val_recall: 0.3225\n",
            "Epoch 57/60\n",
            "46/46 [==============================] - 6s 126ms/step - loss: 0.5310 - accuracy: 0.8010 - f1: 0.7960 - precision: 0.8315 - recall: 0.7637 - val_loss: 2.2081 - val_accuracy: 0.3617 - val_f1: 0.3457 - val_precision: 0.3706 - val_recall: 0.3242\n",
            "Epoch 58/60\n",
            "46/46 [==============================] - 6s 126ms/step - loss: 0.5369 - accuracy: 0.7901 - f1: 0.7848 - precision: 0.8170 - recall: 0.7555 - val_loss: 2.2751 - val_accuracy: 0.3533 - val_f1: 0.3382 - val_precision: 0.3588 - val_recall: 0.3200\n",
            "Epoch 59/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 0.5381 - accuracy: 0.7979 - f1: 0.7919 - precision: 0.8216 - recall: 0.7645 - val_loss: 2.3009 - val_accuracy: 0.3675 - val_f1: 0.3519 - val_precision: 0.3709 - val_recall: 0.3350\n",
            "Epoch 60/60\n",
            "46/46 [==============================] - 6s 124ms/step - loss: 0.5065 - accuracy: 0.8070 - f1: 0.8062 - precision: 0.8332 - recall: 0.7812 - val_loss: 2.3134 - val_accuracy: 0.3717 - val_f1: 0.3607 - val_precision: 0.3801 - val_recall: 0.3433\n",
            "14/14 [==============================] - 1s 78ms/step - loss: 2.3863 - accuracy: 0.3721 - f1: 0.3649 - precision: 0.3839 - recall: 0.3479\n",
            "[2.3863155841827393, 0.37214285135269165, 0.36490514874458313, 0.383871465921402, 0.34785714745521545]\n",
            "CBOW_RNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czoFmEwK1dWT",
        "outputId": "30180675-9a35-46d4-fdae-2ca58adccae0"
      },
      "source": [
        "model_glove = tf.keras.Sequential()\r\n",
        "model_glove.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_glove.add(tf.keras.layers.LSTM(64))\r\n",
        "model_glove.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_glove.add(tf.keras.layers.Dense(64,activation='relu'))\r\n",
        "model_glove.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_glove.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_glove.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy',f1,precision,recall])\r\n",
        "glove_train_gen=glove_gen(vocab_glove,X_train,y_train,batch_size,Max_input_size,Embedding_size)\r\n",
        "glove_val_gen=glove_gen(vocab_glove,X_val,y_val,batch_size,Max_input_size,Embedding_size)\r\n",
        "history_glove_lstm = model_glove.fit_generator(glove_train_gen,validation_data=glove_val_gen,validation_steps=int((len(X_val)/batch_size)+1),steps_per_epoch=int((len(X_train)/batch_size)+1),epochs=epochs)\r\n",
        "history = model_glove.evaluate(x = glove_gen(vocab_glove,X_test,y_test,batch_size,Max_input_size,Embedding_size),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table[6]=history[1]\r\n",
        "print(\"GLOVE_LSTM\")\r\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "46/46 [==============================] - 3s 30ms/step - loss: 1.3810 - accuracy: 0.3078 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3555 - val_accuracy: 0.3283 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 1.2953 - accuracy: 0.3903 - f1: 0.1719 - precision: 0.5081 - recall: 0.1093 - val_loss: 1.1795 - val_accuracy: 0.4858 - val_f1: 0.2701 - val_precision: 0.7232 - val_recall: 0.1667\n",
            "Epoch 3/60\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 1.1711 - accuracy: 0.4680 - f1: 0.3793 - precision: 0.6660 - recall: 0.2758 - val_loss: 1.1277 - val_accuracy: 0.4933 - val_f1: 0.4415 - val_precision: 0.6592 - val_recall: 0.3333\n",
            "Epoch 4/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 1.0650 - accuracy: 0.5286 - f1: 0.4513 - precision: 0.7493 - recall: 0.3251 - val_loss: 1.0277 - val_accuracy: 0.5633 - val_f1: 0.4710 - val_precision: 0.7775 - val_recall: 0.3400\n",
            "Epoch 5/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.9867 - accuracy: 0.5626 - f1: 0.4706 - precision: 0.8291 - recall: 0.3315 - val_loss: 1.0087 - val_accuracy: 0.5750 - val_f1: 0.5115 - val_precision: 0.7621 - val_recall: 0.3875\n",
            "Epoch 6/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.9247 - accuracy: 0.5942 - f1: 0.5101 - precision: 0.8701 - recall: 0.3651 - val_loss: 0.9989 - val_accuracy: 0.5733 - val_f1: 0.4861 - val_precision: 0.8221 - val_recall: 0.3483\n",
            "Epoch 7/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.8521 - accuracy: 0.6374 - f1: 0.5487 - precision: 0.8772 - recall: 0.4008 - val_loss: 0.9674 - val_accuracy: 0.5550 - val_f1: 0.4584 - val_precision: 0.9169 - val_recall: 0.3083\n",
            "Epoch 8/60\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.7892 - accuracy: 0.6460 - f1: 0.5704 - precision: 0.8790 - recall: 0.4250 - val_loss: 0.9004 - val_accuracy: 0.5975 - val_f1: 0.5185 - val_precision: 0.8830 - val_recall: 0.3708\n",
            "Epoch 9/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.7674 - accuracy: 0.6676 - f1: 0.6020 - precision: 0.8582 - recall: 0.4656 - val_loss: 0.9225 - val_accuracy: 0.6008 - val_f1: 0.5125 - val_precision: 0.8679 - val_recall: 0.3658\n",
            "Epoch 10/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.7583 - accuracy: 0.6671 - f1: 0.5975 - precision: 0.8943 - recall: 0.4528 - val_loss: 0.9310 - val_accuracy: 0.6258 - val_f1: 0.5467 - val_precision: 0.7991 - val_recall: 0.4175\n",
            "Epoch 11/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.6820 - accuracy: 0.6956 - f1: 0.6526 - precision: 0.8344 - recall: 0.5383 - val_loss: 0.9036 - val_accuracy: 0.6250 - val_f1: 0.6257 - val_precision: 0.7455 - val_recall: 0.5400\n",
            "Epoch 12/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.6133 - accuracy: 0.7159 - f1: 0.6951 - precision: 0.8120 - recall: 0.6102 - val_loss: 0.8890 - val_accuracy: 0.6475 - val_f1: 0.6477 - val_precision: 0.7239 - val_recall: 0.5867\n",
            "Epoch 13/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.5817 - accuracy: 0.7328 - f1: 0.7073 - precision: 0.7929 - recall: 0.6395 - val_loss: 0.9064 - val_accuracy: 0.6317 - val_f1: 0.6357 - val_precision: 0.7246 - val_recall: 0.5667\n",
            "Epoch 14/60\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.5576 - accuracy: 0.7382 - f1: 0.7202 - precision: 0.8132 - recall: 0.6477 - val_loss: 0.9302 - val_accuracy: 0.6583 - val_f1: 0.6360 - val_precision: 0.7438 - val_recall: 0.5558\n",
            "Epoch 15/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.5439 - accuracy: 0.7534 - f1: 0.7270 - precision: 0.8214 - recall: 0.6547 - val_loss: 0.8396 - val_accuracy: 0.6542 - val_f1: 0.6606 - val_precision: 0.7369 - val_recall: 0.5992\n",
            "Epoch 16/60\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.5179 - accuracy: 0.7704 - f1: 0.7477 - precision: 0.8299 - recall: 0.6828 - val_loss: 0.8888 - val_accuracy: 0.6650 - val_f1: 0.6617 - val_precision: 0.7377 - val_recall: 0.6000\n",
            "Epoch 17/60\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.5252 - accuracy: 0.7585 - f1: 0.7457 - precision: 0.8082 - recall: 0.6938 - val_loss: 0.8952 - val_accuracy: 0.6858 - val_f1: 0.6516 - val_precision: 0.7802 - val_recall: 0.5600\n",
            "Epoch 18/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.4953 - accuracy: 0.7719 - f1: 0.7550 - precision: 0.8233 - recall: 0.6996 - val_loss: 1.1016 - val_accuracy: 0.6408 - val_f1: 0.6381 - val_precision: 0.6896 - val_recall: 0.5942\n",
            "Epoch 19/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.4598 - accuracy: 0.8074 - f1: 0.7980 - precision: 0.8399 - recall: 0.7610 - val_loss: 0.9887 - val_accuracy: 0.6717 - val_f1: 0.6661 - val_precision: 0.6898 - val_recall: 0.6442\n",
            "Epoch 20/60\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.4586 - accuracy: 0.8244 - f1: 0.8141 - precision: 0.8360 - recall: 0.7937 - val_loss: 1.0473 - val_accuracy: 0.6608 - val_f1: 0.6606 - val_precision: 0.6807 - val_recall: 0.6417\n",
            "Epoch 21/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.4532 - accuracy: 0.8375 - f1: 0.8385 - precision: 0.8558 - recall: 0.8220 - val_loss: 1.1275 - val_accuracy: 0.6833 - val_f1: 0.6810 - val_precision: 0.6889 - val_recall: 0.6733\n",
            "Epoch 22/60\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.4513 - accuracy: 0.8510 - f1: 0.8509 - precision: 0.8602 - recall: 0.8419 - val_loss: 0.8917 - val_accuracy: 0.7150 - val_f1: 0.7138 - val_precision: 0.7228 - val_recall: 0.7050\n",
            "Epoch 23/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.3796 - accuracy: 0.8813 - f1: 0.8825 - precision: 0.8902 - recall: 0.8750 - val_loss: 0.9725 - val_accuracy: 0.7242 - val_f1: 0.7252 - val_precision: 0.7306 - val_recall: 0.7200\n",
            "Epoch 24/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.4050 - accuracy: 0.8759 - f1: 0.8751 - precision: 0.8808 - recall: 0.8695 - val_loss: 0.9055 - val_accuracy: 0.7267 - val_f1: 0.7269 - val_precision: 0.7323 - val_recall: 0.7217\n",
            "Epoch 25/60\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.3329 - accuracy: 0.9039 - f1: 0.9012 - precision: 0.9063 - recall: 0.8962 - val_loss: 0.9530 - val_accuracy: 0.7342 - val_f1: 0.7347 - val_precision: 0.7448 - val_recall: 0.7250\n",
            "Epoch 26/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.2883 - accuracy: 0.9192 - f1: 0.9197 - precision: 0.9236 - recall: 0.9159 - val_loss: 0.9132 - val_accuracy: 0.7325 - val_f1: 0.7343 - val_precision: 0.7386 - val_recall: 0.7300\n",
            "Epoch 27/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.3288 - accuracy: 0.9054 - f1: 0.9048 - precision: 0.9089 - recall: 0.9008 - val_loss: 0.9243 - val_accuracy: 0.7442 - val_f1: 0.7469 - val_precision: 0.7558 - val_recall: 0.7383\n",
            "Epoch 28/60\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.2775 - accuracy: 0.9263 - f1: 0.9265 - precision: 0.9305 - recall: 0.9225 - val_loss: 0.8939 - val_accuracy: 0.7567 - val_f1: 0.7581 - val_precision: 0.7674 - val_recall: 0.7492\n",
            "Epoch 29/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.2846 - accuracy: 0.9230 - f1: 0.9242 - precision: 0.9282 - recall: 0.9203 - val_loss: 0.8240 - val_accuracy: 0.7358 - val_f1: 0.7375 - val_precision: 0.7543 - val_recall: 0.7217\n",
            "Epoch 30/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.2416 - accuracy: 0.9389 - f1: 0.9385 - precision: 0.9434 - recall: 0.9337 - val_loss: 0.8513 - val_accuracy: 0.7458 - val_f1: 0.7490 - val_precision: 0.7610 - val_recall: 0.7375\n",
            "Epoch 31/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.2327 - accuracy: 0.9394 - f1: 0.9381 - precision: 0.9420 - recall: 0.9343 - val_loss: 0.8693 - val_accuracy: 0.7517 - val_f1: 0.7502 - val_precision: 0.7690 - val_recall: 0.7325\n",
            "Epoch 32/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.2108 - accuracy: 0.9494 - f1: 0.9482 - precision: 0.9515 - recall: 0.9450 - val_loss: 0.8794 - val_accuracy: 0.7492 - val_f1: 0.7503 - val_precision: 0.7645 - val_recall: 0.7367\n",
            "Epoch 33/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.2024 - accuracy: 0.9501 - f1: 0.9496 - precision: 0.9523 - recall: 0.9469 - val_loss: 0.9189 - val_accuracy: 0.7475 - val_f1: 0.7534 - val_precision: 0.7684 - val_recall: 0.7392\n",
            "Epoch 34/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.2178 - accuracy: 0.9431 - f1: 0.9429 - precision: 0.9463 - recall: 0.9395 - val_loss: 1.0017 - val_accuracy: 0.7550 - val_f1: 0.7549 - val_precision: 0.7626 - val_recall: 0.7475\n",
            "Epoch 35/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.1972 - accuracy: 0.9486 - f1: 0.9486 - precision: 0.9513 - recall: 0.9459 - val_loss: 0.9322 - val_accuracy: 0.7692 - val_f1: 0.7640 - val_precision: 0.7751 - val_recall: 0.7533\n",
            "Epoch 36/60\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.1911 - accuracy: 0.9523 - f1: 0.9531 - precision: 0.9569 - recall: 0.9494 - val_loss: 1.0260 - val_accuracy: 0.7467 - val_f1: 0.7486 - val_precision: 0.7566 - val_recall: 0.7408\n",
            "Epoch 37/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.2044 - accuracy: 0.9454 - f1: 0.9465 - precision: 0.9514 - recall: 0.9418 - val_loss: 1.0360 - val_accuracy: 0.7258 - val_f1: 0.7292 - val_precision: 0.7422 - val_recall: 0.7167\n",
            "Epoch 38/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.3468 - accuracy: 0.8954 - f1: 0.8953 - precision: 0.9069 - recall: 0.8841 - val_loss: 0.9597 - val_accuracy: 0.7492 - val_f1: 0.7518 - val_precision: 0.7642 - val_recall: 0.7400\n",
            "Epoch 39/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.2047 - accuracy: 0.9464 - f1: 0.9489 - precision: 0.9567 - recall: 0.9413 - val_loss: 0.9726 - val_accuracy: 0.7533 - val_f1: 0.7532 - val_precision: 0.7689 - val_recall: 0.7383\n",
            "Epoch 40/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.1674 - accuracy: 0.9564 - f1: 0.9567 - precision: 0.9628 - recall: 0.9507 - val_loss: 1.0672 - val_accuracy: 0.7467 - val_f1: 0.7460 - val_precision: 0.7566 - val_recall: 0.7358\n",
            "Epoch 41/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.1746 - accuracy: 0.9521 - f1: 0.9546 - precision: 0.9607 - recall: 0.9486 - val_loss: 1.0507 - val_accuracy: 0.7567 - val_f1: 0.7593 - val_precision: 0.7699 - val_recall: 0.7492\n",
            "Epoch 42/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.1487 - accuracy: 0.9628 - f1: 0.9610 - precision: 0.9668 - recall: 0.9552 - val_loss: 0.9847 - val_accuracy: 0.7558 - val_f1: 0.7554 - val_precision: 0.7687 - val_recall: 0.7425\n",
            "Epoch 43/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.1516 - accuracy: 0.9631 - f1: 0.9614 - precision: 0.9666 - recall: 0.9562 - val_loss: 0.9138 - val_accuracy: 0.7617 - val_f1: 0.7617 - val_precision: 0.7794 - val_recall: 0.7450\n",
            "Epoch 44/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.1620 - accuracy: 0.9620 - f1: 0.9599 - precision: 0.9674 - recall: 0.9525 - val_loss: 0.9885 - val_accuracy: 0.7625 - val_f1: 0.7618 - val_precision: 0.7760 - val_recall: 0.7483\n",
            "Epoch 45/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.1304 - accuracy: 0.9670 - f1: 0.9669 - precision: 0.9710 - recall: 0.9630 - val_loss: 0.9524 - val_accuracy: 0.7708 - val_f1: 0.7737 - val_precision: 0.7871 - val_recall: 0.7608\n",
            "Epoch 46/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.1833 - accuracy: 0.9555 - f1: 0.9568 - precision: 0.9612 - recall: 0.9526 - val_loss: 0.9761 - val_accuracy: 0.7667 - val_f1: 0.7694 - val_precision: 0.7799 - val_recall: 0.7592\n",
            "Epoch 47/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.1443 - accuracy: 0.9633 - f1: 0.9629 - precision: 0.9657 - recall: 0.9602 - val_loss: 1.0970 - val_accuracy: 0.7633 - val_f1: 0.7640 - val_precision: 0.7698 - val_recall: 0.7583\n",
            "Epoch 48/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.1189 - accuracy: 0.9681 - f1: 0.9690 - precision: 0.9719 - recall: 0.9661 - val_loss: 1.0981 - val_accuracy: 0.7633 - val_f1: 0.7641 - val_precision: 0.7709 - val_recall: 0.7575\n",
            "Epoch 49/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.1217 - accuracy: 0.9657 - f1: 0.9669 - precision: 0.9697 - recall: 0.9642 - val_loss: 1.0915 - val_accuracy: 0.7567 - val_f1: 0.7579 - val_precision: 0.7652 - val_recall: 0.7508\n",
            "Epoch 50/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.1023 - accuracy: 0.9717 - f1: 0.9723 - precision: 0.9739 - recall: 0.9707 - val_loss: 1.0801 - val_accuracy: 0.7675 - val_f1: 0.7735 - val_precision: 0.7831 - val_recall: 0.7642\n",
            "Epoch 51/60\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.0974 - accuracy: 0.9750 - f1: 0.9757 - precision: 0.9787 - recall: 0.9727 - val_loss: 1.1780 - val_accuracy: 0.7533 - val_f1: 0.7518 - val_precision: 0.7605 - val_recall: 0.7433\n",
            "Epoch 52/60\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.1660 - accuracy: 0.9568 - f1: 0.9574 - precision: 0.9637 - recall: 0.9511 - val_loss: 1.1542 - val_accuracy: 0.7500 - val_f1: 0.7495 - val_precision: 0.7559 - val_recall: 0.7433\n",
            "Epoch 53/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.1642 - accuracy: 0.9580 - f1: 0.9585 - precision: 0.9630 - recall: 0.9540 - val_loss: 1.1419 - val_accuracy: 0.7383 - val_f1: 0.7408 - val_precision: 0.7485 - val_recall: 0.7333\n",
            "Epoch 54/60\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.2114 - accuracy: 0.9461 - f1: 0.9461 - precision: 0.9505 - recall: 0.9418 - val_loss: 1.0367 - val_accuracy: 0.7383 - val_f1: 0.7378 - val_precision: 0.7502 - val_recall: 0.7258\n",
            "Epoch 55/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.1683 - accuracy: 0.9575 - f1: 0.9583 - precision: 0.9638 - recall: 0.9528 - val_loss: 1.0737 - val_accuracy: 0.7442 - val_f1: 0.7449 - val_precision: 0.7614 - val_recall: 0.7292\n",
            "Epoch 56/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.1317 - accuracy: 0.9609 - f1: 0.9630 - precision: 0.9699 - recall: 0.9564 - val_loss: 1.1459 - val_accuracy: 0.7742 - val_f1: 0.7720 - val_precision: 0.7819 - val_recall: 0.7625\n",
            "Epoch 57/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.1110 - accuracy: 0.9694 - f1: 0.9696 - precision: 0.9743 - recall: 0.9650 - val_loss: 1.3599 - val_accuracy: 0.7600 - val_f1: 0.7577 - val_precision: 0.7700 - val_recall: 0.7458\n",
            "Epoch 58/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.2922 - accuracy: 0.9349 - f1: 0.9372 - precision: 0.9461 - recall: 0.9286 - val_loss: 1.0486 - val_accuracy: 0.7558 - val_f1: 0.7556 - val_precision: 0.7665 - val_recall: 0.7450\n",
            "Epoch 59/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.1321 - accuracy: 0.9645 - f1: 0.9645 - precision: 0.9723 - recall: 0.9569 - val_loss: 1.0563 - val_accuracy: 0.7700 - val_f1: 0.7717 - val_precision: 0.7820 - val_recall: 0.7617\n",
            "Epoch 60/60\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.1034 - accuracy: 0.9707 - f1: 0.9709 - precision: 0.9754 - recall: 0.9665 - val_loss: 1.0692 - val_accuracy: 0.7683 - val_f1: 0.7730 - val_precision: 0.7829 - val_recall: 0.7633\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 1.0203 - accuracy: 0.7793 - f1: 0.7819 - precision: 0.7944 - recall: 0.7700\n",
            "[1.0203205347061157, 0.779285728931427, 0.7819439768791199, 0.794352114200592, 0.7699999809265137]\n",
            "GLOVE_LSTM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKM9PEwm1fkb",
        "outputId": "609b5605-7fe2-4d32-dfb5-2f9c7a2d8592"
      },
      "source": [
        "model_glove_bi = tf.keras.Sequential()\r\n",
        "model_glove_bi.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_glove_bi.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64),merge_mode='concat'))\r\n",
        "model_glove_bi.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_glove_bi.add(tf.keras.layers.Dense(64,activation='relu'))\r\n",
        "model_glove_bi.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_glove_bi.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_glove_bi.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy',f1,precision,recall])\r\n",
        "history_glove_bi = model_glove_bi.fit_generator(glove_train_gen,validation_data=glove_val_gen,validation_steps=int((len(X_val)/batch_size)+1),steps_per_epoch=int((len(X_train)/batch_size)+1),epochs=epochs)\r\n",
        "history = model_glove_bi.evaluate(x = glove_gen(vocab_glove,X_test,y_test,batch_size,Max_input_size,Embedding_size),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table[7]=history[1]\r\n",
        "print(\"GLOVE_BI\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "46/46 [==============================] - 4s 43ms/step - loss: 1.3811 - accuracy: 0.2928 - f1: 3.8613e-04 - precision: 0.0186 - recall: 1.9518e-04 - val_loss: 1.2981 - val_accuracy: 0.4275 - val_f1: 0.0033 - val_precision: 0.1667 - val_recall: 0.0017\n",
            "Epoch 2/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1.2371 - accuracy: 0.4530 - f1: 0.1612 - precision: 0.7178 - recall: 0.0978 - val_loss: 1.0614 - val_accuracy: 0.5558 - val_f1: 0.4637 - val_precision: 0.6730 - val_recall: 0.3550\n",
            "Epoch 3/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.9955 - accuracy: 0.6020 - f1: 0.5141 - precision: 0.6999 - recall: 0.4080 - val_loss: 0.8939 - val_accuracy: 0.6458 - val_f1: 0.6087 - val_precision: 0.7259 - val_recall: 0.5250\n",
            "Epoch 4/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.7823 - accuracy: 0.6988 - f1: 0.6722 - precision: 0.7717 - recall: 0.5967 - val_loss: 0.8174 - val_accuracy: 0.6800 - val_f1: 0.6692 - val_precision: 0.7342 - val_recall: 0.6150\n",
            "Epoch 5/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.6255 - accuracy: 0.7779 - f1: 0.7641 - precision: 0.8256 - recall: 0.7116 - val_loss: 0.7724 - val_accuracy: 0.7150 - val_f1: 0.7070 - val_precision: 0.7466 - val_recall: 0.6717\n",
            "Epoch 6/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.5366 - accuracy: 0.8094 - f1: 0.7950 - precision: 0.8464 - recall: 0.7501 - val_loss: 0.7056 - val_accuracy: 0.7275 - val_f1: 0.7257 - val_precision: 0.7637 - val_recall: 0.6917\n",
            "Epoch 7/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.4461 - accuracy: 0.8382 - f1: 0.8382 - precision: 0.8770 - recall: 0.8030 - val_loss: 0.7416 - val_accuracy: 0.7275 - val_f1: 0.7269 - val_precision: 0.7652 - val_recall: 0.6925\n",
            "Epoch 8/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.3795 - accuracy: 0.8626 - f1: 0.8643 - precision: 0.8961 - recall: 0.8351 - val_loss: 0.6563 - val_accuracy: 0.7600 - val_f1: 0.7612 - val_precision: 0.7886 - val_recall: 0.7358\n",
            "Epoch 9/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.3163 - accuracy: 0.8889 - f1: 0.8877 - precision: 0.9067 - recall: 0.8696 - val_loss: 0.7473 - val_accuracy: 0.7517 - val_f1: 0.7496 - val_precision: 0.7677 - val_recall: 0.7325\n",
            "Epoch 10/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.2476 - accuracy: 0.9125 - f1: 0.9133 - precision: 0.9287 - recall: 0.8985 - val_loss: 0.8318 - val_accuracy: 0.7500 - val_f1: 0.7522 - val_precision: 0.7677 - val_recall: 0.7375\n",
            "Epoch 11/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.2266 - accuracy: 0.9195 - f1: 0.9208 - precision: 0.9364 - recall: 0.9058 - val_loss: 0.7844 - val_accuracy: 0.7500 - val_f1: 0.7491 - val_precision: 0.7620 - val_recall: 0.7367\n",
            "Epoch 12/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.2158 - accuracy: 0.9157 - f1: 0.9159 - precision: 0.9299 - recall: 0.9026 - val_loss: 0.8428 - val_accuracy: 0.7575 - val_f1: 0.7579 - val_precision: 0.7677 - val_recall: 0.7483\n",
            "Epoch 13/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.2134 - accuracy: 0.9261 - f1: 0.9273 - precision: 0.9394 - recall: 0.9157 - val_loss: 0.8374 - val_accuracy: 0.7592 - val_f1: 0.7580 - val_precision: 0.7690 - val_recall: 0.7475\n",
            "Epoch 14/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.2225 - accuracy: 0.9232 - f1: 0.9206 - precision: 0.9340 - recall: 0.9078 - val_loss: 0.7496 - val_accuracy: 0.7842 - val_f1: 0.7859 - val_precision: 0.7990 - val_recall: 0.7733\n",
            "Epoch 15/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.1564 - accuracy: 0.9449 - f1: 0.9446 - precision: 0.9495 - recall: 0.9397 - val_loss: 0.7980 - val_accuracy: 0.7842 - val_f1: 0.7880 - val_precision: 0.7970 - val_recall: 0.7792\n",
            "Epoch 16/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.1226 - accuracy: 0.9548 - f1: 0.9537 - precision: 0.9584 - recall: 0.9490 - val_loss: 0.8742 - val_accuracy: 0.7750 - val_f1: 0.7780 - val_precision: 0.7863 - val_recall: 0.7700\n",
            "Epoch 17/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.1101 - accuracy: 0.9627 - f1: 0.9629 - precision: 0.9663 - recall: 0.9596 - val_loss: 0.8226 - val_accuracy: 0.7742 - val_f1: 0.7733 - val_precision: 0.7801 - val_recall: 0.7667\n",
            "Epoch 18/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.0940 - accuracy: 0.9623 - f1: 0.9621 - precision: 0.9664 - recall: 0.9579 - val_loss: 0.7979 - val_accuracy: 0.7825 - val_f1: 0.7840 - val_precision: 0.7916 - val_recall: 0.7767\n",
            "Epoch 19/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.0827 - accuracy: 0.9661 - f1: 0.9659 - precision: 0.9691 - recall: 0.9627 - val_loss: 0.9476 - val_accuracy: 0.7758 - val_f1: 0.7749 - val_precision: 0.7807 - val_recall: 0.7692\n",
            "Epoch 20/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0928 - accuracy: 0.9645 - f1: 0.9649 - precision: 0.9685 - recall: 0.9613 - val_loss: 0.9201 - val_accuracy: 0.7783 - val_f1: 0.7790 - val_precision: 0.7856 - val_recall: 0.7725\n",
            "Epoch 21/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.1039 - accuracy: 0.9597 - f1: 0.9616 - precision: 0.9643 - recall: 0.9589 - val_loss: 0.8375 - val_accuracy: 0.7808 - val_f1: 0.7820 - val_precision: 0.7936 - val_recall: 0.7708\n",
            "Epoch 22/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.0897 - accuracy: 0.9661 - f1: 0.9644 - precision: 0.9679 - recall: 0.9610 - val_loss: 0.8621 - val_accuracy: 0.7792 - val_f1: 0.7810 - val_precision: 0.7889 - val_recall: 0.7733\n",
            "Epoch 23/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.0929 - accuracy: 0.9616 - f1: 0.9611 - precision: 0.9660 - recall: 0.9564 - val_loss: 0.8578 - val_accuracy: 0.7883 - val_f1: 0.7896 - val_precision: 0.7960 - val_recall: 0.7833\n",
            "Epoch 24/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.0727 - accuracy: 0.9731 - f1: 0.9725 - precision: 0.9752 - recall: 0.9699 - val_loss: 0.9071 - val_accuracy: 0.7783 - val_f1: 0.7777 - val_precision: 0.7857 - val_recall: 0.7700\n",
            "Epoch 25/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.0619 - accuracy: 0.9768 - f1: 0.9765 - precision: 0.9780 - recall: 0.9750 - val_loss: 0.9396 - val_accuracy: 0.7900 - val_f1: 0.7882 - val_precision: 0.7940 - val_recall: 0.7825\n",
            "Epoch 26/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.0540 - accuracy: 0.9785 - f1: 0.9780 - precision: 0.9788 - recall: 0.9772 - val_loss: 1.0285 - val_accuracy: 0.7758 - val_f1: 0.7757 - val_precision: 0.7798 - val_recall: 0.7717\n",
            "Epoch 27/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.0477 - accuracy: 0.9825 - f1: 0.9822 - precision: 0.9828 - recall: 0.9815 - val_loss: 1.0709 - val_accuracy: 0.7750 - val_f1: 0.7765 - val_precision: 0.7798 - val_recall: 0.7733\n",
            "Epoch 28/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.0546 - accuracy: 0.9757 - f1: 0.9758 - precision: 0.9762 - recall: 0.9754 - val_loss: 1.1648 - val_accuracy: 0.7742 - val_f1: 0.7768 - val_precision: 0.7802 - val_recall: 0.7733\n",
            "Epoch 29/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.0521 - accuracy: 0.9768 - f1: 0.9771 - precision: 0.9774 - recall: 0.9768 - val_loss: 1.0959 - val_accuracy: 0.7833 - val_f1: 0.7842 - val_precision: 0.7869 - val_recall: 0.7817\n",
            "Epoch 30/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.0447 - accuracy: 0.9801 - f1: 0.9798 - precision: 0.9813 - recall: 0.9783 - val_loss: 1.2103 - val_accuracy: 0.7858 - val_f1: 0.7865 - val_precision: 0.7897 - val_recall: 0.7833\n",
            "Epoch 31/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0475 - accuracy: 0.9767 - f1: 0.9764 - precision: 0.9775 - recall: 0.9752 - val_loss: 1.3414 - val_accuracy: 0.7733 - val_f1: 0.7739 - val_precision: 0.7761 - val_recall: 0.7717\n",
            "Epoch 32/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.0456 - accuracy: 0.9751 - f1: 0.9751 - precision: 0.9759 - recall: 0.9743 - val_loss: 1.2963 - val_accuracy: 0.7733 - val_f1: 0.7720 - val_precision: 0.7748 - val_recall: 0.7692\n",
            "Epoch 33/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0453 - accuracy: 0.9748 - f1: 0.9750 - precision: 0.9756 - recall: 0.9745 - val_loss: 1.2914 - val_accuracy: 0.7717 - val_f1: 0.7722 - val_precision: 0.7745 - val_recall: 0.7700\n",
            "Epoch 34/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0467 - accuracy: 0.9776 - f1: 0.9778 - precision: 0.9792 - recall: 0.9765 - val_loss: 1.2923 - val_accuracy: 0.7758 - val_f1: 0.7777 - val_precision: 0.7795 - val_recall: 0.7758\n",
            "Epoch 35/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.0620 - accuracy: 0.9718 - f1: 0.9711 - precision: 0.9728 - recall: 0.9694 - val_loss: 1.1758 - val_accuracy: 0.7717 - val_f1: 0.7742 - val_precision: 0.7768 - val_recall: 0.7717\n",
            "Epoch 36/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0490 - accuracy: 0.9767 - f1: 0.9765 - precision: 0.9789 - recall: 0.9742 - val_loss: 1.1622 - val_accuracy: 0.7792 - val_f1: 0.7786 - val_precision: 0.7815 - val_recall: 0.7758\n",
            "Epoch 37/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.0483 - accuracy: 0.9753 - f1: 0.9757 - precision: 0.9766 - recall: 0.9747 - val_loss: 1.2485 - val_accuracy: 0.7792 - val_f1: 0.7777 - val_precision: 0.7813 - val_recall: 0.7742\n",
            "Epoch 38/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.0454 - accuracy: 0.9729 - f1: 0.9729 - precision: 0.9734 - recall: 0.9725 - val_loss: 1.3412 - val_accuracy: 0.7650 - val_f1: 0.7647 - val_precision: 0.7670 - val_recall: 0.7625\n",
            "Epoch 39/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.0480 - accuracy: 0.9763 - f1: 0.9760 - precision: 0.9769 - recall: 0.9750 - val_loss: 1.3420 - val_accuracy: 0.7467 - val_f1: 0.7480 - val_precision: 0.7503 - val_recall: 0.7458\n",
            "Epoch 40/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.0453 - accuracy: 0.9792 - f1: 0.9793 - precision: 0.9803 - recall: 0.9783 - val_loss: 1.3880 - val_accuracy: 0.7583 - val_f1: 0.7591 - val_precision: 0.7633 - val_recall: 0.7550\n",
            "Epoch 41/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.0433 - accuracy: 0.9754 - f1: 0.9752 - precision: 0.9757 - recall: 0.9747 - val_loss: 1.3533 - val_accuracy: 0.7692 - val_f1: 0.7716 - val_precision: 0.7750 - val_recall: 0.7683\n",
            "Epoch 42/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.0431 - accuracy: 0.9750 - f1: 0.9755 - precision: 0.9781 - recall: 0.9730 - val_loss: 1.4701 - val_accuracy: 0.7575 - val_f1: 0.7588 - val_precision: 0.7627 - val_recall: 0.7550\n",
            "Epoch 43/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.0415 - accuracy: 0.9774 - f1: 0.9781 - precision: 0.9797 - recall: 0.9766 - val_loss: 1.3751 - val_accuracy: 0.7725 - val_f1: 0.7711 - val_precision: 0.7730 - val_recall: 0.7692\n",
            "Epoch 44/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.0454 - accuracy: 0.9738 - f1: 0.9738 - precision: 0.9752 - recall: 0.9724 - val_loss: 1.3011 - val_accuracy: 0.7675 - val_f1: 0.7677 - val_precision: 0.7696 - val_recall: 0.7658\n",
            "Epoch 45/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0502 - accuracy: 0.9735 - f1: 0.9722 - precision: 0.9745 - recall: 0.9699 - val_loss: 1.5713 - val_accuracy: 0.7642 - val_f1: 0.7655 - val_precision: 0.7677 - val_recall: 0.7633\n",
            "Epoch 46/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0438 - accuracy: 0.9749 - f1: 0.9752 - precision: 0.9770 - recall: 0.9735 - val_loss: 1.5689 - val_accuracy: 0.7625 - val_f1: 0.7630 - val_precision: 0.7643 - val_recall: 0.7617\n",
            "Epoch 47/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0479 - accuracy: 0.9707 - f1: 0.9715 - precision: 0.9727 - recall: 0.9703 - val_loss: 1.5203 - val_accuracy: 0.7633 - val_f1: 0.7631 - val_precision: 0.7670 - val_recall: 0.7592\n",
            "Epoch 48/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0493 - accuracy: 0.9725 - f1: 0.9728 - precision: 0.9741 - recall: 0.9715 - val_loss: 1.3377 - val_accuracy: 0.7625 - val_f1: 0.7615 - val_precision: 0.7638 - val_recall: 0.7592\n",
            "Epoch 49/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0546 - accuracy: 0.9750 - f1: 0.9750 - precision: 0.9775 - recall: 0.9724 - val_loss: 1.4397 - val_accuracy: 0.7625 - val_f1: 0.7618 - val_precision: 0.7637 - val_recall: 0.7600\n",
            "Epoch 50/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0419 - accuracy: 0.9769 - f1: 0.9781 - precision: 0.9800 - recall: 0.9763 - val_loss: 1.4875 - val_accuracy: 0.7575 - val_f1: 0.7578 - val_precision: 0.7581 - val_recall: 0.7575\n",
            "Epoch 51/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0461 - accuracy: 0.9783 - f1: 0.9781 - precision: 0.9793 - recall: 0.9769 - val_loss: 1.4083 - val_accuracy: 0.7742 - val_f1: 0.7742 - val_precision: 0.7768 - val_recall: 0.7717\n",
            "Epoch 52/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.0507 - accuracy: 0.9728 - f1: 0.9724 - precision: 0.9752 - recall: 0.9696 - val_loss: 1.2253 - val_accuracy: 0.7900 - val_f1: 0.7893 - val_precision: 0.7936 - val_recall: 0.7850\n",
            "Epoch 53/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0498 - accuracy: 0.9715 - f1: 0.9728 - precision: 0.9746 - recall: 0.9711 - val_loss: 1.3068 - val_accuracy: 0.7642 - val_f1: 0.7646 - val_precision: 0.7659 - val_recall: 0.7633\n",
            "Epoch 54/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0500 - accuracy: 0.9727 - f1: 0.9718 - precision: 0.9745 - recall: 0.9692 - val_loss: 1.2919 - val_accuracy: 0.7725 - val_f1: 0.7726 - val_precision: 0.7736 - val_recall: 0.7717\n",
            "Epoch 55/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0425 - accuracy: 0.9771 - f1: 0.9771 - precision: 0.9787 - recall: 0.9754 - val_loss: 1.3873 - val_accuracy: 0.7708 - val_f1: 0.7721 - val_precision: 0.7750 - val_recall: 0.7692\n",
            "Epoch 56/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.0349 - accuracy: 0.9801 - f1: 0.9813 - precision: 0.9829 - recall: 0.9797 - val_loss: 1.4516 - val_accuracy: 0.7725 - val_f1: 0.7735 - val_precision: 0.7745 - val_recall: 0.7725\n",
            "Epoch 57/60\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.0380 - accuracy: 0.9795 - f1: 0.9794 - precision: 0.9809 - recall: 0.9780 - val_loss: 1.4511 - val_accuracy: 0.7783 - val_f1: 0.7765 - val_precision: 0.7788 - val_recall: 0.7742\n",
            "Epoch 58/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0346 - accuracy: 0.9771 - f1: 0.9778 - precision: 0.9794 - recall: 0.9764 - val_loss: 1.4724 - val_accuracy: 0.7850 - val_f1: 0.7850 - val_precision: 0.7894 - val_recall: 0.7808\n",
            "Epoch 59/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0341 - accuracy: 0.9796 - f1: 0.9804 - precision: 0.9821 - recall: 0.9788 - val_loss: 1.5157 - val_accuracy: 0.7725 - val_f1: 0.7706 - val_precision: 0.7730 - val_recall: 0.7683\n",
            "Epoch 60/60\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0331 - accuracy: 0.9821 - f1: 0.9820 - precision: 0.9849 - recall: 0.9792 - val_loss: 1.4827 - val_accuracy: 0.7792 - val_f1: 0.7778 - val_precision: 0.7798 - val_recall: 0.7758\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 1.3298 - accuracy: 0.8064 - f1: 0.8067 - precision: 0.8084 - recall: 0.8050\n",
            "[1.3298308849334717, 0.8064285516738892, 0.8067120909690857, 0.8084415197372437, 0.8049999475479126]\n",
            "GLOVE_BI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQBa5s4s1hNU",
        "outputId": "c05a68ee-00d7-46e5-869a-99eb0b84cf7e"
      },
      "source": [
        "model_glove_rnn = tf.keras.Sequential()\r\n",
        "model_glove_rnn.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_glove_rnn.add(tf.keras.layers.SimpleRNN(64))\r\n",
        "model_glove_rnn.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_glove_rnn.add(tf.keras.layers.Dense(64,activation='relu'))\r\n",
        "model_glove_rnn.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_glove_rnn.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_glove_rnn.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy',f1,precision,recall])\r\n",
        "history_glove_rnn = model_glove_rnn.fit_generator(glove_train_gen,validation_data=glove_val_gen,validation_steps=int((len(X_val)/batch_size)+1),steps_per_epoch=int((len(X_train)/batch_size)+1),epochs=epochs)\r\n",
        "history = model_glove_rnn.evaluate(x = glove_gen(vocab_glove,X_test,y_test,batch_size,Max_input_size,Embedding_size),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table[8]=history[1]\r\n",
        "print(\"GLOVE_RNN\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "46/46 [==============================] - 4s 60ms/step - loss: 1.3857 - accuracy: 0.2779 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3749 - val_accuracy: 0.3292 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/60\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 1.3768 - accuracy: 0.3014 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3684 - val_accuracy: 0.3250 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/60\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 1.3803 - accuracy: 0.2955 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3675 - val_accuracy: 0.3358 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/60\n",
            "46/46 [==============================] - 2s 53ms/step - loss: 1.3663 - accuracy: 0.3160 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3678 - val_accuracy: 0.3300 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 5/60\n",
            "46/46 [==============================] - 2s 53ms/step - loss: 1.3573 - accuracy: 0.3201 - f1: 2.5004e-04 - precision: 0.0050 - recall: 1.2869e-04 - val_loss: 1.3544 - val_accuracy: 0.3325 - val_f1: 0.0017 - val_precision: 0.0833 - val_recall: 8.3333e-04\n",
            "Epoch 6/60\n",
            "46/46 [==============================] - 2s 54ms/step - loss: 1.3126 - accuracy: 0.3830 - f1: 0.0648 - precision: 0.5374 - recall: 0.0354 - val_loss: 1.3313 - val_accuracy: 0.3533 - val_f1: 0.1552 - val_precision: 0.4849 - val_recall: 0.0933\n",
            "Epoch 7/60\n",
            "46/46 [==============================] - 2s 54ms/step - loss: 1.2519 - accuracy: 0.4264 - f1: 0.1736 - precision: 0.6365 - recall: 0.1046 - val_loss: 1.2962 - val_accuracy: 0.3967 - val_f1: 0.1824 - val_precision: 0.5492 - val_recall: 0.1100\n",
            "Epoch 8/60\n",
            "46/46 [==============================] - 2s 55ms/step - loss: 1.2066 - accuracy: 0.4391 - f1: 0.2433 - precision: 0.6337 - recall: 0.1522 - val_loss: 1.2936 - val_accuracy: 0.4108 - val_f1: 0.1811 - val_precision: 0.5851 - val_recall: 0.1075\n",
            "Epoch 9/60\n",
            "46/46 [==============================] - 3s 56ms/step - loss: 1.1832 - accuracy: 0.4659 - f1: 0.2683 - precision: 0.6244 - recall: 0.1738 - val_loss: 1.3102 - val_accuracy: 0.3925 - val_f1: 0.2178 - val_precision: 0.5158 - val_recall: 0.1383\n",
            "Epoch 10/60\n",
            "46/46 [==============================] - 3s 57ms/step - loss: 1.1344 - accuracy: 0.4968 - f1: 0.3153 - precision: 0.6602 - recall: 0.2104 - val_loss: 1.4076 - val_accuracy: 0.4125 - val_f1: 0.2896 - val_precision: 0.4477 - val_recall: 0.2142\n",
            "Epoch 11/60\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 1.1144 - accuracy: 0.5144 - f1: 0.3901 - precision: 0.6413 - recall: 0.2829 - val_loss: 1.3034 - val_accuracy: 0.4142 - val_f1: 0.2909 - val_precision: 0.4851 - val_recall: 0.2083\n",
            "Epoch 12/60\n",
            "46/46 [==============================] - 2s 52ms/step - loss: 1.0665 - accuracy: 0.5217 - f1: 0.4192 - precision: 0.6516 - recall: 0.3118 - val_loss: 1.2958 - val_accuracy: 0.4392 - val_f1: 0.3274 - val_precision: 0.5127 - val_recall: 0.2408\n",
            "Epoch 13/60\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 1.0243 - accuracy: 0.5558 - f1: 0.4631 - precision: 0.6691 - recall: 0.3582 - val_loss: 1.3205 - val_accuracy: 0.4133 - val_f1: 0.3265 - val_precision: 0.5157 - val_recall: 0.2392\n",
            "Epoch 14/60\n",
            "46/46 [==============================] - 2s 53ms/step - loss: 0.9967 - accuracy: 0.5724 - f1: 0.4733 - precision: 0.6687 - recall: 0.3684 - val_loss: 1.3573 - val_accuracy: 0.4417 - val_f1: 0.3602 - val_precision: 0.4590 - val_recall: 0.2967\n",
            "Epoch 15/60\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 1.0059 - accuracy: 0.5647 - f1: 0.4915 - precision: 0.6766 - recall: 0.3908 - val_loss: 1.4045 - val_accuracy: 0.4008 - val_f1: 0.3395 - val_precision: 0.4564 - val_recall: 0.2708\n",
            "Epoch 16/60\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 0.9864 - accuracy: 0.5811 - f1: 0.5088 - precision: 0.6679 - recall: 0.4142 - val_loss: 1.5667 - val_accuracy: 0.3658 - val_f1: 0.2894 - val_precision: 0.3528 - val_recall: 0.2458\n",
            "Epoch 17/60\n",
            "46/46 [==============================] - 2s 54ms/step - loss: 0.9827 - accuracy: 0.5900 - f1: 0.4997 - precision: 0.6757 - recall: 0.3974 - val_loss: 1.4804 - val_accuracy: 0.3892 - val_f1: 0.3228 - val_precision: 0.4023 - val_recall: 0.2700\n",
            "Epoch 18/60\n",
            "46/46 [==============================] - 2s 54ms/step - loss: 1.0500 - accuracy: 0.5501 - f1: 0.4858 - precision: 0.6346 - recall: 0.3958 - val_loss: 1.4105 - val_accuracy: 0.4200 - val_f1: 0.3586 - val_precision: 0.4644 - val_recall: 0.2925\n",
            "Epoch 19/60\n",
            "46/46 [==============================] - 2s 54ms/step - loss: 0.9674 - accuracy: 0.5889 - f1: 0.5104 - precision: 0.6849 - recall: 0.4096 - val_loss: 1.4942 - val_accuracy: 0.4267 - val_f1: 0.3904 - val_precision: 0.4560 - val_recall: 0.3417\n",
            "Epoch 20/60\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 0.9255 - accuracy: 0.6019 - f1: 0.5558 - precision: 0.6862 - recall: 0.4698 - val_loss: 1.4762 - val_accuracy: 0.4258 - val_f1: 0.3870 - val_precision: 0.4541 - val_recall: 0.3375\n",
            "Epoch 21/60\n",
            "46/46 [==============================] - 2s 55ms/step - loss: 0.8913 - accuracy: 0.6390 - f1: 0.6092 - precision: 0.7193 - recall: 0.5297 - val_loss: 1.4057 - val_accuracy: 0.4542 - val_f1: 0.4098 - val_precision: 0.4784 - val_recall: 0.3592\n",
            "Epoch 22/60\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 0.8322 - accuracy: 0.6697 - f1: 0.6365 - precision: 0.7370 - recall: 0.5610 - val_loss: 1.4328 - val_accuracy: 0.4642 - val_f1: 0.4224 - val_precision: 0.4799 - val_recall: 0.3775\n",
            "Epoch 23/60\n",
            "46/46 [==============================] - 3s 56ms/step - loss: 0.8049 - accuracy: 0.6750 - f1: 0.6508 - precision: 0.7356 - recall: 0.5849 - val_loss: 1.4504 - val_accuracy: 0.4592 - val_f1: 0.4305 - val_precision: 0.4903 - val_recall: 0.3842\n",
            "Epoch 24/60\n",
            "46/46 [==============================] - 2s 54ms/step - loss: 0.8596 - accuracy: 0.6613 - f1: 0.6353 - precision: 0.7251 - recall: 0.5668 - val_loss: 1.3667 - val_accuracy: 0.4525 - val_f1: 0.4042 - val_precision: 0.4891 - val_recall: 0.3450\n",
            "Epoch 25/60\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 0.8186 - accuracy: 0.6731 - f1: 0.6433 - precision: 0.7498 - recall: 0.5647 - val_loss: 1.5314 - val_accuracy: 0.4525 - val_f1: 0.4211 - val_precision: 0.4674 - val_recall: 0.3833\n",
            "Epoch 26/60\n",
            "46/46 [==============================] - 2s 53ms/step - loss: 0.7858 - accuracy: 0.6991 - f1: 0.6798 - precision: 0.7590 - recall: 0.6168 - val_loss: 1.4680 - val_accuracy: 0.4442 - val_f1: 0.4122 - val_precision: 0.4698 - val_recall: 0.3675\n",
            "Epoch 27/60\n",
            "46/46 [==============================] - 3s 54ms/step - loss: 0.7655 - accuracy: 0.6971 - f1: 0.6800 - precision: 0.7604 - recall: 0.6161 - val_loss: 1.5291 - val_accuracy: 0.4550 - val_f1: 0.4274 - val_precision: 0.4794 - val_recall: 0.3858\n",
            "Epoch 28/60\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 0.7359 - accuracy: 0.7149 - f1: 0.7007 - precision: 0.7707 - recall: 0.6430 - val_loss: 1.6104 - val_accuracy: 0.4233 - val_f1: 0.4026 - val_precision: 0.4441 - val_recall: 0.3683\n",
            "Epoch 29/60\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 0.7182 - accuracy: 0.7259 - f1: 0.7131 - precision: 0.7714 - recall: 0.6637 - val_loss: 1.6741 - val_accuracy: 0.4083 - val_f1: 0.3890 - val_precision: 0.4318 - val_recall: 0.3542\n",
            "Epoch 30/60\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 0.7189 - accuracy: 0.7148 - f1: 0.7004 - precision: 0.7685 - recall: 0.6439 - val_loss: 1.7152 - val_accuracy: 0.4292 - val_f1: 0.4119 - val_precision: 0.4489 - val_recall: 0.3808\n",
            "Epoch 31/60\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 0.7453 - accuracy: 0.7044 - f1: 0.6979 - precision: 0.7614 - recall: 0.6454 - val_loss: 1.7280 - val_accuracy: 0.4175 - val_f1: 0.3989 - val_precision: 0.4352 - val_recall: 0.3683\n",
            "Epoch 32/60\n",
            "46/46 [==============================] - 3s 56ms/step - loss: 0.7359 - accuracy: 0.7074 - f1: 0.6947 - precision: 0.7617 - recall: 0.6397 - val_loss: 1.6220 - val_accuracy: 0.4300 - val_f1: 0.4074 - val_precision: 0.4551 - val_recall: 0.3692\n",
            "Epoch 33/60\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 0.7820 - accuracy: 0.6905 - f1: 0.6654 - precision: 0.7400 - recall: 0.6049 - val_loss: 1.6584 - val_accuracy: 0.4242 - val_f1: 0.3925 - val_precision: 0.4380 - val_recall: 0.3558\n",
            "Epoch 34/60\n",
            "46/46 [==============================] - 3s 56ms/step - loss: 0.7273 - accuracy: 0.7127 - f1: 0.6970 - precision: 0.7767 - recall: 0.6332 - val_loss: 1.8673 - val_accuracy: 0.4125 - val_f1: 0.3793 - val_precision: 0.4133 - val_recall: 0.3508\n",
            "Epoch 35/60\n",
            "46/46 [==============================] - 3s 56ms/step - loss: 0.8031 - accuracy: 0.6830 - f1: 0.6660 - precision: 0.7362 - recall: 0.6089 - val_loss: 1.8162 - val_accuracy: 0.4000 - val_f1: 0.3782 - val_precision: 0.4177 - val_recall: 0.3458\n",
            "Epoch 36/60\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 0.8289 - accuracy: 0.6798 - f1: 0.6575 - precision: 0.7322 - recall: 0.5972 - val_loss: 1.7976 - val_accuracy: 0.4017 - val_f1: 0.3704 - val_precision: 0.4047 - val_recall: 0.3417\n",
            "Epoch 37/60\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 0.8751 - accuracy: 0.6598 - f1: 0.6384 - precision: 0.7196 - recall: 0.5748 - val_loss: 1.7647 - val_accuracy: 0.4208 - val_f1: 0.4016 - val_precision: 0.4357 - val_recall: 0.3725\n",
            "Epoch 38/60\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 0.8890 - accuracy: 0.6567 - f1: 0.6361 - precision: 0.7255 - recall: 0.5683 - val_loss: 1.7295 - val_accuracy: 0.4458 - val_f1: 0.4147 - val_precision: 0.4476 - val_recall: 0.3867\n",
            "Epoch 39/60\n",
            "46/46 [==============================] - 2s 54ms/step - loss: 0.8196 - accuracy: 0.6891 - f1: 0.6614 - precision: 0.7494 - recall: 0.5935 - val_loss: 1.7091 - val_accuracy: 0.4600 - val_f1: 0.4353 - val_precision: 0.4645 - val_recall: 0.4100\n",
            "Epoch 40/60\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 0.8080 - accuracy: 0.6862 - f1: 0.6627 - precision: 0.7313 - recall: 0.6071 - val_loss: 1.6999 - val_accuracy: 0.4417 - val_f1: 0.4217 - val_precision: 0.4627 - val_recall: 0.3875\n",
            "Epoch 41/60\n",
            "46/46 [==============================] - 2s 54ms/step - loss: 0.7907 - accuracy: 0.6917 - f1: 0.6785 - precision: 0.7502 - recall: 0.6205 - val_loss: 1.7090 - val_accuracy: 0.4267 - val_f1: 0.4015 - val_precision: 0.4403 - val_recall: 0.3692\n",
            "Epoch 42/60\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 0.8106 - accuracy: 0.6789 - f1: 0.6649 - precision: 0.7348 - recall: 0.6082 - val_loss: 1.6780 - val_accuracy: 0.4267 - val_f1: 0.4026 - val_precision: 0.4443 - val_recall: 0.3683\n",
            "Epoch 43/60\n",
            "46/46 [==============================] - 3s 57ms/step - loss: 0.9131 - accuracy: 0.6336 - f1: 0.6059 - precision: 0.6954 - recall: 0.5377 - val_loss: 1.4950 - val_accuracy: 0.4325 - val_f1: 0.3879 - val_precision: 0.4583 - val_recall: 0.3367\n",
            "Epoch 44/60\n",
            "46/46 [==============================] - 2s 54ms/step - loss: 0.8391 - accuracy: 0.6798 - f1: 0.6487 - precision: 0.7483 - recall: 0.5740 - val_loss: 1.5417 - val_accuracy: 0.4308 - val_f1: 0.4016 - val_precision: 0.4673 - val_recall: 0.3525\n",
            "Epoch 45/60\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 0.7509 - accuracy: 0.7106 - f1: 0.6910 - precision: 0.7640 - recall: 0.6313 - val_loss: 1.6152 - val_accuracy: 0.4308 - val_f1: 0.4021 - val_precision: 0.4474 - val_recall: 0.3658\n",
            "Epoch 46/60\n",
            "46/46 [==============================] - 2s 54ms/step - loss: 0.6999 - accuracy: 0.7294 - f1: 0.7117 - precision: 0.7795 - recall: 0.6555 - val_loss: 1.5911 - val_accuracy: 0.4642 - val_f1: 0.4393 - val_precision: 0.4737 - val_recall: 0.4100\n",
            "Epoch 47/60\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 0.7076 - accuracy: 0.7367 - f1: 0.7260 - precision: 0.7809 - recall: 0.6791 - val_loss: 1.6376 - val_accuracy: 0.4408 - val_f1: 0.4226 - val_precision: 0.4571 - val_recall: 0.3933\n",
            "Epoch 48/60\n",
            "46/46 [==============================] - 3s 56ms/step - loss: 0.6928 - accuracy: 0.7390 - f1: 0.7236 - precision: 0.7827 - recall: 0.6732 - val_loss: 1.5644 - val_accuracy: 0.4500 - val_f1: 0.4381 - val_precision: 0.4732 - val_recall: 0.4083\n",
            "Epoch 49/60\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 0.6529 - accuracy: 0.7381 - f1: 0.7282 - precision: 0.7825 - recall: 0.6813 - val_loss: 1.6026 - val_accuracy: 0.4667 - val_f1: 0.4472 - val_precision: 0.4842 - val_recall: 0.4158\n",
            "Epoch 50/60\n",
            "46/46 [==============================] - 2s 54ms/step - loss: 0.6436 - accuracy: 0.7717 - f1: 0.7569 - precision: 0.8064 - recall: 0.7135 - val_loss: 1.6460 - val_accuracy: 0.4350 - val_f1: 0.4142 - val_precision: 0.4474 - val_recall: 0.3858\n",
            "Epoch 51/60\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 0.7374 - accuracy: 0.7253 - f1: 0.7055 - precision: 0.7640 - recall: 0.6557 - val_loss: 1.6224 - val_accuracy: 0.4342 - val_f1: 0.4155 - val_precision: 0.4504 - val_recall: 0.3858\n",
            "Epoch 52/60\n",
            "46/46 [==============================] - 3s 56ms/step - loss: 0.7310 - accuracy: 0.7217 - f1: 0.7086 - precision: 0.7717 - recall: 0.6557 - val_loss: 1.5928 - val_accuracy: 0.4508 - val_f1: 0.4294 - val_precision: 0.4649 - val_recall: 0.3992\n",
            "Epoch 53/60\n",
            "46/46 [==============================] - 3s 57ms/step - loss: 0.7234 - accuracy: 0.7291 - f1: 0.7140 - precision: 0.7729 - recall: 0.6639 - val_loss: 1.6907 - val_accuracy: 0.4408 - val_f1: 0.4208 - val_precision: 0.4526 - val_recall: 0.3933\n",
            "Epoch 54/60\n",
            "46/46 [==============================] - 2s 54ms/step - loss: 0.7254 - accuracy: 0.7141 - f1: 0.7080 - precision: 0.7624 - recall: 0.6618 - val_loss: 1.5903 - val_accuracy: 0.4483 - val_f1: 0.4244 - val_precision: 0.4645 - val_recall: 0.3908\n",
            "Epoch 55/60\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 0.7184 - accuracy: 0.7329 - f1: 0.7141 - precision: 0.7728 - recall: 0.6644 - val_loss: 1.5690 - val_accuracy: 0.4467 - val_f1: 0.4151 - val_precision: 0.4579 - val_recall: 0.3800\n",
            "Epoch 56/60\n",
            "46/46 [==============================] - 2s 54ms/step - loss: 0.7713 - accuracy: 0.7012 - f1: 0.6819 - precision: 0.7438 - recall: 0.6303 - val_loss: 1.5302 - val_accuracy: 0.4417 - val_f1: 0.4264 - val_precision: 0.4657 - val_recall: 0.3933\n",
            "Epoch 57/60\n",
            "46/46 [==============================] - 3s 56ms/step - loss: 0.7097 - accuracy: 0.7395 - f1: 0.7220 - precision: 0.7871 - recall: 0.6675 - val_loss: 1.6561 - val_accuracy: 0.4433 - val_f1: 0.4212 - val_precision: 0.4666 - val_recall: 0.3842\n",
            "Epoch 58/60\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 0.6881 - accuracy: 0.7348 - f1: 0.7175 - precision: 0.7769 - recall: 0.6671 - val_loss: 1.5411 - val_accuracy: 0.4650 - val_f1: 0.4434 - val_precision: 0.4797 - val_recall: 0.4125\n",
            "Epoch 59/60\n",
            "46/46 [==============================] - 3s 56ms/step - loss: 0.6792 - accuracy: 0.7378 - f1: 0.7342 - precision: 0.7878 - recall: 0.6882 - val_loss: 1.6643 - val_accuracy: 0.4758 - val_f1: 0.4508 - val_precision: 0.4814 - val_recall: 0.4242\n",
            "Epoch 60/60\n",
            "46/46 [==============================] - 2s 54ms/step - loss: 0.6298 - accuracy: 0.7685 - f1: 0.7637 - precision: 0.8027 - recall: 0.7287 - val_loss: 1.7411 - val_accuracy: 0.4367 - val_f1: 0.4200 - val_precision: 0.4495 - val_recall: 0.3942\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 1.6886 - accuracy: 0.4357 - f1: 0.4233 - precision: 0.4554 - recall: 0.3957\n",
            "[1.688595175743103, 0.4357142746448517, 0.4232510030269623, 0.45541951060295105, 0.39571431279182434]\n",
            "GLOVE_RNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZqN_SaM3hs9",
        "outputId": "aa1e4683-dee3-4ebf-a862-7990e5097dd7"
      },
      "source": [
        "print(\"\\tLstm\\t\\t\\tBiLstm\\t\\t\\tRnn\")\r\n",
        "print(\"sg\",result_table[:3])\r\n",
        "print(\"cbow\",result_table[3:6])\r\n",
        "print(\"glove\",result_table[6:9])\r\n",
        "# print(history_sg_bi.history)\r\n",
        "# plt.title(\"Skip-Gram + Bi-LSTM accuracy, loss vs epochs Graph\")\r\n",
        "# plt.plot(history_sg_bi.history['loss'],c='b',label='loss')\r\n",
        "# plt.plot(history_sg_bi.history['accuracy'],c='r',label='accuracy')\r\n",
        "# plt.xlabel('epochs')\r\n",
        "# plt.legend()\r\n",
        "# # plt.yticks()\r\n",
        "# plt.show()\r\n",
        "# plt.title(\"GloVe + Bi-LSTM accuracy, loss vs epochs Graph\")\r\n",
        "# plt.plot(history_glove_bi.history['loss'],c='b',label='loss')\r\n",
        "# plt.plot(history_glove_bi.history['accuracy'],c='r',label='accuracy')\r\n",
        "# plt.xlabel('epochs')\r\n",
        "# plt.legend()\r\n",
        "# # plt.yticks()\r\n",
        "# plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tLstm\t\t\tBiLstm\t\t\tRnn\n",
            "sg [0.5878571271896362, 0.6257143020629883, 0.33000001311302185]\n",
            "cbow [0.488571435213089, 0.6150000095367432, 0.37214285135269165]\n",
            "glove [0.779285728931427, 0.8064285516738892, 0.4357142746448517]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}