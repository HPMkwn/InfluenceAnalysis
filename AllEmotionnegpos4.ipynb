{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AllEmotionnegpos4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harrymkwn/InfluenceAnalysis/blob/master/AllEmotionnegpos4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkuKKcIUmM27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf360db9-0ffd-4d7f-8769-6561a0f1a14a"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from gensim.models import Word2Vec\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import  drive\n",
        "drive.mount('/content/drive')\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('all')\n",
        "device_name = tf.test.gpu_device_name()\n",
        "print(device_name)\n",
        "df_train = pd.read_csv('/content/drive/MyDrive/InfluenceAnalysis/Newdata/train_clean.csv',names=['Tweet','Emotion'])\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/InfluenceAnalysis/Newdata/test_clean.csv',names=['Tweet','Emotion'])\n",
        "df_train = df_train.sample(frac=1)\n",
        "df_test = df_train.sample(frac=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n",
            "/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0zrtpGceAiE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "6a64ad66-fabe-4369-fd17-6d051c332d1b"
      },
      "source": [
        "df_train.head(1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8535</th>\n",
              "      <td>michaelbolton yesmet jon last yr at an interes...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4075</th>\n",
              "      <td>will be attend cic parent orient tomorrowne to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8194</th>\n",
              "      <td>at school again it bore and these peopl are pl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10237</th>\n",
              "      <td>ellebella omg I am so sorri anyth i can do to ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6785</th>\n",
              "      <td>wish i wa in chicago</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12109</th>\n",
              "      <td>take care of yucki stuff</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6758</th>\n",
              "      <td>alfiejg i do not think i am my sister refusn t...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12123</th>\n",
              "      <td>i cannot find my woodi and buzz toy but ive go...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11454</th>\n",
              "      <td>theoriginalteam ooh can i have some I am hungr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4175</th>\n",
              "      <td>teejay heyi no love for me no more</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Tweet Emotion\n",
              "8535   michaelbolton yesmet jon last yr at an interes...       2\n",
              "4075   will be attend cic parent orient tomorrowne to...       1\n",
              "8194   at school again it bore and these peopl are pl...       1\n",
              "10237  ellebella omg I am so sorri anyth i can do to ...       0\n",
              "6785                                wish i wa in chicago       2\n",
              "...                                                  ...     ...\n",
              "12109                           take care of yucki stuff       0\n",
              "6758   alfiejg i do not think i am my sister refusn t...       2\n",
              "12123  i cannot find my woodi and buzz toy but ive go...       2\n",
              "11454  theoriginalteam ooh can i have some I am hungr...       0\n",
              "4175                  teejay heyi no love for me no more       2\n",
              "\n",
              "[1000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K68sxL_LfLy7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03a871e2-26fa-4480-c3aa-207f6fca0557"
      },
      "source": [
        "df_test.Emotion.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['0', '2', '1', '3', 'emotion'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9KFGTW2iP8J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "421659a4-7820-4de0-f599-be7e22d7c490"
      },
      "source": [
        "df_train.nunique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tweet      12370\n",
              "Emotion        5\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yV6_xYSnZHt"
      },
      "source": [
        "category_dict = {'0':[1,0,0,0],'1':[0,1,0,0],'2':[0,0,1,0],'3':[0,0,0,1],'emotion':[1,0,0,0]}\n",
        "train_data_tweet = [x.lower().split() for x in df_train['Tweet']]\n",
        "train_data_cat = np.array([category_dict[x] for x in df_train['Emotion']])\n",
        "test_data_tweet = [x.lower().split() for x in df_test['Tweet']]\n",
        "test_data_cat = np.array([category_dict[x] for x in df_test['Emotion']])\n",
        "\n",
        "data_tweet = train_data_tweet + test_data_tweet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdUvNedMzVV-",
        "outputId": "216b161e-f083-4317-940a-fbf085f90c1f"
      },
      "source": [
        "print(len(train_data_cat))\r\n",
        "print(len(test_data_cat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12428\n",
            "12428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mIV-pI5C44j"
      },
      "source": [
        "# Parameters\n",
        "Min_count = 0\n",
        "Embedding_size = 100\n",
        "Window_size = 5\n",
        "Negative_sampling = 00"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUSBfiE0nTVv"
      },
      "source": [
        "w2v_sg = Word2Vec(min_count=Min_count,\n",
        "                     window=Window_size,\n",
        "                     size=Embedding_size,\n",
        "                     negative=Negative_sampling,sg=1)\n",
        "w2v_sg.build_vocab(data_tweet)\n",
        "w2v_sg.train(data_tweet, total_examples=w2v_sg.corpus_count, epochs=5)\n",
        "w2v_cbow = Word2Vec(min_count=Min_count,\n",
        "                     window=Window_size,\n",
        "                     size=Embedding_size,\n",
        "                     negative=Negative_sampling,sg=0)\n",
        "w2v_cbow.build_vocab(data_tweet)\n",
        "w2v_cbow.train(data_tweet, total_examples=w2v_cbow.corpus_count, epochs=5)\n",
        "w2v_sg.wv.init_sims(True)\n",
        "w2v_cbow.wv.init_sims(True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVzquoxb6FQJ"
      },
      "source": [
        "vocab_sg = w2v_sg.wv.vocab\n",
        "vocab_sg = [x for x in vocab_sg]\n",
        "vocab_cbow = w2v_cbow.wv.vocab\n",
        "vocab_cbow = [x for x in vocab_cbow] \n",
        "vocab_glove = {}\n",
        "with open(\"/content/drive/My Drive/InfluenceAnalysis/glove/glove.twitter.27B.100d.txt\", 'r', encoding=\"utf-8\") as f:\n",
        "  for line in f:\n",
        "      values = line.split()\n",
        "      word = values[0]\n",
        "      vector = np.asarray(values[1:], \"float32\")\n",
        "      vocab_glove[word] = vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8ksBvx9Z_ws"
      },
      "source": [
        "def save_dict_to_file(dic):\r\n",
        "    f = open(\"/content/drive/My Drive/InfluenceAnalysis/vocab1.txt\",'w')\r\n",
        "    for i in dic:\r\n",
        "      f.write(str(i)+\"\\t\")\r\n",
        "      f.write(str(w2v_sg.wv.get_vector(i)))\r\n",
        "      f.write(\"\\n\")\r\n",
        "    f.close()\r\n",
        "save_dict_to_file(vocab_sg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdgSI9FSmw60"
      },
      "source": [
        "batch_size = 500\r\n",
        "Max_input_size = max([len(x) for x in data_tweet])\r\n",
        "mul_factor=1.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z65iXVhlpeDX"
      },
      "source": [
        "positive = pd.read_csv('/content/drive/My Drive/InfluenceAnalysis/CodeMix/positive-words.csv')\r\n",
        "positive = list(positive['0'][1:])\r\n",
        "negative = pd.read_csv('/content/drive/My Drive/InfluenceAnalysis/CodeMix/negative-words.csv')\r\n",
        "negative = list(negative['0'][2:])\r\n",
        "pn_dict = {}\r\n",
        "for i in range(len(positive)):\r\n",
        "  pn_dict[positive[i]] = 1\r\n",
        "\r\n",
        "for i in range(len(negative)):\r\n",
        "  pn_dict[negative[i]] = -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqvzy05D2iim"
      },
      "source": [
        "X_train = train_data_tweet\r\n",
        "X_test = test_data_tweet\r\n",
        "y_train = train_data_cat\r\n",
        "y_test = test_data_cat \r\n",
        "X_train = [nltk.pos_tag(x) for x in X_train]\r\n",
        "X_test = [nltk.pos_tag(x) for x in X_test]\r\n",
        "X_train = [[(i[0],i[1],pn_dict.get(i[0],1)) for i in x] for x in X_train]\r\n",
        "X_test = [[(i[0],i[1],pn_dict.get(i[0],1)) for i in x] for x in X_test]\r\n",
        "result_table = [0,0,0,0,0,0,0,0,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIGpYOBRx-kf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArwAlW-wmZxv"
      },
      "source": [
        "def vec_gen(w2v,vocab,data_tweet,data_cat,batch_size,Max_input_size,Embedding_size,mul_factor):\r\n",
        "  while True:\r\n",
        "    for k in range(int(len(data_tweet)/batch_size)):\r\n",
        "      res=[]\r\n",
        "      for x in data_tweet[k*(batch_size):(k+1)*(batch_size)]:\r\n",
        "        tweet = [(w2v.wv.word_vec(i[0]),i[1],i[2]) for i in x if i[0] in vocab]\r\n",
        "        l=len(tweet)\r\n",
        "        for i in range(l):\r\n",
        "          tweet[i]=((tweet[i][0]*tweet[i][2]),tweet[i][1],tweet[i][2])\r\n",
        "        for i in range(l):\r\n",
        "          if tweet[i][1][:2]=='JJ' or tweet[i][1][:2]=='RB':\r\n",
        "            tweet[i]=((tweet[i][0]*mul_factor),tweet[i][1],tweet[i][2])\r\n",
        "        for i in range(l):\r\n",
        "          if tweet[i][1][:2]=='JJ':\r\n",
        "            for z in range(max(i-2,0),min(i+3,l)):\r\n",
        "              if tweet[z][1][:2]=='NN':\r\n",
        "                tweet[z]=((tweet[z][0]+tweet[i][0]),tweet[z][1])\r\n",
        "          if tweet[i][1][:2]=='RB':\r\n",
        "            for z in range(max(i-2,0),min(i+3,l)):\r\n",
        "              if tweet[z][1][:2]=='VB':\r\n",
        "                tweet[z]=((tweet[z][0]+tweet[i][0]),tweet[z][1])\r\n",
        "        res+=[np.array([x[0] for x in tweet])]\r\n",
        "      temp = np.array([np.pad(z.flatten(),(0,Max_input_size*Embedding_size-len(z.flatten()))).reshape(Max_input_size,Embedding_size) for z in res])\r\n",
        "      tempres = data_cat[k*(batch_size):(k+1)*(batch_size)]\r\n",
        "      yield (temp,tempres)          \r\n",
        "      \r\n",
        "def glove_gen(vocab,data_tweet,data_cat,batch_size,Max_input_size,Embedding_size,mul_factor):\r\n",
        "  while True:\r\n",
        "    for k in range(int(len(data_tweet)/batch_size)):\r\n",
        "      res=[]\r\n",
        "      for x in data_tweet[k*(batch_size):(k+1)*(batch_size)]:\r\n",
        "        tweet = [(vocab[i[0]],i[1],i[2]) for i in x if i[0] in vocab.keys()]\r\n",
        "        l=len(tweet)\r\n",
        "        for i in range(l):\r\n",
        "          tweet[i]=((tweet[i][0]*tweet[i][2]),tweet[i][1],tweet[i][2])\r\n",
        "        for i in range(l):\r\n",
        "          if tweet[i][1][:2]=='JJ' or tweet[i][1][:2]=='RB':\r\n",
        "            tweet[i]=((tweet[i][0]*mul_factor),tweet[i][1],tweet[i][2])\r\n",
        "        for i in range(l):\r\n",
        "          if tweet[i][1][:2]=='JJ':\r\n",
        "            for z in range(max(i-2,0),min(i+3,l)):\r\n",
        "              if tweet[z][1][:2]=='NN':\r\n",
        "                tweet[z]=((tweet[z][0]+tweet[i][0]),tweet[z][1])\r\n",
        "          if tweet[i][1][:2]=='RB':\r\n",
        "            for z in range(max(i-2,0),min(i+3,l)):\r\n",
        "              if tweet[z][1][:2]=='VB':\r\n",
        "                tweet[z]=((tweet[z][0]+tweet[i][0]),tweet[z][1])\r\n",
        "        res+=[np.array([x[0] for x in tweet])]\r\n",
        "      temp = np.array([np.pad(z.flatten(),(0,Max_input_size*Embedding_size-len(z.flatten()))).reshape(Max_input_size,Embedding_size) for z in res])\r\n",
        "      tempres = data_cat[k*(batch_size):(k+1)*(batch_size)]\r\n",
        "      yield (temp,tempres)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0leTuTOb3naL"
      },
      "source": [
        "epochs = 40"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GfgXfAFlD1J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d77ecab-8a9b-4902-9e01-a545ed8d2fb0"
      },
      "source": [
        "model_sg = tf.keras.Sequential()\n",
        "model_sg.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\n",
        "model_sg.add(tf.keras.layers.LSTM(50))\n",
        "model_sg.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
        "model_sg.compile(loss='categorical_crossentropy',optimizer='adam', \n",
        "                           metrics=['accuracy'])\n",
        "history = model_sg.fit_generator(generator = vec_gen(w2v_sg,vocab_sg,X_train,y_train,batch_size,Max_input_size,Embedding_size,mul_factor),steps_per_epoch=int(len(X_train)/batch_size),epochs=epochs)\n",
        "history = model_sg.evaluate(x = vec_gen(w2v_sg,vocab_sg,X_test,y_test,batch_size,Max_input_size,Embedding_size,mul_factor),steps=int(len(y_test)/batch_size))\n",
        "print(history)\n",
        "\n",
        "result_table[0]=history[1]\n",
        "print(\"SG_LSTM\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-bddb9a303a31>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/40\n",
            " 1/24 [>.............................] - ETA: 0s - loss: 1.3865 - accuracy: 0.2280WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0173s vs `on_train_batch_end` time: 0.0267s). Check your callbacks.\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 1.2647 - accuracy: 0.5685\n",
            "Epoch 2/40\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 1.0252 - accuracy: 0.5847\n",
            "Epoch 3/40\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.9864 - accuracy: 0.5847\n",
            "Epoch 4/40\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.9819 - accuracy: 0.5847\n",
            "Epoch 5/40\n",
            "24/24 [==============================] - 6s 239ms/step - loss: 0.9769 - accuracy: 0.5847\n",
            "Epoch 6/40\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.9728 - accuracy: 0.5847\n",
            "Epoch 7/40\n",
            "24/24 [==============================] - 6s 239ms/step - loss: 0.9686 - accuracy: 0.5847\n",
            "Epoch 8/40\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.9638 - accuracy: 0.5847\n",
            "Epoch 9/40\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.9585 - accuracy: 0.5849\n",
            "Epoch 10/40\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.9541 - accuracy: 0.5841\n",
            "Epoch 11/40\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.9496 - accuracy: 0.5845\n",
            "Epoch 12/40\n",
            "24/24 [==============================] - 6s 245ms/step - loss: 0.9451 - accuracy: 0.5850\n",
            "Epoch 13/40\n",
            "24/24 [==============================] - 6s 254ms/step - loss: 0.9411 - accuracy: 0.5863\n",
            "Epoch 14/40\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.9369 - accuracy: 0.5862\n",
            "Epoch 15/40\n",
            "24/24 [==============================] - 6s 239ms/step - loss: 0.9316 - accuracy: 0.5893\n",
            "Epoch 16/40\n",
            "24/24 [==============================] - 6s 241ms/step - loss: 0.9243 - accuracy: 0.5919\n",
            "Epoch 17/40\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.9181 - accuracy: 0.5969\n",
            "Epoch 18/40\n",
            "24/24 [==============================] - 6s 252ms/step - loss: 0.9133 - accuracy: 0.5982\n",
            "Epoch 19/40\n",
            "24/24 [==============================] - 6s 256ms/step - loss: 0.9044 - accuracy: 0.6029\n",
            "Epoch 20/40\n",
            "24/24 [==============================] - 6s 241ms/step - loss: 0.8976 - accuracy: 0.6097\n",
            "Epoch 21/40\n",
            "24/24 [==============================] - 6s 241ms/step - loss: 0.8890 - accuracy: 0.6153\n",
            "Epoch 22/40\n",
            "24/24 [==============================] - 6s 241ms/step - loss: 0.8806 - accuracy: 0.6202\n",
            "Epoch 23/40\n",
            "24/24 [==============================] - 6s 237ms/step - loss: 0.8728 - accuracy: 0.6248\n",
            "Epoch 24/40\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.8655 - accuracy: 0.6277\n",
            "Epoch 25/40\n",
            "24/24 [==============================] - 6s 239ms/step - loss: 0.8609 - accuracy: 0.6278\n",
            "Epoch 26/40\n",
            "24/24 [==============================] - 6s 241ms/step - loss: 0.8629 - accuracy: 0.6267\n",
            "Epoch 27/40\n",
            "24/24 [==============================] - 6s 239ms/step - loss: 0.8450 - accuracy: 0.6393\n",
            "Epoch 28/40\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.8302 - accuracy: 0.6482\n",
            "Epoch 29/40\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.8214 - accuracy: 0.6540\n",
            "Epoch 30/40\n",
            "24/24 [==============================] - 6s 237ms/step - loss: 0.8145 - accuracy: 0.6574\n",
            "Epoch 31/40\n",
            "24/24 [==============================] - 6s 255ms/step - loss: 0.8088 - accuracy: 0.6582\n",
            "Epoch 32/40\n",
            "24/24 [==============================] - 6s 256ms/step - loss: 0.8069 - accuracy: 0.6597\n",
            "Epoch 33/40\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.8050 - accuracy: 0.6591\n",
            "Epoch 34/40\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.7888 - accuracy: 0.6723\n",
            "Epoch 35/40\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.7787 - accuracy: 0.6754\n",
            "Epoch 36/40\n",
            "24/24 [==============================] - 6s 236ms/step - loss: 0.7716 - accuracy: 0.6773\n",
            "Epoch 37/40\n",
            "24/24 [==============================] - 6s 239ms/step - loss: 0.7671 - accuracy: 0.6806\n",
            "Epoch 38/40\n",
            "24/24 [==============================] - 6s 238ms/step - loss: 0.7706 - accuracy: 0.6783\n",
            "Epoch 39/40\n",
            "24/24 [==============================] - 6s 238ms/step - loss: 0.7881 - accuracy: 0.6731\n",
            "Epoch 40/40\n",
            "24/24 [==============================] - 6s 241ms/step - loss: 0.7778 - accuracy: 0.6774\n",
            "24/24 [==============================] - 6s 233ms/step - loss: 0.7806 - accuracy: 0.6798\n",
            "[0.7805622816085815, 0.6798333525657654]\n",
            "SG_LSTM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJHtKjzc1SA8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e587b3d9-9ab0-459f-c97f-898e47b4dfb3"
      },
      "source": [
        "model_sg_bi = tf.keras.Sequential()\r\n",
        "model_sg_bi.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_sg_bi.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50),merge_mode='concat'))\r\n",
        "model_sg_bi.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_sg_bi.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy'])\r\n",
        "history = model_sg_bi.fit_generator(generator = vec_gen(w2v_sg,vocab_sg,X_train,y_train,batch_size,Max_input_size,Embedding_size,mul_factor),steps_per_epoch=int(len(X_train)/batch_size),epochs=epochs)\r\n",
        "history = model_sg_bi.evaluate(x = vec_gen(w2v_sg,vocab_sg,X_test,y_test,batch_size,Max_input_size,Embedding_size,mul_factor),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table[1]=history[1]\r\n",
        "print(\"SG_BI\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            " 2/24 [=>............................] - ETA: 0s - loss: 1.3756 - accuracy: 0.3510WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0218s vs `on_train_batch_end` time: 0.0687s). Check your callbacks.\n",
            "24/24 [==============================] - 6s 239ms/step - loss: 1.2167 - accuracy: 0.5478\n",
            "Epoch 2/40\n",
            "24/24 [==============================] - 6s 245ms/step - loss: 0.9949 - accuracy: 0.5847\n",
            "Epoch 3/40\n",
            "24/24 [==============================] - 6s 248ms/step - loss: 0.9740 - accuracy: 0.5848\n",
            "Epoch 4/40\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.9665 - accuracy: 0.5844\n",
            "Epoch 5/40\n",
            "24/24 [==============================] - 6s 241ms/step - loss: 0.9615 - accuracy: 0.5842\n",
            "Epoch 6/40\n",
            "24/24 [==============================] - 6s 239ms/step - loss: 0.9566 - accuracy: 0.5842\n",
            "Epoch 7/40\n",
            "24/24 [==============================] - 6s 239ms/step - loss: 0.9510 - accuracy: 0.5847\n",
            "Epoch 8/40\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.9469 - accuracy: 0.5857\n",
            "Epoch 9/40\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.9426 - accuracy: 0.5862\n",
            "Epoch 10/40\n",
            "24/24 [==============================] - 6s 236ms/step - loss: 0.9376 - accuracy: 0.5867\n",
            "Epoch 11/40\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.9332 - accuracy: 0.5881\n",
            "Epoch 12/40\n",
            "24/24 [==============================] - 6s 238ms/step - loss: 0.9289 - accuracy: 0.5884\n",
            "Epoch 13/40\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.9244 - accuracy: 0.5900\n",
            "Epoch 14/40\n",
            "24/24 [==============================] - 6s 239ms/step - loss: 0.9198 - accuracy: 0.5917\n",
            "Epoch 15/40\n",
            "24/24 [==============================] - 6s 246ms/step - loss: 0.9150 - accuracy: 0.5938\n",
            "Epoch 16/40\n",
            "24/24 [==============================] - 6s 246ms/step - loss: 0.9098 - accuracy: 0.5957\n",
            "Epoch 17/40\n",
            "24/24 [==============================] - 6s 246ms/step - loss: 0.9042 - accuracy: 0.5973\n",
            "Epoch 18/40\n",
            "24/24 [==============================] - 6s 248ms/step - loss: 0.8982 - accuracy: 0.5987\n",
            "Epoch 19/40\n",
            "24/24 [==============================] - 6s 239ms/step - loss: 0.8921 - accuracy: 0.6012\n",
            "Epoch 20/40\n",
            "24/24 [==============================] - 6s 245ms/step - loss: 0.8864 - accuracy: 0.6033\n",
            "Epoch 21/40\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.8811 - accuracy: 0.6044\n",
            "Epoch 22/40\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.8754 - accuracy: 0.6072\n",
            "Epoch 23/40\n",
            "24/24 [==============================] - 6s 233ms/step - loss: 0.8722 - accuracy: 0.6108\n",
            "Epoch 24/40\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.8687 - accuracy: 0.6122\n",
            "Epoch 25/40\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.8571 - accuracy: 0.6195\n",
            "Epoch 26/40\n",
            "24/24 [==============================] - 6s 238ms/step - loss: 0.8484 - accuracy: 0.6212\n",
            "Epoch 27/40\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.8389 - accuracy: 0.6279\n",
            "Epoch 28/40\n",
            "24/24 [==============================] - 6s 251ms/step - loss: 0.8317 - accuracy: 0.6326\n",
            "Epoch 29/40\n",
            "24/24 [==============================] - 6s 256ms/step - loss: 0.8265 - accuracy: 0.6350\n",
            "Epoch 30/40\n",
            "24/24 [==============================] - 6s 241ms/step - loss: 0.8225 - accuracy: 0.6348\n",
            "Epoch 31/40\n",
            "24/24 [==============================] - 6s 237ms/step - loss: 0.8167 - accuracy: 0.6394\n",
            "Epoch 32/40\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.8086 - accuracy: 0.6392\n",
            "Epoch 33/40\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.7990 - accuracy: 0.6481\n",
            "Epoch 34/40\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.7926 - accuracy: 0.6492\n",
            "Epoch 35/40\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.7854 - accuracy: 0.6522\n",
            "Epoch 36/40\n",
            "24/24 [==============================] - 6s 245ms/step - loss: 0.7793 - accuracy: 0.6571\n",
            "Epoch 37/40\n",
            "24/24 [==============================] - 6s 249ms/step - loss: 0.7674 - accuracy: 0.6605\n",
            "Epoch 38/40\n",
            "24/24 [==============================] - 6s 249ms/step - loss: 0.7615 - accuracy: 0.6633\n",
            "Epoch 39/40\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.7473 - accuracy: 0.6704\n",
            "Epoch 40/40\n",
            "24/24 [==============================] - 6s 246ms/step - loss: 0.7383 - accuracy: 0.6760\n",
            "24/24 [==============================] - 6s 239ms/step - loss: 0.7499 - accuracy: 0.6748\n",
            "[0.7498981952667236, 0.674833357334137]\n",
            "SG_BI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opfhhYPH1VoL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cff910e-9396-4013-fbb9-b1e1649d9658"
      },
      "source": [
        "model_sg_rnn = tf.keras.Sequential()\r\n",
        "model_sg_rnn.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_sg_rnn.add(tf.keras.layers.SimpleRNN(50))\r\n",
        "model_sg_rnn.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_sg_rnn.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy'])\r\n",
        "history = model_sg_rnn.fit_generator(generator = vec_gen(w2v_sg,vocab_sg,X_train,y_train,batch_size,Max_input_size,Embedding_size,mul_factor),steps_per_epoch=int(len(X_train)/batch_size),epochs=epochs)\r\n",
        "history = model_sg_rnn.evaluate(x = vec_gen(w2v_sg,vocab_sg,X_test,y_test,batch_size,Max_input_size,Embedding_size,mul_factor),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table[2]=history[1]\r\n",
        "print(\"SG_RNN\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            " 2/24 [=>............................] - ETA: 2s - loss: 1.4005 - accuracy: 0.2350WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0701s vs `on_train_batch_end` time: 0.1381s). Check your callbacks.\n",
            "24/24 [==============================] - 7s 273ms/step - loss: 1.1181 - accuracy: 0.5297\n",
            "Epoch 2/40\n",
            "24/24 [==============================] - 6s 263ms/step - loss: 0.9919 - accuracy: 0.5847\n",
            "Epoch 3/40\n",
            "24/24 [==============================] - 6s 261ms/step - loss: 0.9866 - accuracy: 0.5847\n",
            "Epoch 4/40\n",
            "24/24 [==============================] - 6s 254ms/step - loss: 0.9860 - accuracy: 0.5847\n",
            "Epoch 5/40\n",
            "24/24 [==============================] - 6s 254ms/step - loss: 0.9858 - accuracy: 0.5848\n",
            "Epoch 6/40\n",
            "24/24 [==============================] - 6s 253ms/step - loss: 0.9857 - accuracy: 0.5847\n",
            "Epoch 7/40\n",
            "24/24 [==============================] - 6s 256ms/step - loss: 0.9857 - accuracy: 0.5847\n",
            "Epoch 8/40\n",
            "24/24 [==============================] - 6s 253ms/step - loss: 0.9856 - accuracy: 0.5848\n",
            "Epoch 9/40\n",
            "24/24 [==============================] - 6s 251ms/step - loss: 0.9858 - accuracy: 0.5848\n",
            "Epoch 10/40\n",
            "24/24 [==============================] - 6s 255ms/step - loss: 0.9856 - accuracy: 0.5847\n",
            "Epoch 11/40\n",
            "24/24 [==============================] - 6s 261ms/step - loss: 0.9854 - accuracy: 0.5849\n",
            "Epoch 12/40\n",
            "24/24 [==============================] - 6s 249ms/step - loss: 0.9854 - accuracy: 0.5849\n",
            "Epoch 13/40\n",
            "24/24 [==============================] - 6s 249ms/step - loss: 0.9852 - accuracy: 0.5848\n",
            "Epoch 14/40\n",
            "24/24 [==============================] - 6s 254ms/step - loss: 0.9855 - accuracy: 0.5847\n",
            "Epoch 15/40\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 0.9873 - accuracy: 0.5847\n",
            "Epoch 16/40\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.9859 - accuracy: 0.5847\n",
            "Epoch 17/40\n",
            "24/24 [==============================] - 6s 263ms/step - loss: 0.9855 - accuracy: 0.5847\n",
            "Epoch 18/40\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.9848 - accuracy: 0.5847\n",
            "Epoch 19/40\n",
            "24/24 [==============================] - 6s 263ms/step - loss: 0.9844 - accuracy: 0.5847\n",
            "Epoch 20/40\n",
            "24/24 [==============================] - 6s 256ms/step - loss: 0.9848 - accuracy: 0.5847\n",
            "Epoch 21/40\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.9847 - accuracy: 0.5847\n",
            "Epoch 22/40\n",
            "24/24 [==============================] - 6s 261ms/step - loss: 0.9841 - accuracy: 0.5847\n",
            "Epoch 23/40\n",
            "24/24 [==============================] - 6s 251ms/step - loss: 0.9844 - accuracy: 0.5847\n",
            "Epoch 24/40\n",
            "24/24 [==============================] - 6s 256ms/step - loss: 0.9830 - accuracy: 0.5849\n",
            "Epoch 25/40\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.9804 - accuracy: 0.5853\n",
            "Epoch 26/40\n",
            "24/24 [==============================] - 6s 251ms/step - loss: 0.9760 - accuracy: 0.5855\n",
            "Epoch 27/40\n",
            "24/24 [==============================] - 6s 252ms/step - loss: 0.9722 - accuracy: 0.5859\n",
            "Epoch 28/40\n",
            "24/24 [==============================] - 6s 249ms/step - loss: 0.9694 - accuracy: 0.5862\n",
            "Epoch 29/40\n",
            "24/24 [==============================] - 6s 256ms/step - loss: 0.9639 - accuracy: 0.5858\n",
            "Epoch 30/40\n",
            "24/24 [==============================] - 6s 253ms/step - loss: 0.9592 - accuracy: 0.5886\n",
            "Epoch 31/40\n",
            "24/24 [==============================] - 6s 251ms/step - loss: 0.9506 - accuracy: 0.5884\n",
            "Epoch 32/40\n",
            "24/24 [==============================] - 6s 249ms/step - loss: 0.9437 - accuracy: 0.5913\n",
            "Epoch 33/40\n",
            "24/24 [==============================] - 6s 257ms/step - loss: 0.9371 - accuracy: 0.5932\n",
            "Epoch 34/40\n",
            "24/24 [==============================] - 6s 252ms/step - loss: 0.9299 - accuracy: 0.5945\n",
            "Epoch 35/40\n",
            "24/24 [==============================] - 6s 253ms/step - loss: 0.9253 - accuracy: 0.5983\n",
            "Epoch 36/40\n",
            "24/24 [==============================] - 6s 264ms/step - loss: 0.9166 - accuracy: 0.5996\n",
            "Epoch 37/40\n",
            "24/24 [==============================] - 6s 263ms/step - loss: 0.9104 - accuracy: 0.6034\n",
            "Epoch 38/40\n",
            "24/24 [==============================] - 6s 257ms/step - loss: 0.9063 - accuracy: 0.6082\n",
            "Epoch 39/40\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.9014 - accuracy: 0.6137\n",
            "Epoch 40/40\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 0.8985 - accuracy: 0.6101\n",
            "24/24 [==============================] - 6s 234ms/step - loss: 0.8860 - accuracy: 0.6156\n",
            "[0.8860383033752441, 0.6155833601951599]\n",
            "SG_RNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YumD1M9Y1Xxr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b6cc0fc-8fbb-4b0b-ae94-1fa6fb2deaf2"
      },
      "source": [
        "model_cbow = tf.keras.Sequential()\r\n",
        "model_cbow.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_cbow.add(tf.keras.layers.LSTM(50))\r\n",
        "model_cbow.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_cbow.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy'])\r\n",
        "history = model_cbow.fit_generator(generator = vec_gen(w2v_cbow,vocab_cbow,X_train,y_train,batch_size,Max_input_size,Embedding_size,mul_factor),steps_per_epoch=int(len(X_train)/batch_size),epochs=epochs)\r\n",
        "history = model_cbow.evaluate(x = vec_gen(w2v_cbow,vocab_cbow,X_test,y_test,batch_size,Max_input_size,Embedding_size,mul_factor),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table[3]=history[1]\r\n",
        "print(\"CBOW_LSTM\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "24/24 [==============================] - 6s 239ms/step - loss: 1.2622 - accuracy: 0.5691\n",
            "Epoch 2/40\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 1.0054 - accuracy: 0.5847\n",
            "Epoch 3/40\n",
            "24/24 [==============================] - 6s 241ms/step - loss: 0.9848 - accuracy: 0.5847\n",
            "Epoch 4/40\n",
            "24/24 [==============================] - 6s 238ms/step - loss: 0.9830 - accuracy: 0.5848\n",
            "Epoch 5/40\n",
            "24/24 [==============================] - 6s 239ms/step - loss: 0.9808 - accuracy: 0.5848\n",
            "Epoch 6/40\n",
            "24/24 [==============================] - 6s 237ms/step - loss: 0.9778 - accuracy: 0.5847\n",
            "Epoch 7/40\n",
            "24/24 [==============================] - 6s 238ms/step - loss: 0.9744 - accuracy: 0.5847\n",
            "Epoch 8/40\n",
            "24/24 [==============================] - 6s 236ms/step - loss: 0.9704 - accuracy: 0.5847\n",
            "Epoch 9/40\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.9665 - accuracy: 0.5847\n",
            "Epoch 10/40\n",
            "24/24 [==============================] - 6s 257ms/step - loss: 0.9631 - accuracy: 0.5847\n",
            "Epoch 11/40\n",
            "24/24 [==============================] - 6s 245ms/step - loss: 0.9597 - accuracy: 0.5847\n",
            "Epoch 12/40\n",
            "24/24 [==============================] - 6s 238ms/step - loss: 0.9566 - accuracy: 0.5847\n",
            "Epoch 13/40\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.9528 - accuracy: 0.5845\n",
            "Epoch 14/40\n",
            "24/24 [==============================] - 6s 241ms/step - loss: 0.9486 - accuracy: 0.5853\n",
            "Epoch 15/40\n",
            "24/24 [==============================] - 6s 239ms/step - loss: 0.9435 - accuracy: 0.5859\n",
            "Epoch 16/40\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.9372 - accuracy: 0.5884\n",
            "Epoch 17/40\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.9310 - accuracy: 0.5916\n",
            "Epoch 18/40\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.9227 - accuracy: 0.5939\n",
            "Epoch 19/40\n",
            "24/24 [==============================] - 6s 238ms/step - loss: 0.9134 - accuracy: 0.5990\n",
            "Epoch 20/40\n",
            "24/24 [==============================] - 6s 241ms/step - loss: 0.9059 - accuracy: 0.6036\n",
            "Epoch 21/40\n",
            "24/24 [==============================] - 6s 236ms/step - loss: 0.8952 - accuracy: 0.6074\n",
            "Epoch 22/40\n",
            "24/24 [==============================] - 6s 238ms/step - loss: 0.8859 - accuracy: 0.6149\n",
            "Epoch 23/40\n",
            "24/24 [==============================] - 6s 241ms/step - loss: 0.8770 - accuracy: 0.6204\n",
            "Epoch 24/40\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.8684 - accuracy: 0.6243\n",
            "Epoch 25/40\n",
            "24/24 [==============================] - 6s 236ms/step - loss: 0.8607 - accuracy: 0.6280\n",
            "Epoch 26/40\n",
            "24/24 [==============================] - 6s 235ms/step - loss: 0.8544 - accuracy: 0.6320\n",
            "Epoch 27/40\n",
            "24/24 [==============================] - 6s 239ms/step - loss: 0.8518 - accuracy: 0.6323\n",
            "Epoch 28/40\n",
            "24/24 [==============================] - 6s 241ms/step - loss: 0.8533 - accuracy: 0.6303\n",
            "Epoch 29/40\n",
            "24/24 [==============================] - 6s 239ms/step - loss: 0.8373 - accuracy: 0.6379\n",
            "Epoch 30/40\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.8278 - accuracy: 0.6467\n",
            "Epoch 31/40\n",
            "24/24 [==============================] - 6s 238ms/step - loss: 0.8215 - accuracy: 0.6502\n",
            "Epoch 32/40\n",
            "24/24 [==============================] - 6s 235ms/step - loss: 0.8152 - accuracy: 0.6543\n",
            "Epoch 33/40\n",
            "24/24 [==============================] - 6s 234ms/step - loss: 0.8114 - accuracy: 0.6565\n",
            "Epoch 34/40\n",
            "24/24 [==============================] - 6s 233ms/step - loss: 0.8063 - accuracy: 0.6608\n",
            "Epoch 35/40\n",
            "24/24 [==============================] - 6s 238ms/step - loss: 0.7982 - accuracy: 0.6631\n",
            "Epoch 36/40\n",
            "24/24 [==============================] - 6s 238ms/step - loss: 0.7906 - accuracy: 0.6702\n",
            "Epoch 37/40\n",
            "24/24 [==============================] - 6s 234ms/step - loss: 0.7848 - accuracy: 0.6745\n",
            "Epoch 38/40\n",
            "24/24 [==============================] - 6s 237ms/step - loss: 0.7793 - accuracy: 0.6759\n",
            "Epoch 39/40\n",
            "24/24 [==============================] - 6s 236ms/step - loss: 0.7763 - accuracy: 0.6803\n",
            "Epoch 40/40\n",
            "24/24 [==============================] - 6s 239ms/step - loss: 0.7765 - accuracy: 0.6777\n",
            "24/24 [==============================] - 6s 236ms/step - loss: 0.8031 - accuracy: 0.6622\n",
            "[0.8030928373336792, 0.6622499823570251]\n",
            "CBOW_LSTM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01yVMiF41ZtT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2434bf79-a789-4795-8455-b1d262cfba32"
      },
      "source": [
        "model_cbow_bi = tf.keras.Sequential()\r\n",
        "model_cbow_bi.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_cbow_bi.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50),merge_mode='concat'))\r\n",
        "model_cbow_bi.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_cbow_bi.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy'])\r\n",
        "history = model_cbow_bi.fit_generator(generator = vec_gen(w2v_cbow,vocab_cbow,X_train,y_train,batch_size,Max_input_size,Embedding_size,mul_factor),steps_per_epoch=int(len(X_train)/batch_size),epochs=epochs)\r\n",
        "history = model_cbow_bi.evaluate(x = vec_gen(w2v_cbow,vocab_cbow,X_test,y_test,batch_size,Max_input_size,Embedding_size,mul_factor),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table[4]=history[1]\r\n",
        "print(\"CBOW_BI\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 1.2222 - accuracy: 0.5440\n",
            "Epoch 2/40\n",
            "24/24 [==============================] - 6s 246ms/step - loss: 1.0046 - accuracy: 0.5847\n",
            "Epoch 3/40\n",
            "24/24 [==============================] - 6s 248ms/step - loss: 0.9752 - accuracy: 0.5847\n",
            "Epoch 4/40\n",
            "24/24 [==============================] - 6s 247ms/step - loss: 0.9664 - accuracy: 0.5847\n",
            "Epoch 5/40\n",
            "24/24 [==============================] - 6s 257ms/step - loss: 0.9587 - accuracy: 0.5847\n",
            "Epoch 6/40\n",
            "24/24 [==============================] - 6s 254ms/step - loss: 0.9534 - accuracy: 0.5847\n",
            "Epoch 7/40\n",
            "24/24 [==============================] - 6s 247ms/step - loss: 0.9490 - accuracy: 0.5855\n",
            "Epoch 8/40\n",
            "24/24 [==============================] - 6s 245ms/step - loss: 0.9445 - accuracy: 0.5863\n",
            "Epoch 9/40\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.9402 - accuracy: 0.5881\n",
            "Epoch 10/40\n",
            "24/24 [==============================] - 6s 250ms/step - loss: 0.9359 - accuracy: 0.5899\n",
            "Epoch 11/40\n",
            "24/24 [==============================] - 6s 247ms/step - loss: 0.9313 - accuracy: 0.5921\n",
            "Epoch 12/40\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.9261 - accuracy: 0.5936\n",
            "Epoch 13/40\n",
            "24/24 [==============================] - 6s 248ms/step - loss: 0.9199 - accuracy: 0.5958\n",
            "Epoch 14/40\n",
            "24/24 [==============================] - 6s 249ms/step - loss: 0.9127 - accuracy: 0.6010\n",
            "Epoch 15/40\n",
            "24/24 [==============================] - 6s 249ms/step - loss: 0.9035 - accuracy: 0.6068\n",
            "Epoch 16/40\n",
            "24/24 [==============================] - 6s 249ms/step - loss: 0.8936 - accuracy: 0.6132\n",
            "Epoch 17/40\n",
            "24/24 [==============================] - 6s 250ms/step - loss: 0.8858 - accuracy: 0.6135\n",
            "Epoch 18/40\n",
            "24/24 [==============================] - 6s 249ms/step - loss: 0.8758 - accuracy: 0.6193\n",
            "Epoch 19/40\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.8644 - accuracy: 0.6233\n",
            "Epoch 20/40\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.8548 - accuracy: 0.6288\n",
            "Epoch 21/40\n",
            "24/24 [==============================] - 6s 262ms/step - loss: 0.8462 - accuracy: 0.6339\n",
            "Epoch 22/40\n",
            "24/24 [==============================] - 6s 248ms/step - loss: 0.8405 - accuracy: 0.6357\n",
            "Epoch 23/40\n",
            "24/24 [==============================] - 6s 251ms/step - loss: 0.8324 - accuracy: 0.6373\n",
            "Epoch 24/40\n",
            "24/24 [==============================] - 6s 245ms/step - loss: 0.8200 - accuracy: 0.6429\n",
            "Epoch 25/40\n",
            "24/24 [==============================] - 6s 246ms/step - loss: 0.8081 - accuracy: 0.6494\n",
            "Epoch 26/40\n",
            "24/24 [==============================] - 6s 247ms/step - loss: 0.7963 - accuracy: 0.6510\n",
            "Epoch 27/40\n",
            "24/24 [==============================] - 6s 251ms/step - loss: 0.7847 - accuracy: 0.6605\n",
            "Epoch 28/40\n",
            "24/24 [==============================] - 6s 248ms/step - loss: 0.7787 - accuracy: 0.6627\n",
            "Epoch 29/40\n",
            "24/24 [==============================] - 6s 248ms/step - loss: 0.7719 - accuracy: 0.6663\n",
            "Epoch 30/40\n",
            "24/24 [==============================] - 6s 247ms/step - loss: 0.7611 - accuracy: 0.6713\n",
            "Epoch 31/40\n",
            "24/24 [==============================] - 6s 249ms/step - loss: 0.7559 - accuracy: 0.6768\n",
            "Epoch 32/40\n",
            "24/24 [==============================] - 6s 248ms/step - loss: 0.7505 - accuracy: 0.6736\n",
            "Epoch 33/40\n",
            "24/24 [==============================] - 6s 248ms/step - loss: 0.7816 - accuracy: 0.6581\n",
            "Epoch 34/40\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.7632 - accuracy: 0.6694\n",
            "Epoch 35/40\n",
            "24/24 [==============================] - 6s 250ms/step - loss: 0.7468 - accuracy: 0.6757\n",
            "Epoch 36/40\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.7306 - accuracy: 0.6853\n",
            "Epoch 37/40\n",
            "24/24 [==============================] - 6s 245ms/step - loss: 0.7149 - accuracy: 0.6977\n",
            "Epoch 38/40\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.6997 - accuracy: 0.7073\n",
            "Epoch 39/40\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.6966 - accuracy: 0.7067\n",
            "Epoch 40/40\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.6984 - accuracy: 0.7017\n",
            "24/24 [==============================] - 6s 239ms/step - loss: 0.7087 - accuracy: 0.7022\n",
            "[0.7086641192436218, 0.7021666765213013]\n",
            "CBOW_BI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_G3Ff5r1bSD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e87ed25b-f9d6-467d-8ec5-4a3dfcd506cc"
      },
      "source": [
        "model_cbow_rnn = tf.keras.Sequential()\r\n",
        "model_cbow_rnn.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_cbow_rnn.add(tf.keras.layers.SimpleRNN(50))\r\n",
        "model_cbow_rnn.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_cbow_rnn.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy'])\r\n",
        "history = model_cbow_rnn.fit_generator(generator = vec_gen(w2v_cbow,vocab_cbow,X_train,y_train,batch_size,Max_input_size,Embedding_size,mul_factor),steps_per_epoch=int(len(X_train)/batch_size),epochs=epochs)\r\n",
        "history = model_cbow_rnn.evaluate(x = vec_gen(w2v_cbow,vocab_cbow,X_test,y_test,batch_size,Max_input_size,Embedding_size,mul_factor),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table[5]=history[1]\r\n",
        "print(\"CBOW_RNN\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 1.1680 - accuracy: 0.5102\n",
            "Epoch 2/40\n",
            "24/24 [==============================] - 6s 257ms/step - loss: 0.9998 - accuracy: 0.5842\n",
            "Epoch 3/40\n",
            "24/24 [==============================] - 6s 253ms/step - loss: 0.9889 - accuracy: 0.5846\n",
            "Epoch 4/40\n",
            "24/24 [==============================] - 6s 255ms/step - loss: 0.9868 - accuracy: 0.5847\n",
            "Epoch 5/40\n",
            "24/24 [==============================] - 6s 257ms/step - loss: 0.9857 - accuracy: 0.5848\n",
            "Epoch 6/40\n",
            "24/24 [==============================] - 6s 255ms/step - loss: 0.9854 - accuracy: 0.5848\n",
            "Epoch 7/40\n",
            "24/24 [==============================] - 6s 256ms/step - loss: 0.9853 - accuracy: 0.5849\n",
            "Epoch 8/40\n",
            "24/24 [==============================] - 6s 251ms/step - loss: 0.9853 - accuracy: 0.5848\n",
            "Epoch 9/40\n",
            "24/24 [==============================] - 6s 248ms/step - loss: 0.9853 - accuracy: 0.5848\n",
            "Epoch 10/40\n",
            "24/24 [==============================] - 6s 252ms/step - loss: 0.9853 - accuracy: 0.5848\n",
            "Epoch 11/40\n",
            "24/24 [==============================] - 6s 250ms/step - loss: 0.9853 - accuracy: 0.5848\n",
            "Epoch 12/40\n",
            "24/24 [==============================] - 6s 249ms/step - loss: 0.9852 - accuracy: 0.5848\n",
            "Epoch 13/40\n",
            "24/24 [==============================] - 6s 249ms/step - loss: 0.9852 - accuracy: 0.5848\n",
            "Epoch 14/40\n",
            "24/24 [==============================] - 6s 266ms/step - loss: 0.9852 - accuracy: 0.5848\n",
            "Epoch 15/40\n",
            "24/24 [==============================] - 6s 261ms/step - loss: 0.9851 - accuracy: 0.5848\n",
            "Epoch 16/40\n",
            "24/24 [==============================] - 6s 256ms/step - loss: 0.9852 - accuracy: 0.5848\n",
            "Epoch 17/40\n",
            "24/24 [==============================] - 6s 261ms/step - loss: 0.9850 - accuracy: 0.5848\n",
            "Epoch 18/40\n",
            "24/24 [==============================] - 6s 256ms/step - loss: 0.9850 - accuracy: 0.5848\n",
            "Epoch 19/40\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 0.9848 - accuracy: 0.5848\n",
            "Epoch 20/40\n",
            "24/24 [==============================] - 6s 262ms/step - loss: 0.9846 - accuracy: 0.5849\n",
            "Epoch 21/40\n",
            "24/24 [==============================] - 6s 253ms/step - loss: 0.9844 - accuracy: 0.5850\n",
            "Epoch 22/40\n",
            "24/24 [==============================] - 6s 251ms/step - loss: 0.9844 - accuracy: 0.5847\n",
            "Epoch 23/40\n",
            "24/24 [==============================] - 6s 249ms/step - loss: 0.9841 - accuracy: 0.5847\n",
            "Epoch 24/40\n",
            "24/24 [==============================] - 6s 252ms/step - loss: 0.9819 - accuracy: 0.5849\n",
            "Epoch 25/40\n",
            " 9/24 [==========>...................] - ETA: 2s - loss: 0.9737 - accuracy: 0.5904"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-e6bed8a3c57a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m model_cbow_rnn.compile(loss='categorical_crossentropy',optimizer='adam', \n\u001b[1;32m      6\u001b[0m                            metrics=['accuracy'])\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_cbow_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v_cbow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab_cbow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMax_input_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEmbedding_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmul_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_cbow_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v_cbow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab_cbow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMax_input_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEmbedding_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmul_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1827\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1829\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m   @deprecation.deprecated(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEglKIfExKKI"
      },
      "source": [
        "epochs=40\r\n",
        "Embedding_size=100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czoFmEwK1dWT"
      },
      "source": [
        "model_glove = tf.keras.Sequential()\r\n",
        "model_glove.add(tf.keras.Input(shape=(Max_input_size,100)))\r\n",
        "model_glove.add(tf.keras.layers.LSTM(50))\r\n",
        "model_glove.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_glove.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy'])\r\n",
        "history = model_glove.fit_generator(generator = glove_gen(vocab_glove,X_train,y_train,batch_size,Max_input_size,Embedding_size,mul_factor),steps_per_epoch=int(len(X_train)/batch_size),epochs=epochs)\r\n",
        "history = model_glove.evaluate(x = glove_gen(vocab_glove,X_test,y_test,batch_size,Max_input_size,Embedding_size,mul_factor),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table[6]=history[1]\r\n",
        "print(\"GLOVE_LSTM\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKM9PEwm1fkb"
      },
      "source": [
        "model_glove_bi = tf.keras.Sequential()\r\n",
        "model_glove_bi.add(tf.keras.Input(shape=(Max_input_size,100)))\r\n",
        "model_glove_bi.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50),merge_mode='concat'))\r\n",
        "model_glove_bi.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_glove_bi.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy'])\r\n",
        "history = model_glove_bi.fit_generator(generator = glove_gen(vocab_glove,X_train,y_train,batch_size,Max_input_size,Embedding_size,mul_factor),steps_per_epoch=int(len(X_train)/batch_size),epochs=epochs)\r\n",
        "history = model_glove_bi.evaluate(x = glove_gen(vocab_glove,X_test,y_test,batch_size,Max_input_size,Embedding_size,mul_factor),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table[7]=history[1]\r\n",
        "print(\"GLOVE_BI\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQBa5s4s1hNU"
      },
      "source": [
        "model_glove_rnn = tf.keras.Sequential()\r\n",
        "model_glove_rnn.add(tf.keras.Input(shape=(Max_input_size,100)))\r\n",
        "model_glove_rnn.add(tf.keras.layers.SimpleRNN(50))\r\n",
        "model_glove_rnn.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_glove_rnn.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy'])\r\n",
        "history = model_glove_rnn.fit_generator(generator = glove_gen(vocab_glove,X_train,y_train,batch_size,Max_input_size,Embedding_size,mul_factor),steps_per_epoch=int(len(X_train)/batch_size),epochs=epochs)\r\n",
        "history = model_glove_rnn.evaluate(x = glove_gen(vocab_glove,X_test,y_test,batch_size,Max_input_size,Embedding_size,mul_factor),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table[8]=history[1]\r\n",
        "print(\"GLOVE_RNN\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdPYKennH7PF"
      },
      "source": [
        "model_sg1 = tf.keras.Sequential()\r\n",
        "model_sg1.add(tf.keras.Input(shape=(Max_input_size,100)))\r\n",
        "model_sg1.add(tf.keras.layers.LSTM(64))\r\n",
        "model_sg1.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_sg1.add(tf.keras.layers.Dense(64,activation='relu'))\r\n",
        "model_sg1.add(tf.keras.layers.Dropout(0.2))\r\n",
        "model_sg1.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_sg1.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy'])\r\n",
        "history = model_sg1.fit_generator(generator = vec_gen(w2v_sg,vocab_sg,X_train,y_train,batch_size,Max_input_size,Embedding_size,mul_factor),steps_per_epoch=int(len(X_train)/batch_size),epochs=epochs)\r\n",
        "history = model_sg1.evaluate(x = vec_gen(w2v_sg,vocab_sg,X_test,y_test,batch_size,Max_input_size,Embedding_size,mul_factor),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table+=[history[1]]\r\n",
        "print(\"SG_LSTM\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZqN_SaM3hs9"
      },
      "source": [
        "print(\"\\tLstm\\t\\t\\tBiLstm\\t\\t\\tRnn\")\r\n",
        "print(\"sg\",result_table[:3])\r\n",
        "print(\"cbow\",result_table[3:6])\r\n",
        "print(\"glove\",result_table[6:9])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRLVUTMaIFdi"
      },
      "source": [
        "print(result_table[9])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}