{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AllCF_Add.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harrymkwn/InfluenceAnalysis/blob/master/AllCF_Add.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f07YBO0HutGC",
        "outputId": "bd3ffdb9-bedc-4e9b-9a0e-0d50244e2022"
      },
      "source": [
        "from google.colab import  drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_ZbOn58n2x4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd05cb9e-d923-4354-a781-d43507fbd516"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from gensim.models import Word2Vec\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.multiclass import OneVsRestClassifier\r\n",
        "from gensim.models import KeyedVectors\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import nltk\r\n",
        "from nltk.corpus import stopwords\r\n",
        "nltk.download('all')\r\n",
        "from nltk.corpus import sentiwordnet as swn\r\n",
        "device_name = tf.test.gpu_device_name()\r\n",
        "print(device_name)\r\n",
        "df = pd.read_csv('/content/drive/MyDrive/InfluenceAnalysis/crowdFlower/crowdFlower_clean.csv')\r\n",
        "df = df.sample(frac=1,random_state=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "2kcOfvgzvPwr",
        "outputId": "c99b7d42-4884-4217-bb84-a1e3300bfdc7"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>emotion</th>\n",
              "      <th>tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>35975</th>\n",
              "      <td>35975</td>\n",
              "      <td>6</td>\n",
              "      <td>katofawesome praying for love in a lap dance a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17590</th>\n",
              "      <td>17590</td>\n",
              "      <td>1</td>\n",
              "      <td>trying to fix my internet connectionguess my p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38071</th>\n",
              "      <td>38071</td>\n",
              "      <td>0</td>\n",
              "      <td>starting an account here on twitter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23304</th>\n",
              "      <td>23304</td>\n",
              "      <td>1</td>\n",
              "      <td>dipfico hmm wrong link ignore my tweet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26990</th>\n",
              "      <td>26990</td>\n",
              "      <td>0</td>\n",
              "      <td>mzunyque thanks before the major chop</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  emotion                                             tweets\n",
              "35975       35975        6  katofawesome praying for love in a lap dance a...\n",
              "17590       17590        1  trying to fix my internet connectionguess my p...\n",
              "38071       38071        0                starting an account here on twitter\n",
              "23304       23304        1             dipfico hmm wrong link ignore my tweet\n",
              "26990       26990        0              mzunyque thanks before the major chop"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFWkf_bDvSb_",
        "outputId": "29e49d46-3b99-4571-a4f0-b844d1563f57"
      },
      "source": [
        "df.emotion.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6,  1,  0,  2,  3,  4, 10,  5,  7,  8,  9, 12, 11])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qZgGMFSoMEj"
      },
      "source": [
        "category_dict = {0:[1,0,0,0,0,0,0,0,0,0,0,0,0],1:[0,1,0,0,0,0,0,0,0,0,0,0,0],2:[0,0,1,0,0,0,0,0,0,0,0,0,0],3:[0,0,0,1,0,0,0,0,0,0,0,0,0],4:[0,0,0,0,1,0,0,0,0,0,0,0,0],5:[0,0,0,0,0,1,0,0,0,0,0,0,0],6:[0,0,0,0,0,0,1,0,0,0,0,0,0],7:[0,0,0,0,0,0,0,1,0,0,0,0,0],8:[0,0,0,0,0,0,0,0,1,0,0,0,0],9:[0,0,0,0,0,0,0,0,0,1,0,0,0],10:[0,0,0,0,0,0,0,0,0,0,1,0,0],11:[0,0,0,0,0,0,0,0,0,0,0,1,0],12:[0,0,0,0,0,0,0,0,0,0,0,0,1]}\r\n",
        "data_tweet = [x.lower().split() for x in df['tweets']]\r\n",
        "data_cat = np.array([category_dict[x] for x in df['emotion']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ0TOnAwoMBn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38b88fca-8367-4e0b-a6a7-782add55a9d9"
      },
      "source": [
        "print(data_tweet[:5])\r\n",
        "print(data_cat[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['katofawesome', 'praying', 'for', 'love', 'in', 'a', 'lap', 'dance', 'and', 'paying', 'in', 'naivety', 'lt--one', 'of', 'my', 'fav', 'songs'], ['trying', 'to', 'fix', 'my', 'internet', 'connectionguess', 'my', 'prayers', 'have', 'been', 'answered', 'and', 'i', 'wont', 'have', 'any', 'study', 'distractions', 'ugh'], ['starting', 'an', 'account', 'here', 'on', 'twitter'], ['dipfico', 'hmm', 'wrong', 'link', 'ignore', 'my', 'tweet'], ['mzunyque', 'thanks', 'before', 'the', 'major', 'chop']]\n",
            "[[0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXMVH-X2oL_N"
      },
      "source": [
        "# Parameters\r\n",
        "Min_count = 0\r\n",
        "Embedding_size = 200\r\n",
        "Window_size = 5\r\n",
        "Negative_sampling = 00"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVu-FHPnoL84"
      },
      "source": [
        "w2v_sg = Word2Vec(min_count=Min_count,\r\n",
        "                     window=Window_size,\r\n",
        "                     size=Embedding_size,\r\n",
        "                     negative=Negative_sampling,sg=1)\r\n",
        "w2v_sg.build_vocab(data_tweet)\r\n",
        "w2v_sg.train(data_tweet, total_examples=w2v_sg.corpus_count, epochs=5)\r\n",
        "w2v_cbow = Word2Vec(min_count=Min_count,\r\n",
        "                     window=Window_size,\r\n",
        "                     size=Embedding_size,\r\n",
        "                     negative=Negative_sampling,sg=0)\r\n",
        "w2v_cbow.build_vocab(data_tweet)\r\n",
        "w2v_cbow.train(data_tweet, total_examples=w2v_cbow.corpus_count, epochs=5)\r\n",
        "w2v_sg.wv.init_sims(True)\r\n",
        "w2v_cbow.wv.init_sims(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydjh-41loL6F"
      },
      "source": [
        "vocab_sg = w2v_sg.wv.vocab\r\n",
        "vocab_sg = [x for x in vocab_sg]\r\n",
        "vocab_cbow = w2v_cbow.wv.vocab\r\n",
        "vocab_cbow = [x for x in vocab_cbow] \r\n",
        "vocab_glove = {}\r\n",
        "with open(\"/content/drive/My Drive/InfluenceAnalysis/glove/glove.twitter.27B.200d.txt\", 'r', encoding=\"utf-8\") as f:\r\n",
        "  for line in f:\r\n",
        "      values = line.split()\r\n",
        "      word = values[0]\r\n",
        "      vector = np.asarray(values[1:], \"float32\")\r\n",
        "      vocab_glove[word] = vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNpmWgnWoL3U"
      },
      "source": [
        "batch_size = 100\r\n",
        "Max_input_size = max([len(x) for x in data_tweet])\r\n",
        "data_tweet = [nltk.pos_tag(x) for x in data_tweet]\r\n",
        "def getsent(word,tag):\r\n",
        "  res=0\r\n",
        "  try:\r\n",
        "    x = swn.senti_synset(word+'.'+tag[0].lower()+'.01')\r\n",
        "    res =  (x.pos_score()-x.neg_score())\r\n",
        "  finally:\r\n",
        "    return res \r\n",
        "data_tweet = [[(i[0],i[1],getsent(i[0],i[1])) for i in x] for x in data_tweet]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO3sLvcdoL01"
      },
      "source": [
        "def vec_gen(w2v,vocab,data_tweet,data_cat,batch_size,Max_input_size,Embedding_size,mul_factor=2):\r\n",
        "  while True:\r\n",
        "    for k in range(int(len(data_tweet)/batch_size)):\r\n",
        "      res=[]\r\n",
        "      for x in data_tweet[k*(batch_size):(k+1)*(batch_size)]:\r\n",
        "        tweet = [(w2v.wv.word_vec(i[0]),i[1],i[2]) for i in x if i[0] in vocab]\r\n",
        "        l=len(tweet)\r\n",
        "        for i in range(l):\r\n",
        "          if tweet[i][1][:2]=='JJ':\r\n",
        "            for z in range(max(i-1,0),min(i+2,l)):\r\n",
        "              if tweet[z][1][:2]=='NN':\r\n",
        "                tweet[z]=((tweet[z][0]+tweet[i][0])/2,tweet[z][1])\r\n",
        "          if tweet[i][1][:2]=='RB':\r\n",
        "            for z in range(max(i-1,0),min(i+2,l)):\r\n",
        "              if tweet[z][1][:2]=='VB':\r\n",
        "                tweet[z]=((tweet[z][0]+tweet[i][0])/2,tweet[z][1])\r\n",
        "        res+=[np.array([x[0] for x in tweet])]\r\n",
        "      temp = np.array([np.pad(z.flatten(),(0,Max_input_size*Embedding_size-len(z.flatten()))).reshape(Max_input_size,Embedding_size) for z in res])\r\n",
        "      tempres = data_cat[k*(batch_size):(k+1)*(batch_size)]\r\n",
        "      yield (temp,tempres)          \r\n",
        "      \r\n",
        "def glove_gen(vocab,data_tweet,data_cat,batch_size,Max_input_size,Embedding_size,mul_factor=2):\r\n",
        "  while True:\r\n",
        "    for k in range(int(len(data_tweet)/batch_size)):\r\n",
        "      res=[]\r\n",
        "      for x in data_tweet[k*(batch_size):(k+1)*(batch_size)]:\r\n",
        "        tweet = [(vocab[i[0]],i[1],i[2]) for i in x if i[0] in vocab.keys()]\r\n",
        "        l=len(tweet)\r\n",
        "        for i in range(l):\r\n",
        "          if tweet[i][1][:2]=='JJ':\r\n",
        "            for z in range(max(i-1,0),min(i+2,l)):\r\n",
        "              if tweet[z][1][:2]=='NN':\r\n",
        "                tweet[z]=((tweet[z][0]+tweet[i][0])/2,tweet[z][1])\r\n",
        "          if tweet[i][1][:2]=='RB':\r\n",
        "            for z in range(max(i-1,0),min(i+2,l)):\r\n",
        "              if tweet[z][1][:2]=='VB':\r\n",
        "                tweet[z]=((tweet[z][0]+tweet[i][0])/2,tweet[z][1])\r\n",
        "        res+=[np.array([x[0] for x in tweet])]\r\n",
        "      temp = np.array([np.pad(z.flatten(),(0,Max_input_size*Embedding_size-len(z.flatten()))).reshape(Max_input_size,Embedding_size) for z in res])\r\n",
        "      tempres = data_cat[k*(batch_size):(k+1)*(batch_size)]\r\n",
        "      yield (temp,tempres)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BZKZFX7oLyC"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data_tweet, data_cat, test_size=0.20, random_state=42)\r\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42)\r\n",
        "result_table = [0,0,0,0,0,0,0,0,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIj49u6QoLuq"
      },
      "source": [
        "epochs = 40"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XspDStZyoLsD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a9efdfd-4055-4234-b71f-823759e75632"
      },
      "source": [
        "model_sg = tf.keras.Sequential()\r\n",
        "model_sg.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_sg.add(tf.keras.layers.LSTM(50))\r\n",
        "model_sg.add(tf.keras.layers.Dense(13, activation='softmax'))\r\n",
        "model_sg.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy'])\r\n",
        "sg_train_gen=vec_gen(w2v_sg,vocab_sg,X_train,y_train,batch_size,Max_input_size,Embedding_size)\r\n",
        "sg_val_gen=vec_gen(w2v_sg,vocab_sg,X_val,y_val,batch_size,Max_input_size,Embedding_size)\r\n",
        "history_sg_lstm = model_sg.fit_generator(sg_train_gen,validation_data=sg_val_gen,validation_steps=int((len(X_val)/batch_size)+1),steps_per_epoch=int((len(X_train)/batch_size)+1),epochs=epochs)\r\n",
        "history = model_sg.evaluate(x = vec_gen(w2v_sg,vocab_sg,X_test,y_test,batch_size,Max_input_size,Embedding_size),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table[0]=history[1]\r\n",
        "print(\"SG_LSTM\")\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "257/257 [==============================] - 92s 352ms/step - loss: 2.2628 - accuracy: 0.2098 - val_loss: 2.1376 - val_accuracy: 0.2182\n",
            "Epoch 2/40\n",
            "257/257 [==============================] - 89s 346ms/step - loss: 2.1417 - accuracy: 0.2298 - val_loss: 2.0951 - val_accuracy: 0.2617\n",
            "Epoch 3/40\n",
            "257/257 [==============================] - 89s 346ms/step - loss: 2.0946 - accuracy: 0.2605 - val_loss: 2.0719 - val_accuracy: 0.2752\n",
            "Epoch 4/40\n",
            "257/257 [==============================] - 89s 348ms/step - loss: 2.0579 - accuracy: 0.2804 - val_loss: 2.0557 - val_accuracy: 0.2883\n",
            "Epoch 5/40\n",
            "257/257 [==============================] - 90s 350ms/step - loss: 2.0331 - accuracy: 0.2968 - val_loss: 2.0436 - val_accuracy: 0.2923\n",
            "Epoch 6/40\n",
            "257/257 [==============================] - 90s 351ms/step - loss: 2.0218 - accuracy: 0.3017 - val_loss: 2.0307 - val_accuracy: 0.2922\n",
            "Epoch 7/40\n",
            "257/257 [==============================] - 94s 367ms/step - loss: 2.0071 - accuracy: 0.3067 - val_loss: 2.0273 - val_accuracy: 0.2962\n",
            "Epoch 8/40\n",
            "257/257 [==============================] - 99s 385ms/step - loss: 1.9961 - accuracy: 0.3138 - val_loss: 2.0214 - val_accuracy: 0.3003\n",
            "Epoch 9/40\n",
            "257/257 [==============================] - 93s 363ms/step - loss: 1.9865 - accuracy: 0.3188 - val_loss: 2.0176 - val_accuracy: 0.3046\n",
            "Epoch 10/40\n",
            "257/257 [==============================] - 92s 359ms/step - loss: 1.9755 - accuracy: 0.3246 - val_loss: 2.0122 - val_accuracy: 0.3085\n",
            "Epoch 11/40\n",
            "257/257 [==============================] - 93s 363ms/step - loss: 1.9648 - accuracy: 0.3296 - val_loss: 2.0119 - val_accuracy: 0.3111\n",
            "Epoch 12/40\n",
            "257/257 [==============================] - 93s 363ms/step - loss: 1.9574 - accuracy: 0.3321 - val_loss: 2.0110 - val_accuracy: 0.3129\n",
            "Epoch 13/40\n",
            "257/257 [==============================] - 99s 385ms/step - loss: 1.9438 - accuracy: 0.3364 - val_loss: 2.0090 - val_accuracy: 0.3162\n",
            "Epoch 14/40\n",
            "257/257 [==============================] - 95s 369ms/step - loss: 1.9292 - accuracy: 0.3412 - val_loss: 2.0065 - val_accuracy: 0.3152\n",
            "Epoch 15/40\n",
            "257/257 [==============================] - 96s 375ms/step - loss: 1.9211 - accuracy: 0.3472 - val_loss: 2.0004 - val_accuracy: 0.3146\n",
            "Epoch 16/40\n",
            "257/257 [==============================] - 96s 374ms/step - loss: 1.9066 - accuracy: 0.3533 - val_loss: 2.0091 - val_accuracy: 0.3082\n",
            "Epoch 17/40\n",
            "257/257 [==============================] - 98s 383ms/step - loss: 1.8998 - accuracy: 0.3565 - val_loss: 2.0056 - val_accuracy: 0.3135\n",
            "Epoch 18/40\n",
            "257/257 [==============================] - 101s 392ms/step - loss: 1.8880 - accuracy: 0.3607 - val_loss: 2.0069 - val_accuracy: 0.3122\n",
            "Epoch 19/40\n",
            "257/257 [==============================] - 107s 419ms/step - loss: 1.8743 - accuracy: 0.3668 - val_loss: 2.0105 - val_accuracy: 0.3157\n",
            "Epoch 20/40\n",
            "257/257 [==============================] - 102s 398ms/step - loss: 1.8662 - accuracy: 0.3709 - val_loss: 2.0150 - val_accuracy: 0.3175\n",
            "Epoch 21/40\n",
            "257/257 [==============================] - 98s 382ms/step - loss: 1.8605 - accuracy: 0.3742 - val_loss: 2.0204 - val_accuracy: 0.3169\n",
            "Epoch 22/40\n",
            "257/257 [==============================] - 94s 367ms/step - loss: 1.8482 - accuracy: 0.3784 - val_loss: 2.0259 - val_accuracy: 0.3163\n",
            "Epoch 23/40\n",
            "257/257 [==============================] - 94s 367ms/step - loss: 1.8402 - accuracy: 0.3820 - val_loss: 2.0322 - val_accuracy: 0.3168\n",
            "Epoch 24/40\n",
            "257/257 [==============================] - 96s 377ms/step - loss: 1.8309 - accuracy: 0.3874 - val_loss: 2.0417 - val_accuracy: 0.3191\n",
            "Epoch 25/40\n",
            "257/257 [==============================] - 98s 383ms/step - loss: 1.8274 - accuracy: 0.3876 - val_loss: 2.0404 - val_accuracy: 0.3169\n",
            "Epoch 26/40\n",
            "257/257 [==============================] - 96s 375ms/step - loss: 1.8135 - accuracy: 0.3959 - val_loss: 2.0445 - val_accuracy: 0.3211\n",
            "Epoch 27/40\n",
            "257/257 [==============================] - 98s 383ms/step - loss: 1.8094 - accuracy: 0.3977 - val_loss: 2.0511 - val_accuracy: 0.3158\n",
            "Epoch 28/40\n",
            "257/257 [==============================] - 99s 386ms/step - loss: 1.8029 - accuracy: 0.4011 - val_loss: 2.0576 - val_accuracy: 0.3137\n",
            "Epoch 29/40\n",
            "257/257 [==============================] - 99s 387ms/step - loss: 1.7971 - accuracy: 0.4034 - val_loss: 2.0636 - val_accuracy: 0.3171\n",
            "Epoch 30/40\n",
            "257/257 [==============================] - 101s 395ms/step - loss: 1.7884 - accuracy: 0.4070 - val_loss: 2.0697 - val_accuracy: 0.3151\n",
            "Epoch 31/40\n",
            "257/257 [==============================] - 100s 391ms/step - loss: 1.7784 - accuracy: 0.4088 - val_loss: 2.0802 - val_accuracy: 0.3174\n",
            "Epoch 32/40\n",
            "257/257 [==============================] - 94s 367ms/step - loss: 1.7710 - accuracy: 0.4150 - val_loss: 2.0907 - val_accuracy: 0.3105\n",
            "Epoch 33/40\n",
            "257/257 [==============================] - 94s 366ms/step - loss: 1.7650 - accuracy: 0.4148 - val_loss: 2.0905 - val_accuracy: 0.3040\n",
            "Epoch 34/40\n",
            "257/257 [==============================] - 94s 366ms/step - loss: 1.7731 - accuracy: 0.4102 - val_loss: 2.1067 - val_accuracy: 0.3035\n",
            "Epoch 35/40\n",
            "257/257 [==============================] - 96s 374ms/step - loss: 1.7625 - accuracy: 0.4105 - val_loss: 2.1181 - val_accuracy: 0.3012\n",
            "Epoch 36/40\n",
            "257/257 [==============================] - 94s 368ms/step - loss: 1.7445 - accuracy: 0.4226 - val_loss: 2.1157 - val_accuracy: 0.2995\n",
            "Epoch 37/40\n",
            "257/257 [==============================] - 94s 367ms/step - loss: 1.7335 - accuracy: 0.4240 - val_loss: 2.1260 - val_accuracy: 0.3022\n",
            "Epoch 38/40\n",
            "257/257 [==============================] - 95s 372ms/step - loss: 1.7255 - accuracy: 0.4303 - val_loss: 2.1155 - val_accuracy: 0.3031\n",
            "Epoch 39/40\n",
            "257/257 [==============================] - 94s 368ms/step - loss: 1.7220 - accuracy: 0.4282 - val_loss: 2.1177 - val_accuracy: 0.3012\n",
            "Epoch 40/40\n",
            "257/257 [==============================] - 93s 362ms/step - loss: 1.7252 - accuracy: 0.4269 - val_loss: 2.1231 - val_accuracy: 0.3069\n",
            "80/80 [==============================] - 22s 276ms/step - loss: 2.1353 - accuracy: 0.3063\n",
            "[2.135326862335205, 0.3062500059604645]\n",
            "SG_LSTM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9VFILTsoLpE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0142d746-8c11-46a9-ec50-fb809bfb26c4"
      },
      "source": [
        "model_sg_bi = tf.keras.Sequential()\r\n",
        "model_sg_bi.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_sg_bi.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50),merge_mode='concat'))\r\n",
        "model_sg_bi.add(tf.keras.layers.Dense(13, activation='softmax'))\r\n",
        "model_sg_bi.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy'])\r\n",
        "history_sg_bi = model_sg_bi.fit_generator(sg_train_gen,validation_data=sg_val_gen,validation_steps=int((len(X_val)/batch_size)+1),steps_per_epoch=int((len(X_train)/batch_size)+1),epochs=epochs)\r\n",
        "history = model_sg_bi.evaluate(x = vec_gen(w2v_sg,vocab_sg,X_test,y_test,batch_size,Max_input_size,Embedding_size),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table[1]=history[1]\r\n",
        "print(\"SG_BI\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "257/257 [==============================] - 107s 403ms/step - loss: 2.2408 - accuracy: 0.2211 - val_loss: 2.0670 - val_accuracy: 0.2771\n",
            "Epoch 2/40\n",
            "257/257 [==============================] - 99s 387ms/step - loss: 2.0593 - accuracy: 0.2859 - val_loss: 2.0313 - val_accuracy: 0.2986\n",
            "Epoch 3/40\n",
            "257/257 [==============================] - 100s 391ms/step - loss: 2.0220 - accuracy: 0.3057 - val_loss: 2.0193 - val_accuracy: 0.3083\n",
            "Epoch 4/40\n",
            "257/257 [==============================] - 100s 391ms/step - loss: 2.0029 - accuracy: 0.3158 - val_loss: 2.0140 - val_accuracy: 0.3109\n",
            "Epoch 5/40\n",
            "257/257 [==============================] - 100s 389ms/step - loss: 1.9860 - accuracy: 0.3211 - val_loss: 2.0112 - val_accuracy: 0.3125\n",
            "Epoch 6/40\n",
            "257/257 [==============================] - 101s 392ms/step - loss: 1.9705 - accuracy: 0.3264 - val_loss: 2.0097 - val_accuracy: 0.3126\n",
            "Epoch 7/40\n",
            "257/257 [==============================] - 100s 392ms/step - loss: 1.9556 - accuracy: 0.3328 - val_loss: 2.0077 - val_accuracy: 0.3098\n",
            "Epoch 8/40\n",
            "257/257 [==============================] - 99s 387ms/step - loss: 1.9399 - accuracy: 0.3394 - val_loss: 2.0142 - val_accuracy: 0.3077\n",
            "Epoch 9/40\n",
            "257/257 [==============================] - 101s 396ms/step - loss: 1.9282 - accuracy: 0.3424 - val_loss: 2.0091 - val_accuracy: 0.3103\n",
            "Epoch 10/40\n",
            "257/257 [==============================] - 102s 396ms/step - loss: 1.9121 - accuracy: 0.3477 - val_loss: 2.0120 - val_accuracy: 0.3075\n",
            "Epoch 11/40\n",
            "257/257 [==============================] - 99s 385ms/step - loss: 1.8946 - accuracy: 0.3515 - val_loss: 2.0174 - val_accuracy: 0.3085\n",
            "Epoch 12/40\n",
            "257/257 [==============================] - 98s 384ms/step - loss: 1.8782 - accuracy: 0.3570 - val_loss: 2.0275 - val_accuracy: 0.3048\n",
            "Epoch 13/40\n",
            "257/257 [==============================] - 99s 386ms/step - loss: 1.8608 - accuracy: 0.3631 - val_loss: 2.0364 - val_accuracy: 0.3025\n",
            "Epoch 14/40\n",
            "257/257 [==============================] - 98s 382ms/step - loss: 1.8450 - accuracy: 0.3699 - val_loss: 2.0438 - val_accuracy: 0.3005\n",
            "Epoch 15/40\n",
            "257/257 [==============================] - 97s 378ms/step - loss: 1.8297 - accuracy: 0.3752 - val_loss: 2.0567 - val_accuracy: 0.3035\n",
            "Epoch 16/40\n",
            "257/257 [==============================] - 98s 381ms/step - loss: 1.8114 - accuracy: 0.3833 - val_loss: 2.0656 - val_accuracy: 0.3015\n",
            "Epoch 17/40\n",
            "257/257 [==============================] - 98s 383ms/step - loss: 1.7980 - accuracy: 0.3867 - val_loss: 2.0738 - val_accuracy: 0.3017\n",
            "Epoch 18/40\n",
            "257/257 [==============================] - 97s 378ms/step - loss: 1.7838 - accuracy: 0.3922 - val_loss: 2.0862 - val_accuracy: 0.2978\n",
            "Epoch 19/40\n",
            "257/257 [==============================] - 98s 384ms/step - loss: 1.7652 - accuracy: 0.3992 - val_loss: 2.1002 - val_accuracy: 0.2937\n",
            "Epoch 20/40\n",
            "257/257 [==============================] - 97s 380ms/step - loss: 1.7486 - accuracy: 0.4060 - val_loss: 2.1071 - val_accuracy: 0.2929\n",
            "Epoch 21/40\n",
            "257/257 [==============================] - 98s 382ms/step - loss: 1.7368 - accuracy: 0.4074 - val_loss: 2.1251 - val_accuracy: 0.2925\n",
            "Epoch 22/40\n",
            "257/257 [==============================] - 98s 383ms/step - loss: 1.7250 - accuracy: 0.4108 - val_loss: 2.1348 - val_accuracy: 0.2912\n",
            "Epoch 23/40\n",
            "257/257 [==============================] - 97s 379ms/step - loss: 1.7107 - accuracy: 0.4171 - val_loss: 2.1385 - val_accuracy: 0.2917\n",
            "Epoch 24/40\n",
            "257/257 [==============================] - 99s 386ms/step - loss: 1.6835 - accuracy: 0.4292 - val_loss: 2.1588 - val_accuracy: 0.2868\n",
            "Epoch 25/40\n",
            "257/257 [==============================] - 100s 392ms/step - loss: 1.6777 - accuracy: 0.4311 - val_loss: 2.1645 - val_accuracy: 0.2860\n",
            "Epoch 26/40\n",
            "257/257 [==============================] - 102s 397ms/step - loss: 1.6635 - accuracy: 0.4380 - val_loss: 2.1817 - val_accuracy: 0.2874\n",
            "Epoch 27/40\n",
            "257/257 [==============================] - 101s 394ms/step - loss: 1.6486 - accuracy: 0.4434 - val_loss: 2.2143 - val_accuracy: 0.2828\n",
            "Epoch 28/40\n",
            "257/257 [==============================] - 101s 393ms/step - loss: 1.6350 - accuracy: 0.4475 - val_loss: 2.2397 - val_accuracy: 0.2798\n",
            "Epoch 29/40\n",
            "257/257 [==============================] - 102s 398ms/step - loss: 1.6243 - accuracy: 0.4505 - val_loss: 2.2739 - val_accuracy: 0.2832\n",
            "Epoch 30/40\n",
            "257/257 [==============================] - 101s 395ms/step - loss: 1.6020 - accuracy: 0.4558 - val_loss: 2.2818 - val_accuracy: 0.2840\n",
            "Epoch 31/40\n",
            "257/257 [==============================] - 100s 391ms/step - loss: 1.5850 - accuracy: 0.4624 - val_loss: 2.2815 - val_accuracy: 0.2829\n",
            "Epoch 32/40\n",
            "257/257 [==============================] - 101s 393ms/step - loss: 1.5709 - accuracy: 0.4717 - val_loss: 2.2838 - val_accuracy: 0.2802\n",
            "Epoch 33/40\n",
            "257/257 [==============================] - 99s 388ms/step - loss: 1.5574 - accuracy: 0.4736 - val_loss: 2.2943 - val_accuracy: 0.2780\n",
            "Epoch 34/40\n",
            "257/257 [==============================] - 99s 387ms/step - loss: 1.5354 - accuracy: 0.4828 - val_loss: 2.2913 - val_accuracy: 0.2814\n",
            "Epoch 35/40\n",
            "257/257 [==============================] - 101s 392ms/step - loss: 1.5255 - accuracy: 0.4864 - val_loss: 2.3302 - val_accuracy: 0.2758\n",
            "Epoch 36/40\n",
            "257/257 [==============================] - 99s 386ms/step - loss: 1.5111 - accuracy: 0.4906 - val_loss: 2.3509 - val_accuracy: 0.2782\n",
            "Epoch 37/40\n",
            "257/257 [==============================] - 98s 382ms/step - loss: 1.4859 - accuracy: 0.5026 - val_loss: 2.3441 - val_accuracy: 0.2726\n",
            "Epoch 38/40\n",
            "257/257 [==============================] - 99s 386ms/step - loss: 1.4715 - accuracy: 0.5094 - val_loss: 2.3729 - val_accuracy: 0.2715\n",
            "Epoch 39/40\n",
            "257/257 [==============================] - 99s 387ms/step - loss: 1.4624 - accuracy: 0.5098 - val_loss: 2.3901 - val_accuracy: 0.2746\n",
            "Epoch 40/40\n",
            "257/257 [==============================] - 99s 386ms/step - loss: 1.4631 - accuracy: 0.5097 - val_loss: 2.3872 - val_accuracy: 0.2749\n",
            "80/80 [==============================] - 22s 276ms/step - loss: 2.4172 - accuracy: 0.2771\n",
            "[2.417156934738159, 0.2771250009536743]\n",
            "SG_BI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlpoO9KGoLiz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d2261a7-b5bf-474b-eb1d-03ca11bfe5a0"
      },
      "source": [
        "model_sg_rnn = tf.keras.Sequential()\r\n",
        "model_sg_rnn.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_sg_rnn.add(tf.keras.layers.SimpleRNN(50))\r\n",
        "model_sg_rnn.add(tf.keras.layers.Dense(13, activation='softmax'))\r\n",
        "model_sg_rnn.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy'])\r\n",
        "history_sg_rnn = model_sg_rnn.fit_generator(sg_train_gen,validation_data=sg_val_gen,validation_steps=int((len(X_val)/batch_size)+1),steps_per_epoch=int((len(X_train)/batch_size)+1),epochs=epochs)\r\n",
        "history = model_sg_rnn.evaluate(x = vec_gen(w2v_sg,vocab_sg,X_test,y_test,batch_size,Max_input_size,Embedding_size),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "\r\n",
        "result_table[2]=history[1]\r\n",
        "print(\"SG_RNN\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "257/257 [==============================] - 87s 334ms/step - loss: 2.2733 - accuracy: 0.1824 - val_loss: 2.1413 - val_accuracy: 0.2157\n",
            "Epoch 2/40\n",
            "257/257 [==============================] - 84s 326ms/step - loss: 2.1427 - accuracy: 0.2170 - val_loss: 2.1368 - val_accuracy: 0.2154\n",
            "Epoch 3/40\n",
            "257/257 [==============================] - 83s 324ms/step - loss: 2.1437 - accuracy: 0.2153 - val_loss: 2.1378 - val_accuracy: 0.2158\n",
            "Epoch 4/40\n",
            "257/257 [==============================] - 82s 321ms/step - loss: 2.1441 - accuracy: 0.2158 - val_loss: 2.1396 - val_accuracy: 0.2154\n",
            "Epoch 5/40\n",
            "257/257 [==============================] - 84s 328ms/step - loss: 2.1413 - accuracy: 0.2144 - val_loss: 2.1386 - val_accuracy: 0.2158\n",
            "Epoch 6/40\n",
            "257/257 [==============================] - 83s 325ms/step - loss: 2.1418 - accuracy: 0.2165 - val_loss: 2.1387 - val_accuracy: 0.2132\n",
            "Epoch 7/40\n",
            "257/257 [==============================] - 83s 324ms/step - loss: 2.1402 - accuracy: 0.2218 - val_loss: 2.1396 - val_accuracy: 0.2105\n",
            "Epoch 8/40\n",
            "257/257 [==============================] - 82s 321ms/step - loss: 2.1395 - accuracy: 0.2236 - val_loss: 2.1381 - val_accuracy: 0.2146\n",
            "Epoch 9/40\n",
            "257/257 [==============================] - 84s 326ms/step - loss: 2.1407 - accuracy: 0.2191 - val_loss: 2.1380 - val_accuracy: 0.2138\n",
            "Epoch 10/40\n",
            "257/257 [==============================] - 84s 328ms/step - loss: 2.1382 - accuracy: 0.2236 - val_loss: 2.1377 - val_accuracy: 0.2075\n",
            "Epoch 11/40\n",
            "257/257 [==============================] - 84s 327ms/step - loss: 2.1381 - accuracy: 0.2294 - val_loss: 2.1410 - val_accuracy: 0.2155\n",
            "Epoch 12/40\n",
            "257/257 [==============================] - 84s 328ms/step - loss: 2.1324 - accuracy: 0.2312 - val_loss: 2.1299 - val_accuracy: 0.2183\n",
            "Epoch 13/40\n",
            "257/257 [==============================] - 84s 328ms/step - loss: 2.1172 - accuracy: 0.2425 - val_loss: 2.1173 - val_accuracy: 0.2340\n",
            "Epoch 14/40\n",
            "257/257 [==============================] - 85s 333ms/step - loss: 2.1037 - accuracy: 0.2471 - val_loss: 2.1190 - val_accuracy: 0.2323\n",
            "Epoch 15/40\n",
            "257/257 [==============================] - 85s 330ms/step - loss: 2.0906 - accuracy: 0.2606 - val_loss: 2.1141 - val_accuracy: 0.2362\n",
            "Epoch 16/40\n",
            "257/257 [==============================] - 85s 331ms/step - loss: 2.0831 - accuracy: 0.2642 - val_loss: 2.1205 - val_accuracy: 0.2323\n",
            "Epoch 17/40\n",
            "257/257 [==============================] - 84s 327ms/step - loss: 2.0738 - accuracy: 0.2706 - val_loss: 2.1161 - val_accuracy: 0.2337\n",
            "Epoch 18/40\n",
            "257/257 [==============================] - 84s 328ms/step - loss: 2.0683 - accuracy: 0.2655 - val_loss: 2.1162 - val_accuracy: 0.2335\n",
            "Epoch 19/40\n",
            "257/257 [==============================] - 84s 329ms/step - loss: 2.0657 - accuracy: 0.2678 - val_loss: 2.1201 - val_accuracy: 0.2325\n",
            "Epoch 20/40\n",
            "257/257 [==============================] - 84s 327ms/step - loss: 2.0653 - accuracy: 0.2725 - val_loss: 2.1331 - val_accuracy: 0.2283\n",
            "Epoch 21/40\n",
            "257/257 [==============================] - 83s 326ms/step - loss: 2.0614 - accuracy: 0.2724 - val_loss: 2.1327 - val_accuracy: 0.2309\n",
            "Epoch 22/40\n",
            "257/257 [==============================] - 85s 331ms/step - loss: 2.0542 - accuracy: 0.2765 - val_loss: 2.1227 - val_accuracy: 0.2414\n",
            "Epoch 23/40\n",
            "257/257 [==============================] - 84s 329ms/step - loss: 2.0460 - accuracy: 0.2820 - val_loss: 2.1272 - val_accuracy: 0.2415\n",
            "Epoch 24/40\n",
            "257/257 [==============================] - 84s 326ms/step - loss: 2.0426 - accuracy: 0.2793 - val_loss: 2.1362 - val_accuracy: 0.2414\n",
            "Epoch 25/40\n",
            "257/257 [==============================] - 84s 327ms/step - loss: 2.0358 - accuracy: 0.2865 - val_loss: 2.1424 - val_accuracy: 0.2366\n",
            "Epoch 26/40\n",
            "257/257 [==============================] - 84s 329ms/step - loss: 2.0355 - accuracy: 0.2845 - val_loss: 2.1476 - val_accuracy: 0.2345\n",
            "Epoch 27/40\n",
            "257/257 [==============================] - 83s 325ms/step - loss: 2.0333 - accuracy: 0.2850 - val_loss: 2.1364 - val_accuracy: 0.2371\n",
            "Epoch 28/40\n",
            "257/257 [==============================] - 84s 326ms/step - loss: 2.0305 - accuracy: 0.2894 - val_loss: 2.1551 - val_accuracy: 0.2357\n",
            "Epoch 29/40\n",
            "257/257 [==============================] - 84s 330ms/step - loss: 2.0255 - accuracy: 0.2920 - val_loss: 2.1532 - val_accuracy: 0.2391\n",
            "Epoch 30/40\n",
            "257/257 [==============================] - 83s 324ms/step - loss: 2.0157 - accuracy: 0.2952 - val_loss: 2.1605 - val_accuracy: 0.2317\n",
            "Epoch 31/40\n",
            "257/257 [==============================] - 84s 327ms/step - loss: 2.0185 - accuracy: 0.2951 - val_loss: 2.1616 - val_accuracy: 0.2325\n",
            "Epoch 32/40\n",
            "257/257 [==============================] - 83s 325ms/step - loss: 2.0205 - accuracy: 0.2931 - val_loss: 2.1596 - val_accuracy: 0.2322\n",
            "Epoch 33/40\n",
            "257/257 [==============================] - 83s 325ms/step - loss: 2.0225 - accuracy: 0.3003 - val_loss: 2.1576 - val_accuracy: 0.2317\n",
            "Epoch 34/40\n",
            "257/257 [==============================] - 84s 330ms/step - loss: 2.0139 - accuracy: 0.2997 - val_loss: 2.1523 - val_accuracy: 0.2400\n",
            "Epoch 35/40\n",
            "257/257 [==============================] - 84s 327ms/step - loss: 2.0175 - accuracy: 0.2984 - val_loss: 2.1701 - val_accuracy: 0.2291\n",
            "Epoch 36/40\n",
            "257/257 [==============================] - 83s 323ms/step - loss: 2.0139 - accuracy: 0.3014 - val_loss: 2.1642 - val_accuracy: 0.2351\n",
            "Epoch 37/40\n",
            "257/257 [==============================] - 84s 327ms/step - loss: 2.0118 - accuracy: 0.3049 - val_loss: 2.1612 - val_accuracy: 0.2343\n",
            "Epoch 38/40\n",
            "257/257 [==============================] - 84s 327ms/step - loss: 2.0089 - accuracy: 0.3026 - val_loss: 2.1646 - val_accuracy: 0.2295\n",
            "Epoch 39/40\n",
            "257/257 [==============================] - 83s 324ms/step - loss: 2.0020 - accuracy: 0.3102 - val_loss: 2.1741 - val_accuracy: 0.2298\n",
            "Epoch 40/40\n",
            "257/257 [==============================] - 83s 323ms/step - loss: 2.0118 - accuracy: 0.3050 - val_loss: 2.1676 - val_accuracy: 0.2305\n",
            "80/80 [==============================] - 20s 256ms/step - loss: 2.1816 - accuracy: 0.2393\n",
            "[2.181575059890747, 0.23925000429153442]\n",
            "SG_RNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJt84aNsomaT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fa402a4-0d4c-4714-c739-11c90d7e8a06"
      },
      "source": [
        "model_cbow = tf.keras.Sequential()\r\n",
        "model_cbow.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_cbow.add(tf.keras.layers.LSTM(50))\r\n",
        "model_cbow.add(tf.keras.layers.Dense(13, activation='softmax'))\r\n",
        "model_cbow.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy'])\r\n",
        "cbow_train_gen=vec_gen(w2v_cbow,vocab_cbow,X_train,y_train,batch_size,Max_input_size,Embedding_size)\r\n",
        "cbow_val_gen=vec_gen(w2v_cbow,vocab_cbow,X_val,y_val,batch_size,Max_input_size,Embedding_size)\r\n",
        "history_cbow_lstm = model_cbow.fit_generator(cbow_train_gen,validation_data=cbow_val_gen,validation_steps=int((len(X_val)/batch_size)+1),steps_per_epoch=int((len(X_train)/batch_size)+1),epochs=epochs)\r\n",
        "history = model_cbow.evaluate(x = vec_gen(w2v_cbow,vocab_cbow,X_test,y_test,batch_size,Max_input_size,Embedding_size),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table[3]=history[1]\r\n",
        "print(\"CBOW_LSTM\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "257/257 [==============================] - 91s 350ms/step - loss: 2.2548 - accuracy: 0.2135 - val_loss: 2.1324 - val_accuracy: 0.2212\n",
            "Epoch 2/40\n",
            "257/257 [==============================] - 88s 345ms/step - loss: 2.1360 - accuracy: 0.2216 - val_loss: 2.0945 - val_accuracy: 0.2509\n",
            "Epoch 3/40\n",
            "257/257 [==============================] - 90s 350ms/step - loss: 2.0946 - accuracy: 0.2455 - val_loss: 2.0739 - val_accuracy: 0.2628\n",
            "Epoch 4/40\n",
            "257/257 [==============================] - 91s 354ms/step - loss: 2.0614 - accuracy: 0.2748 - val_loss: 2.0580 - val_accuracy: 0.2835\n",
            "Epoch 5/40\n",
            "257/257 [==============================] - 91s 354ms/step - loss: 2.0381 - accuracy: 0.2941 - val_loss: 2.0448 - val_accuracy: 0.2951\n",
            "Epoch 6/40\n",
            "257/257 [==============================] - 92s 357ms/step - loss: 2.0252 - accuracy: 0.3054 - val_loss: 2.0324 - val_accuracy: 0.2985\n",
            "Epoch 7/40\n",
            "257/257 [==============================] - 90s 353ms/step - loss: 2.0100 - accuracy: 0.3135 - val_loss: 2.0289 - val_accuracy: 0.2989\n",
            "Epoch 8/40\n",
            "257/257 [==============================] - 93s 364ms/step - loss: 1.9992 - accuracy: 0.3170 - val_loss: 2.0242 - val_accuracy: 0.3043\n",
            "Epoch 9/40\n",
            "257/257 [==============================] - 95s 370ms/step - loss: 1.9892 - accuracy: 0.3207 - val_loss: 2.0214 - val_accuracy: 0.3037\n",
            "Epoch 10/40\n",
            "257/257 [==============================] - 99s 386ms/step - loss: 1.9784 - accuracy: 0.3271 - val_loss: 2.0175 - val_accuracy: 0.3051\n",
            "Epoch 11/40\n",
            "257/257 [==============================] - 96s 375ms/step - loss: 1.9675 - accuracy: 0.3322 - val_loss: 2.0170 - val_accuracy: 0.3037\n",
            "Epoch 12/40\n",
            "257/257 [==============================] - 95s 372ms/step - loss: 1.9599 - accuracy: 0.3346 - val_loss: 2.0139 - val_accuracy: 0.3057\n",
            "Epoch 13/40\n",
            "257/257 [==============================] - 93s 364ms/step - loss: 1.9455 - accuracy: 0.3379 - val_loss: 2.0114 - val_accuracy: 0.3078\n",
            "Epoch 14/40\n",
            "257/257 [==============================] - 92s 358ms/step - loss: 1.9309 - accuracy: 0.3433 - val_loss: 2.0109 - val_accuracy: 0.3062\n",
            "Epoch 15/40\n",
            "257/257 [==============================] - 92s 358ms/step - loss: 1.9233 - accuracy: 0.3479 - val_loss: 2.0134 - val_accuracy: 0.3091\n",
            "Epoch 16/40\n",
            "257/257 [==============================] - 91s 354ms/step - loss: 1.9103 - accuracy: 0.3515 - val_loss: 2.0171 - val_accuracy: 0.3066\n",
            "Epoch 17/40\n",
            "257/257 [==============================] - 89s 347ms/step - loss: 1.9042 - accuracy: 0.3541 - val_loss: 2.0197 - val_accuracy: 0.3091\n",
            "Epoch 18/40\n",
            "257/257 [==============================] - 92s 358ms/step - loss: 1.8936 - accuracy: 0.3589 - val_loss: 2.0226 - val_accuracy: 0.3094\n",
            "Epoch 19/40\n",
            "257/257 [==============================] - 89s 348ms/step - loss: 1.8796 - accuracy: 0.3660 - val_loss: 2.0219 - val_accuracy: 0.3126\n",
            "Epoch 20/40\n",
            "257/257 [==============================] - 89s 346ms/step - loss: 1.8681 - accuracy: 0.3718 - val_loss: 2.0274 - val_accuracy: 0.3080\n",
            "Epoch 21/40\n",
            "257/257 [==============================] - 89s 349ms/step - loss: 1.8628 - accuracy: 0.3737 - val_loss: 2.0145 - val_accuracy: 0.3180\n",
            "Epoch 22/40\n",
            "257/257 [==============================] - 89s 348ms/step - loss: 1.8519 - accuracy: 0.3778 - val_loss: 2.0134 - val_accuracy: 0.3137\n",
            "Epoch 23/40\n",
            "257/257 [==============================] - 89s 349ms/step - loss: 1.8413 - accuracy: 0.3815 - val_loss: 2.0268 - val_accuracy: 0.3111\n",
            "Epoch 24/40\n",
            "257/257 [==============================] - 89s 348ms/step - loss: 1.8363 - accuracy: 0.3838 - val_loss: 2.0273 - val_accuracy: 0.3083\n",
            "Epoch 25/40\n",
            "257/257 [==============================] - 90s 352ms/step - loss: 1.8277 - accuracy: 0.3868 - val_loss: 2.0294 - val_accuracy: 0.3114\n",
            "Epoch 26/40\n",
            "257/257 [==============================] - 89s 346ms/step - loss: 1.8208 - accuracy: 0.3905 - val_loss: 2.0328 - val_accuracy: 0.3135\n",
            "Epoch 27/40\n",
            "257/257 [==============================] - 89s 347ms/step - loss: 1.8239 - accuracy: 0.3909 - val_loss: 2.0363 - val_accuracy: 0.3120\n",
            "Epoch 28/40\n",
            "257/257 [==============================] - 90s 351ms/step - loss: 1.8119 - accuracy: 0.3954 - val_loss: 2.0309 - val_accuracy: 0.3137\n",
            "Epoch 29/40\n",
            "257/257 [==============================] - 89s 349ms/step - loss: 1.8123 - accuracy: 0.3956 - val_loss: 2.0309 - val_accuracy: 0.3115\n",
            "Epoch 30/40\n",
            "257/257 [==============================] - 88s 343ms/step - loss: 1.7955 - accuracy: 0.4016 - val_loss: 2.0592 - val_accuracy: 0.3068\n",
            "Epoch 31/40\n",
            "257/257 [==============================] - 89s 346ms/step - loss: 1.7852 - accuracy: 0.4043 - val_loss: 2.0727 - val_accuracy: 0.3045\n",
            "Epoch 32/40\n",
            "257/257 [==============================] - 91s 356ms/step - loss: 1.7720 - accuracy: 0.4066 - val_loss: 2.0849 - val_accuracy: 0.3031\n",
            "Epoch 33/40\n",
            "257/257 [==============================] - 88s 345ms/step - loss: 1.7689 - accuracy: 0.4080 - val_loss: 2.0920 - val_accuracy: 0.3017\n",
            "Epoch 34/40\n",
            "257/257 [==============================] - 88s 345ms/step - loss: 1.7590 - accuracy: 0.4116 - val_loss: 2.1021 - val_accuracy: 0.3035\n",
            "Epoch 35/40\n",
            "257/257 [==============================] - 90s 351ms/step - loss: 1.7527 - accuracy: 0.4131 - val_loss: 2.0966 - val_accuracy: 0.3052\n",
            "Epoch 36/40\n",
            "257/257 [==============================] - 89s 349ms/step - loss: 1.7409 - accuracy: 0.4140 - val_loss: 2.1132 - val_accuracy: 0.3006\n",
            "Epoch 37/40\n",
            "257/257 [==============================] - 88s 344ms/step - loss: 1.7394 - accuracy: 0.4124 - val_loss: 2.1313 - val_accuracy: 0.2966\n",
            "Epoch 38/40\n",
            "257/257 [==============================] - 88s 342ms/step - loss: 1.7459 - accuracy: 0.4123 - val_loss: 2.1168 - val_accuracy: 0.2995\n",
            "Epoch 39/40\n",
            "257/257 [==============================] - 88s 343ms/step - loss: 1.7544 - accuracy: 0.4119 - val_loss: 2.1163 - val_accuracy: 0.3031\n",
            "Epoch 40/40\n",
            "257/257 [==============================] - 88s 343ms/step - loss: 1.7357 - accuracy: 0.4174 - val_loss: 2.1217 - val_accuracy: 0.3026\n",
            "80/80 [==============================] - 20s 258ms/step - loss: 2.1393 - accuracy: 0.3052\n",
            "[2.139293670654297, 0.30524998903274536]\n",
            "CBOW_LSTM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn15zb6NomYU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb843297-465b-443f-cdad-0eb0db8d471d"
      },
      "source": [
        "model_cbow_bi = tf.keras.Sequential()\r\n",
        "model_cbow_bi.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_cbow_bi.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50),merge_mode='concat'))\r\n",
        "model_cbow_bi.add(tf.keras.layers.Dense(13, activation='softmax'))\r\n",
        "model_cbow_bi.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy'])\r\n",
        "history_cbow_bi = model_cbow_bi.fit_generator(cbow_train_gen,validation_data=cbow_val_gen,validation_steps=int((len(X_val)/batch_size)+1),steps_per_epoch=int((len(X_train)/batch_size)+1),epochs=epochs)\r\n",
        "history = model_cbow_bi.evaluate(x = vec_gen(w2v_cbow,vocab_cbow,X_test,y_test,batch_size,Max_input_size,Embedding_size),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table[4]=history[1]\r\n",
        "print(\"CBOW_BI\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "257/257 [==============================] - 108s 406ms/step - loss: 2.2421 - accuracy: 0.2274 - val_loss: 2.0779 - val_accuracy: 0.2748\n",
            "Epoch 2/40\n",
            "257/257 [==============================] - 99s 385ms/step - loss: 2.0628 - accuracy: 0.2841 - val_loss: 2.0411 - val_accuracy: 0.2949\n",
            "Epoch 3/40\n",
            "257/257 [==============================] - 114s 445ms/step - loss: 2.0274 - accuracy: 0.2988 - val_loss: 2.0286 - val_accuracy: 0.3012\n",
            "Epoch 4/40\n",
            "257/257 [==============================] - 116s 454ms/step - loss: 2.0105 - accuracy: 0.3090 - val_loss: 2.0253 - val_accuracy: 0.3015\n",
            "Epoch 5/40\n",
            "257/257 [==============================] - 121s 474ms/step - loss: 1.9928 - accuracy: 0.3167 - val_loss: 2.0250 - val_accuracy: 0.3040\n",
            "Epoch 6/40\n",
            "257/257 [==============================] - 114s 445ms/step - loss: 1.9762 - accuracy: 0.3220 - val_loss: 2.0243 - val_accuracy: 0.3040\n",
            "Epoch 7/40\n",
            "257/257 [==============================] - 119s 465ms/step - loss: 1.9599 - accuracy: 0.3296 - val_loss: 2.0280 - val_accuracy: 0.2985\n",
            "Epoch 8/40\n",
            "257/257 [==============================] - 121s 470ms/step - loss: 1.9455 - accuracy: 0.3353 - val_loss: 2.0366 - val_accuracy: 0.2972\n",
            "Epoch 9/40\n",
            "257/257 [==============================] - 120s 467ms/step - loss: 1.9335 - accuracy: 0.3396 - val_loss: 2.0331 - val_accuracy: 0.2963\n",
            "Epoch 10/40\n",
            "257/257 [==============================] - 121s 472ms/step - loss: 1.9166 - accuracy: 0.3455 - val_loss: 2.0332 - val_accuracy: 0.2965\n",
            "Epoch 11/40\n",
            "257/257 [==============================] - 119s 464ms/step - loss: 1.9018 - accuracy: 0.3495 - val_loss: 2.0348 - val_accuracy: 0.2969\n",
            "Epoch 12/40\n",
            "257/257 [==============================] - 124s 485ms/step - loss: 1.8903 - accuracy: 0.3527 - val_loss: 2.0421 - val_accuracy: 0.2915\n",
            "Epoch 13/40\n",
            "257/257 [==============================] - 121s 473ms/step - loss: 1.8716 - accuracy: 0.3562 - val_loss: 2.0474 - val_accuracy: 0.2908\n",
            "Epoch 14/40\n",
            "257/257 [==============================] - 127s 494ms/step - loss: 1.8576 - accuracy: 0.3636 - val_loss: 2.0496 - val_accuracy: 0.2951\n",
            "Epoch 15/40\n",
            "257/257 [==============================] - 107s 416ms/step - loss: 1.8422 - accuracy: 0.3692 - val_loss: 2.0572 - val_accuracy: 0.2909\n",
            "Epoch 16/40\n",
            "257/257 [==============================] - 99s 385ms/step - loss: 1.8254 - accuracy: 0.3742 - val_loss: 2.0694 - val_accuracy: 0.2880\n",
            "Epoch 17/40\n",
            "257/257 [==============================] - 99s 388ms/step - loss: 1.8116 - accuracy: 0.3810 - val_loss: 2.0784 - val_accuracy: 0.2888\n",
            "Epoch 18/40\n",
            "257/257 [==============================] - 101s 395ms/step - loss: 1.7961 - accuracy: 0.3856 - val_loss: 2.0728 - val_accuracy: 0.2928\n",
            "Epoch 19/40\n",
            "257/257 [==============================] - 100s 390ms/step - loss: 1.7797 - accuracy: 0.3932 - val_loss: 2.0696 - val_accuracy: 0.2942\n",
            "Epoch 20/40\n",
            "257/257 [==============================] - 101s 395ms/step - loss: 1.7613 - accuracy: 0.4007 - val_loss: 2.0825 - val_accuracy: 0.2985\n",
            "Epoch 21/40\n",
            "257/257 [==============================] - 102s 398ms/step - loss: 1.7488 - accuracy: 0.4039 - val_loss: 2.0947 - val_accuracy: 0.2975\n",
            "Epoch 22/40\n",
            "257/257 [==============================] - 101s 394ms/step - loss: 1.7323 - accuracy: 0.4119 - val_loss: 2.0927 - val_accuracy: 0.2966\n",
            "Epoch 23/40\n",
            "257/257 [==============================] - 101s 392ms/step - loss: 1.7163 - accuracy: 0.4185 - val_loss: 2.1160 - val_accuracy: 0.2949\n",
            "Epoch 24/40\n",
            "257/257 [==============================] - 103s 401ms/step - loss: 1.6939 - accuracy: 0.4212 - val_loss: 2.1265 - val_accuracy: 0.2980\n",
            "Epoch 25/40\n",
            "257/257 [==============================] - 105s 408ms/step - loss: 1.6794 - accuracy: 0.4233 - val_loss: 2.1364 - val_accuracy: 0.2962\n",
            "Epoch 26/40\n",
            "257/257 [==============================] - 102s 397ms/step - loss: 1.6648 - accuracy: 0.4312 - val_loss: 2.1533 - val_accuracy: 0.2958\n",
            "Epoch 27/40\n",
            "257/257 [==============================] - 101s 393ms/step - loss: 1.6402 - accuracy: 0.4380 - val_loss: 2.1581 - val_accuracy: 0.2938\n",
            "Epoch 28/40\n",
            "257/257 [==============================] - 101s 395ms/step - loss: 1.6288 - accuracy: 0.4412 - val_loss: 2.1867 - val_accuracy: 0.2878\n",
            "Epoch 29/40\n",
            "257/257 [==============================] - 100s 390ms/step - loss: 1.6338 - accuracy: 0.4411 - val_loss: 2.1968 - val_accuracy: 0.2938\n",
            "Epoch 30/40\n",
            "257/257 [==============================] - 99s 386ms/step - loss: 1.5961 - accuracy: 0.4567 - val_loss: 2.2133 - val_accuracy: 0.2878\n",
            "Epoch 31/40\n",
            "257/257 [==============================] - 99s 384ms/step - loss: 1.5782 - accuracy: 0.4629 - val_loss: 2.2233 - val_accuracy: 0.2878\n",
            "Epoch 32/40\n",
            "257/257 [==============================] - 99s 386ms/step - loss: 1.5583 - accuracy: 0.4686 - val_loss: 2.2336 - val_accuracy: 0.2895\n",
            "Epoch 33/40\n",
            "257/257 [==============================] - 100s 390ms/step - loss: 1.5638 - accuracy: 0.4635 - val_loss: 2.2746 - val_accuracy: 0.2886\n",
            "Epoch 34/40\n",
            "257/257 [==============================] - 98s 383ms/step - loss: 1.5460 - accuracy: 0.4744 - val_loss: 2.2678 - val_accuracy: 0.2934\n",
            "Epoch 35/40\n",
            "257/257 [==============================] - 99s 386ms/step - loss: 1.5179 - accuracy: 0.4834 - val_loss: 2.2733 - val_accuracy: 0.2878\n",
            "Epoch 36/40\n",
            "257/257 [==============================] - 99s 386ms/step - loss: 1.5039 - accuracy: 0.4883 - val_loss: 2.3204 - val_accuracy: 0.2837\n",
            "Epoch 37/40\n",
            "257/257 [==============================] - 99s 388ms/step - loss: 1.4820 - accuracy: 0.4975 - val_loss: 2.3134 - val_accuracy: 0.2902\n",
            "Epoch 38/40\n",
            "257/257 [==============================] - 99s 386ms/step - loss: 1.4698 - accuracy: 0.5011 - val_loss: 2.3395 - val_accuracy: 0.2891\n",
            "Epoch 39/40\n",
            "257/257 [==============================] - 100s 389ms/step - loss: 1.4452 - accuracy: 0.5120 - val_loss: 2.3823 - val_accuracy: 0.2828\n",
            "Epoch 40/40\n",
            "257/257 [==============================] - 100s 391ms/step - loss: 1.4325 - accuracy: 0.5155 - val_loss: 2.3999 - val_accuracy: 0.2834\n",
            "80/80 [==============================] - 22s 279ms/step - loss: 2.4070 - accuracy: 0.2835\n",
            "[2.406978130340576, 0.28349998593330383]\n",
            "CBOW_BI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-5svIOHomWE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7e8080e-5ed1-411c-d623-97706f4f8702"
      },
      "source": [
        "model_cbow_rnn = tf.keras.Sequential()\r\n",
        "model_cbow_rnn.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_cbow_rnn.add(tf.keras.layers.SimpleRNN(50))\r\n",
        "model_cbow_rnn.add(tf.keras.layers.Dense(13, activation='softmax'))\r\n",
        "model_cbow_rnn.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy'])\r\n",
        "history_cbow_rnn = model_cbow_rnn.fit_generator(cbow_train_gen,validation_data=cbow_val_gen,validation_steps=int((len(X_val)/batch_size)+1),steps_per_epoch=int((len(X_train)/batch_size)+1),epochs=epochs)\r\n",
        "history = model_cbow_rnn.evaluate(x = vec_gen(w2v_cbow,vocab_cbow,X_test,y_test,batch_size,Max_input_size,Embedding_size),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table[5]=history[1]\r\n",
        "print(\"CBOW_RNN\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "257/257 [==============================] - 85s 330ms/step - loss: 2.2501 - accuracy: 0.2144 - val_loss: 2.1239 - val_accuracy: 0.2360\n",
            "Epoch 2/40\n",
            "257/257 [==============================] - 84s 327ms/step - loss: 2.1019 - accuracy: 0.2549 - val_loss: 2.1109 - val_accuracy: 0.2331\n",
            "Epoch 3/40\n",
            "257/257 [==============================] - 85s 331ms/step - loss: 2.0866 - accuracy: 0.2632 - val_loss: 2.0902 - val_accuracy: 0.2475\n",
            "Epoch 4/40\n",
            "257/257 [==============================] - 83s 325ms/step - loss: 2.0689 - accuracy: 0.2757 - val_loss: 2.0704 - val_accuracy: 0.2765\n",
            "Epoch 5/40\n",
            "257/257 [==============================] - 84s 327ms/step - loss: 2.0510 - accuracy: 0.2832 - val_loss: 2.0759 - val_accuracy: 0.2785\n",
            "Epoch 6/40\n",
            "257/257 [==============================] - 84s 327ms/step - loss: 2.0396 - accuracy: 0.2891 - val_loss: 2.0859 - val_accuracy: 0.2735\n",
            "Epoch 7/40\n",
            "257/257 [==============================] - 84s 328ms/step - loss: 2.0276 - accuracy: 0.2957 - val_loss: 2.0868 - val_accuracy: 0.2691\n",
            "Epoch 8/40\n",
            "257/257 [==============================] - 83s 324ms/step - loss: 2.0170 - accuracy: 0.2982 - val_loss: 2.0915 - val_accuracy: 0.2620\n",
            "Epoch 9/40\n",
            "257/257 [==============================] - 84s 329ms/step - loss: 2.0088 - accuracy: 0.3076 - val_loss: 2.0987 - val_accuracy: 0.2595\n",
            "Epoch 10/40\n",
            "257/257 [==============================] - 83s 326ms/step - loss: 1.9984 - accuracy: 0.3119 - val_loss: 2.1061 - val_accuracy: 0.2585\n",
            "Epoch 11/40\n",
            "257/257 [==============================] - 83s 324ms/step - loss: 1.9860 - accuracy: 0.3189 - val_loss: 2.1136 - val_accuracy: 0.2600\n",
            "Epoch 12/40\n",
            "257/257 [==============================] - 83s 324ms/step - loss: 1.9714 - accuracy: 0.3293 - val_loss: 2.1284 - val_accuracy: 0.2508\n",
            "Epoch 13/40\n",
            "257/257 [==============================] - 84s 328ms/step - loss: 1.9600 - accuracy: 0.3337 - val_loss: 2.1381 - val_accuracy: 0.2491\n",
            "Epoch 14/40\n",
            "257/257 [==============================] - 84s 330ms/step - loss: 1.9472 - accuracy: 0.3394 - val_loss: 2.1411 - val_accuracy: 0.2488\n",
            "Epoch 15/40\n",
            "257/257 [==============================] - 83s 325ms/step - loss: 1.9378 - accuracy: 0.3417 - val_loss: 2.1416 - val_accuracy: 0.2508\n",
            "Epoch 16/40\n",
            "257/257 [==============================] - 84s 328ms/step - loss: 1.9285 - accuracy: 0.3416 - val_loss: 2.1533 - val_accuracy: 0.2509\n",
            "Epoch 17/40\n",
            "257/257 [==============================] - 83s 325ms/step - loss: 1.9243 - accuracy: 0.3436 - val_loss: 2.1494 - val_accuracy: 0.2568\n",
            "Epoch 18/40\n",
            "257/257 [==============================] - 84s 330ms/step - loss: 1.9146 - accuracy: 0.3437 - val_loss: 2.1520 - val_accuracy: 0.2632\n",
            "Epoch 19/40\n",
            "257/257 [==============================] - 83s 325ms/step - loss: 1.9090 - accuracy: 0.3452 - val_loss: 2.1631 - val_accuracy: 0.2602\n",
            "Epoch 20/40\n",
            "257/257 [==============================] - 86s 335ms/step - loss: 1.9047 - accuracy: 0.3493 - val_loss: 2.1751 - val_accuracy: 0.2577\n",
            "Epoch 21/40\n",
            "257/257 [==============================] - 85s 331ms/step - loss: 1.9007 - accuracy: 0.3499 - val_loss: 2.1852 - val_accuracy: 0.2580\n",
            "Epoch 22/40\n",
            "257/257 [==============================] - 85s 331ms/step - loss: 1.8931 - accuracy: 0.3518 - val_loss: 2.1940 - val_accuracy: 0.2568\n",
            "Epoch 23/40\n",
            "257/257 [==============================] - 83s 325ms/step - loss: 1.8827 - accuracy: 0.3564 - val_loss: 2.2078 - val_accuracy: 0.2574\n",
            "Epoch 24/40\n",
            "257/257 [==============================] - 85s 331ms/step - loss: 1.8806 - accuracy: 0.3574 - val_loss: 2.2202 - val_accuracy: 0.2600\n",
            "Epoch 25/40\n",
            "257/257 [==============================] - 85s 332ms/step - loss: 1.8774 - accuracy: 0.3589 - val_loss: 2.2326 - val_accuracy: 0.2518\n",
            "Epoch 26/40\n",
            "257/257 [==============================] - 83s 326ms/step - loss: 1.8816 - accuracy: 0.3580 - val_loss: 2.2221 - val_accuracy: 0.2498\n",
            "Epoch 27/40\n",
            "257/257 [==============================] - 85s 331ms/step - loss: 1.8684 - accuracy: 0.3640 - val_loss: 2.2359 - val_accuracy: 0.2449\n",
            "Epoch 28/40\n",
            "257/257 [==============================] - 86s 336ms/step - loss: 1.8513 - accuracy: 0.3726 - val_loss: 2.2531 - val_accuracy: 0.2369\n",
            "Epoch 29/40\n",
            "257/257 [==============================] - 86s 334ms/step - loss: 1.8423 - accuracy: 0.3785 - val_loss: 2.2615 - val_accuracy: 0.2363\n",
            "Epoch 30/40\n",
            "257/257 [==============================] - 85s 331ms/step - loss: 1.8360 - accuracy: 0.3775 - val_loss: 2.2647 - val_accuracy: 0.2335\n",
            "Epoch 31/40\n",
            "257/257 [==============================] - 86s 337ms/step - loss: 1.8426 - accuracy: 0.3716 - val_loss: 2.2714 - val_accuracy: 0.2288\n",
            "Epoch 32/40\n",
            "257/257 [==============================] - 87s 339ms/step - loss: 1.8573 - accuracy: 0.3676 - val_loss: 2.2731 - val_accuracy: 0.2262\n",
            "Epoch 33/40\n",
            "257/257 [==============================] - 86s 334ms/step - loss: 1.8499 - accuracy: 0.3777 - val_loss: 2.2576 - val_accuracy: 0.2309\n",
            "Epoch 34/40\n",
            "257/257 [==============================] - 87s 340ms/step - loss: 1.8426 - accuracy: 0.3777 - val_loss: 2.2556 - val_accuracy: 0.2349\n",
            "Epoch 35/40\n",
            "257/257 [==============================] - 89s 349ms/step - loss: 1.8232 - accuracy: 0.3827 - val_loss: 2.2755 - val_accuracy: 0.2374\n",
            "Epoch 36/40\n",
            "257/257 [==============================] - 89s 347ms/step - loss: 1.8099 - accuracy: 0.3859 - val_loss: 2.2798 - val_accuracy: 0.2326\n",
            "Epoch 37/40\n",
            "257/257 [==============================] - 87s 339ms/step - loss: 1.8076 - accuracy: 0.3884 - val_loss: 2.2923 - val_accuracy: 0.2340\n",
            "Epoch 38/40\n",
            "257/257 [==============================] - 91s 353ms/step - loss: 1.8070 - accuracy: 0.3863 - val_loss: 2.2928 - val_accuracy: 0.2352\n",
            "Epoch 39/40\n",
            "257/257 [==============================] - 96s 373ms/step - loss: 1.8113 - accuracy: 0.3844 - val_loss: 2.2918 - val_accuracy: 0.2432\n",
            "Epoch 40/40\n",
            "257/257 [==============================] - 94s 368ms/step - loss: 1.8147 - accuracy: 0.3847 - val_loss: 2.2764 - val_accuracy: 0.2460\n",
            "80/80 [==============================] - 22s 278ms/step - loss: 2.3102 - accuracy: 0.2355\n",
            "[2.3101606369018555, 0.23549999296665192]\n",
            "CBOW_RNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GeZYWIEomUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21b77356-4eee-4db1-f28e-3f6395a785f9"
      },
      "source": [
        "model_glove = tf.keras.Sequential()\r\n",
        "model_glove.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_glove.add(tf.keras.layers.LSTM(50))\r\n",
        "model_glove.add(tf.keras.layers.Dense(13, activation='softmax'))\r\n",
        "model_glove.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy'])\r\n",
        "glove_train_gen=glove_gen(vocab_glove,X_train,y_train,batch_size,Max_input_size,Embedding_size)\r\n",
        "glove_val_gen=glove_gen(vocab_glove,X_val,y_val,batch_size,Max_input_size,Embedding_size)\r\n",
        "history_glove_lstm = model_glove.fit_generator(glove_train_gen,validation_data=glove_val_gen,validation_steps=int((len(X_val)/batch_size)+1),steps_per_epoch=int((len(X_train)/batch_size)+1),epochs=epochs)\r\n",
        "history = model_glove.evaluate(x = glove_gen(vocab_glove,X_test,y_test,batch_size,Max_input_size,Embedding_size),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table[6]=history[1]\r\n",
        "print(\"GLOVE_LSTM\")\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "257/257 [==============================] - 17s 59ms/step - loss: 2.2303 - accuracy: 0.2244 - val_loss: 1.9843 - val_accuracy: 0.3057\n",
            "Epoch 2/40\n",
            "257/257 [==============================] - 14s 56ms/step - loss: 1.9681 - accuracy: 0.3176 - val_loss: 1.9079 - val_accuracy: 0.3377\n",
            "Epoch 3/40\n",
            "257/257 [==============================] - 14s 56ms/step - loss: 1.9109 - accuracy: 0.3376 - val_loss: 1.8908 - val_accuracy: 0.3443\n",
            "Epoch 4/40\n",
            "257/257 [==============================] - 14s 55ms/step - loss: 1.8779 - accuracy: 0.3578 - val_loss: 1.8796 - val_accuracy: 0.3471\n",
            "Epoch 5/40\n",
            "257/257 [==============================] - 14s 54ms/step - loss: 1.8583 - accuracy: 0.3676 - val_loss: 1.8787 - val_accuracy: 0.3463\n",
            "Epoch 6/40\n",
            "257/257 [==============================] - 14s 54ms/step - loss: 1.8444 - accuracy: 0.3729 - val_loss: 1.8718 - val_accuracy: 0.3535\n",
            "Epoch 7/40\n",
            "257/257 [==============================] - 14s 56ms/step - loss: 1.8235 - accuracy: 0.3816 - val_loss: 1.8730 - val_accuracy: 0.3546\n",
            "Epoch 8/40\n",
            "257/257 [==============================] - 14s 55ms/step - loss: 1.8037 - accuracy: 0.3895 - val_loss: 1.8746 - val_accuracy: 0.3557\n",
            "Epoch 9/40\n",
            "257/257 [==============================] - 14s 56ms/step - loss: 1.7863 - accuracy: 0.3932 - val_loss: 1.8765 - val_accuracy: 0.3589\n",
            "Epoch 10/40\n",
            "257/257 [==============================] - 14s 54ms/step - loss: 1.7666 - accuracy: 0.4032 - val_loss: 1.8793 - val_accuracy: 0.3577\n",
            "Epoch 11/40\n",
            "257/257 [==============================] - 14s 54ms/step - loss: 1.7450 - accuracy: 0.4112 - val_loss: 1.8927 - val_accuracy: 0.3582\n",
            "Epoch 12/40\n",
            "257/257 [==============================] - 14s 54ms/step - loss: 1.7282 - accuracy: 0.4182 - val_loss: 1.9052 - val_accuracy: 0.3545\n",
            "Epoch 13/40\n",
            "257/257 [==============================] - 14s 55ms/step - loss: 1.7061 - accuracy: 0.4264 - val_loss: 1.9138 - val_accuracy: 0.3517\n",
            "Epoch 14/40\n",
            "257/257 [==============================] - 14s 53ms/step - loss: 1.6855 - accuracy: 0.4335 - val_loss: 1.9273 - val_accuracy: 0.3462\n",
            "Epoch 15/40\n",
            "257/257 [==============================] - 13s 52ms/step - loss: 1.6690 - accuracy: 0.4419 - val_loss: 1.9405 - val_accuracy: 0.3448\n",
            "Epoch 16/40\n",
            "257/257 [==============================] - 14s 53ms/step - loss: 1.6477 - accuracy: 0.4473 - val_loss: 1.9885 - val_accuracy: 0.3338\n",
            "Epoch 17/40\n",
            "257/257 [==============================] - 14s 54ms/step - loss: 1.6335 - accuracy: 0.4521 - val_loss: 1.9925 - val_accuracy: 0.3308\n",
            "Epoch 18/40\n",
            "257/257 [==============================] - 14s 54ms/step - loss: 1.6182 - accuracy: 0.4588 - val_loss: 1.9802 - val_accuracy: 0.3386\n",
            "Epoch 19/40\n",
            "257/257 [==============================] - 14s 54ms/step - loss: 1.6089 - accuracy: 0.4603 - val_loss: 1.9761 - val_accuracy: 0.3331\n",
            "Epoch 20/40\n",
            "257/257 [==============================] - 14s 54ms/step - loss: 1.5904 - accuracy: 0.4689 - val_loss: 2.0070 - val_accuracy: 0.3209\n",
            "Epoch 21/40\n",
            "257/257 [==============================] - 14s 54ms/step - loss: 1.5845 - accuracy: 0.4702 - val_loss: 2.0192 - val_accuracy: 0.3222\n",
            "Epoch 22/40\n",
            "257/257 [==============================] - 14s 55ms/step - loss: 1.5727 - accuracy: 0.4787 - val_loss: 2.0427 - val_accuracy: 0.3178\n",
            "Epoch 23/40\n",
            "257/257 [==============================] - 14s 53ms/step - loss: 1.5759 - accuracy: 0.4741 - val_loss: 2.0433 - val_accuracy: 0.3266\n",
            "Epoch 24/40\n",
            "257/257 [==============================] - 14s 53ms/step - loss: 1.5590 - accuracy: 0.4837 - val_loss: 2.0701 - val_accuracy: 0.3271\n",
            "Epoch 25/40\n",
            "257/257 [==============================] - 14s 54ms/step - loss: 1.5429 - accuracy: 0.4866 - val_loss: 2.0664 - val_accuracy: 0.3280\n",
            "Epoch 26/40\n",
            "257/257 [==============================] - 14s 53ms/step - loss: 1.5213 - accuracy: 0.4956 - val_loss: 2.0884 - val_accuracy: 0.3286\n",
            "Epoch 27/40\n",
            "257/257 [==============================] - 14s 53ms/step - loss: 1.5153 - accuracy: 0.4995 - val_loss: 2.0998 - val_accuracy: 0.3271\n",
            "Epoch 28/40\n",
            "257/257 [==============================] - 14s 54ms/step - loss: 1.5043 - accuracy: 0.4992 - val_loss: 2.1164 - val_accuracy: 0.3198\n",
            "Epoch 29/40\n",
            "257/257 [==============================] - 14s 54ms/step - loss: 1.4816 - accuracy: 0.5068 - val_loss: 2.1302 - val_accuracy: 0.3175\n",
            "Epoch 30/40\n",
            "257/257 [==============================] - 14s 53ms/step - loss: 1.4668 - accuracy: 0.5151 - val_loss: 2.1483 - val_accuracy: 0.3177\n",
            "Epoch 31/40\n",
            "257/257 [==============================] - 14s 54ms/step - loss: 1.4691 - accuracy: 0.5124 - val_loss: 2.1540 - val_accuracy: 0.3195\n",
            "Epoch 32/40\n",
            "257/257 [==============================] - 14s 55ms/step - loss: 1.4728 - accuracy: 0.5132 - val_loss: 2.1585 - val_accuracy: 0.3183\n",
            "Epoch 33/40\n",
            "257/257 [==============================] - 14s 54ms/step - loss: 1.4469 - accuracy: 0.5239 - val_loss: 2.2044 - val_accuracy: 0.3089\n",
            "Epoch 34/40\n",
            "257/257 [==============================] - 14s 53ms/step - loss: 1.4293 - accuracy: 0.5279 - val_loss: 2.2073 - val_accuracy: 0.3185\n",
            "Epoch 35/40\n",
            "257/257 [==============================] - 14s 53ms/step - loss: 1.4211 - accuracy: 0.5279 - val_loss: 2.2466 - val_accuracy: 0.3088\n",
            "Epoch 36/40\n",
            "257/257 [==============================] - 14s 54ms/step - loss: 1.4051 - accuracy: 0.5353 - val_loss: 2.2439 - val_accuracy: 0.3057\n",
            "Epoch 37/40\n",
            "257/257 [==============================] - 14s 54ms/step - loss: 1.4146 - accuracy: 0.5375 - val_loss: 2.2472 - val_accuracy: 0.3051\n",
            "Epoch 38/40\n",
            "257/257 [==============================] - 14s 54ms/step - loss: 1.4116 - accuracy: 0.5338 - val_loss: 2.2431 - val_accuracy: 0.3098\n",
            "Epoch 39/40\n",
            "257/257 [==============================] - 14s 54ms/step - loss: 1.4191 - accuracy: 0.5347 - val_loss: 2.2392 - val_accuracy: 0.3106\n",
            "Epoch 40/40\n",
            "257/257 [==============================] - 14s 54ms/step - loss: 1.4005 - accuracy: 0.5409 - val_loss: 2.2709 - val_accuracy: 0.3094\n",
            "80/80 [==============================] - 2s 27ms/step - loss: 2.2988 - accuracy: 0.3086\n",
            "[2.298797845840454, 0.3086250126361847]\n",
            "GLOVE_LSTM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gay5RdSomRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8da1ad2-f3a1-4d35-e23b-7a707c942eb0"
      },
      "source": [
        "model_glove_rnn = tf.keras.Sequential()\r\n",
        "model_glove_rnn.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_glove_rnn.add(tf.keras.layers.SimpleRNN(50))\r\n",
        "model_glove_rnn.add(tf.keras.layers.Dense(13, activation='softmax'))\r\n",
        "model_glove_rnn.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy'])\r\n",
        "history_glove_rnn = model_glove_rnn.fit_generator(glove_train_gen,validation_data=glove_val_gen,validation_steps=int((len(X_val)/batch_size)+1),steps_per_epoch=int((len(X_train)/batch_size)+1),epochs=epochs)\r\n",
        "history = model_glove_rnn.evaluate(x = glove_gen(vocab_glove,X_test,y_test,batch_size,Max_input_size,Embedding_size),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table[8]=history[1]\r\n",
        "print(\"GLOVE_RNN\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "257/257 [==============================] - 7s 26ms/step - loss: 2.2235 - accuracy: 0.1948 - val_loss: 2.1395 - val_accuracy: 0.2146\n",
            "Epoch 2/40\n",
            "257/257 [==============================] - 6s 25ms/step - loss: 2.1516 - accuracy: 0.2178 - val_loss: 2.1370 - val_accuracy: 0.2191\n",
            "Epoch 3/40\n",
            "257/257 [==============================] - 6s 25ms/step - loss: 2.1474 - accuracy: 0.2301 - val_loss: 2.1259 - val_accuracy: 0.2462\n",
            "Epoch 4/40\n",
            "257/257 [==============================] - 6s 25ms/step - loss: 2.1404 - accuracy: 0.2401 - val_loss: 2.1419 - val_accuracy: 0.2171\n",
            "Epoch 5/40\n",
            "257/257 [==============================] - 6s 25ms/step - loss: 2.1566 - accuracy: 0.2172 - val_loss: 2.1385 - val_accuracy: 0.2175\n",
            "Epoch 6/40\n",
            "257/257 [==============================] - 6s 25ms/step - loss: 2.1540 - accuracy: 0.2157 - val_loss: 2.1402 - val_accuracy: 0.2174\n",
            "Epoch 7/40\n",
            "257/257 [==============================] - 6s 25ms/step - loss: 2.1540 - accuracy: 0.2170 - val_loss: 2.1392 - val_accuracy: 0.2175\n",
            "Epoch 8/40\n",
            "257/257 [==============================] - 6s 24ms/step - loss: 2.1525 - accuracy: 0.2167 - val_loss: 2.1401 - val_accuracy: 0.2178\n",
            "Epoch 9/40\n",
            "257/257 [==============================] - 6s 25ms/step - loss: 2.1419 - accuracy: 0.2197 - val_loss: 2.1243 - val_accuracy: 0.2168\n",
            "Epoch 10/40\n",
            "257/257 [==============================] - 6s 25ms/step - loss: 2.1288 - accuracy: 0.2276 - val_loss: 2.0928 - val_accuracy: 0.2375\n",
            "Epoch 11/40\n",
            "257/257 [==============================] - 6s 25ms/step - loss: 2.0989 - accuracy: 0.2387 - val_loss: 2.1022 - val_accuracy: 0.2349\n",
            "Epoch 12/40\n",
            "257/257 [==============================] - 6s 25ms/step - loss: 2.1168 - accuracy: 0.2251 - val_loss: 2.1236 - val_accuracy: 0.2271\n",
            "Epoch 13/40\n",
            "257/257 [==============================] - 6s 25ms/step - loss: 2.1268 - accuracy: 0.2209 - val_loss: 2.1203 - val_accuracy: 0.2248\n",
            "Epoch 14/40\n",
            "257/257 [==============================] - 6s 25ms/step - loss: 2.1293 - accuracy: 0.2183 - val_loss: 2.1190 - val_accuracy: 0.2277\n",
            "Epoch 15/40\n",
            "257/257 [==============================] - 6s 25ms/step - loss: 2.1313 - accuracy: 0.2200 - val_loss: 2.1478 - val_accuracy: 0.2160\n",
            "Epoch 16/40\n",
            "257/257 [==============================] - 7s 25ms/step - loss: 2.1330 - accuracy: 0.2207 - val_loss: 2.1162 - val_accuracy: 0.2294\n",
            "Epoch 17/40\n",
            "257/257 [==============================] - 6s 25ms/step - loss: 2.1147 - accuracy: 0.2252 - val_loss: 2.1352 - val_accuracy: 0.2168\n",
            "Epoch 18/40\n",
            "257/257 [==============================] - 7s 25ms/step - loss: 2.1383 - accuracy: 0.2147 - val_loss: 2.1390 - val_accuracy: 0.2171\n",
            "Epoch 19/40\n",
            "257/257 [==============================] - 7s 26ms/step - loss: 2.1441 - accuracy: 0.2155 - val_loss: 2.1421 - val_accuracy: 0.2177\n",
            "Epoch 20/40\n",
            "257/257 [==============================] - 6s 25ms/step - loss: 2.1489 - accuracy: 0.2140 - val_loss: 2.1407 - val_accuracy: 0.2188\n",
            "Epoch 21/40\n",
            "257/257 [==============================] - 7s 26ms/step - loss: 2.1500 - accuracy: 0.2130 - val_loss: 2.1407 - val_accuracy: 0.2171\n",
            "Epoch 22/40\n",
            "257/257 [==============================] - 6s 25ms/step - loss: 2.1490 - accuracy: 0.2132 - val_loss: 2.1413 - val_accuracy: 0.2180\n",
            "Epoch 23/40\n",
            "257/257 [==============================] - 6s 25ms/step - loss: 2.1485 - accuracy: 0.2164 - val_loss: 2.1405 - val_accuracy: 0.2171\n",
            "Epoch 24/40\n",
            "257/257 [==============================] - 6s 25ms/step - loss: 2.1435 - accuracy: 0.2166 - val_loss: 2.1413 - val_accuracy: 0.2180\n",
            "Epoch 25/40\n",
            "257/257 [==============================] - 7s 25ms/step - loss: 2.1454 - accuracy: 0.2180 - val_loss: 2.1407 - val_accuracy: 0.2186\n",
            "Epoch 26/40\n",
            "257/257 [==============================] - 6s 25ms/step - loss: 2.1436 - accuracy: 0.2212 - val_loss: 2.1392 - val_accuracy: 0.2217\n",
            "Epoch 27/40\n",
            "257/257 [==============================] - 6s 25ms/step - loss: 2.1433 - accuracy: 0.2253 - val_loss: 2.1433 - val_accuracy: 0.2211\n",
            "Epoch 28/40\n",
            "257/257 [==============================] - 7s 25ms/step - loss: 2.1372 - accuracy: 0.2227 - val_loss: 2.1480 - val_accuracy: 0.2234\n",
            "Epoch 29/40\n",
            "257/257 [==============================] - 6s 24ms/step - loss: 2.1371 - accuracy: 0.2233 - val_loss: 2.1522 - val_accuracy: 0.2157\n",
            "Epoch 30/40\n",
            "257/257 [==============================] - 7s 25ms/step - loss: 2.1375 - accuracy: 0.2275 - val_loss: 2.1541 - val_accuracy: 0.2194\n",
            "Epoch 31/40\n",
            "257/257 [==============================] - 7s 26ms/step - loss: 2.1354 - accuracy: 0.2318 - val_loss: 2.1541 - val_accuracy: 0.2237\n",
            "Epoch 32/40\n",
            "257/257 [==============================] - 7s 26ms/step - loss: 2.1303 - accuracy: 0.2359 - val_loss: 2.1580 - val_accuracy: 0.2238\n",
            "Epoch 33/40\n",
            "257/257 [==============================] - 7s 26ms/step - loss: 2.1275 - accuracy: 0.2404 - val_loss: 2.1556 - val_accuracy: 0.2212\n",
            "Epoch 34/40\n",
            "257/257 [==============================] - 6s 25ms/step - loss: 2.1209 - accuracy: 0.2461 - val_loss: 2.1591 - val_accuracy: 0.2211\n",
            "Epoch 35/40\n",
            "257/257 [==============================] - 7s 25ms/step - loss: 2.1141 - accuracy: 0.2480 - val_loss: 2.1579 - val_accuracy: 0.2086\n",
            "Epoch 36/40\n",
            "257/257 [==============================] - 6s 25ms/step - loss: 2.1091 - accuracy: 0.2506 - val_loss: 2.1617 - val_accuracy: 0.2095\n",
            "Epoch 37/40\n",
            "257/257 [==============================] - 7s 25ms/step - loss: 2.0997 - accuracy: 0.2570 - val_loss: 2.1659 - val_accuracy: 0.2071\n",
            "Epoch 38/40\n",
            "257/257 [==============================] - 7s 26ms/step - loss: 2.0943 - accuracy: 0.2620 - val_loss: 2.1639 - val_accuracy: 0.2114\n",
            "Epoch 39/40\n",
            "257/257 [==============================] - 7s 25ms/step - loss: 2.0836 - accuracy: 0.2693 - val_loss: 2.1731 - val_accuracy: 0.2092\n",
            "Epoch 40/40\n",
            "257/257 [==============================] - 7s 26ms/step - loss: 2.0810 - accuracy: 0.2696 - val_loss: 2.1814 - val_accuracy: 0.2058\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 2.1988 - accuracy: 0.2052\n",
            "[2.1988351345062256, 0.20524999499320984]\n",
            "GLOVE_RNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPXr5_utxIvm",
        "outputId": "234e6fbc-7417-4cbb-8348-dfd04ff13de8"
      },
      "source": [
        "model_glove_bi = tf.keras.Sequential()\n",
        "model_glove_bi.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\n",
        "model_glove_bi.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50),merge_mode='concat'))\n",
        "model_glove_bi.add(tf.keras.layers.Dense(13, activation='softmax'))\n",
        "model_glove_bi.compile(loss='categorical_crossentropy',optimizer='adam', \n",
        "                           metrics=['accuracy'])\n",
        "history_glove_bi = model_glove_bi.fit_generator(glove_train_gen,validation_data=glove_val_gen,validation_steps=int((len(X_val)/batch_size)+1),steps_per_epoch=int((len(X_train)/batch_size)+1),epochs=epochs)\n",
        "history = model_glove_bi.evaluate(x = glove_gen(vocab_glove,X_test,y_test,batch_size,Max_input_size,Embedding_size),steps=int(len(y_test)/batch_size))\n",
        "print(history)\n",
        "\n",
        "result_table[7]=history[1]\n",
        "print(\"GLOVE_BI\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "257/257 [==============================] - 28s 97ms/step - loss: 2.1339 - accuracy: 0.2789 - val_loss: 1.9030 - val_accuracy: 0.3442\n",
            "Epoch 2/40\n",
            "257/257 [==============================] - 24s 94ms/step - loss: 1.8888 - accuracy: 0.3522 - val_loss: 1.8603 - val_accuracy: 0.3555\n",
            "Epoch 3/40\n",
            "257/257 [==============================] - 24s 94ms/step - loss: 1.8410 - accuracy: 0.3729 - val_loss: 1.8443 - val_accuracy: 0.3605\n",
            "Epoch 4/40\n",
            "257/257 [==============================] - 24s 93ms/step - loss: 1.8092 - accuracy: 0.3802 - val_loss: 1.8384 - val_accuracy: 0.3675\n",
            "Epoch 5/40\n",
            "257/257 [==============================] - 24s 92ms/step - loss: 1.7730 - accuracy: 0.3918 - val_loss: 1.8382 - val_accuracy: 0.3695\n",
            "Epoch 6/40\n",
            "257/257 [==============================] - 24s 93ms/step - loss: 1.7480 - accuracy: 0.4048 - val_loss: 1.8430 - val_accuracy: 0.3706\n",
            "Epoch 7/40\n",
            "257/257 [==============================] - 24s 94ms/step - loss: 1.7174 - accuracy: 0.4170 - val_loss: 1.8563 - val_accuracy: 0.3683\n",
            "Epoch 8/40\n",
            "257/257 [==============================] - 24s 95ms/step - loss: 1.6866 - accuracy: 0.4268 - val_loss: 1.8744 - val_accuracy: 0.3642\n",
            "Epoch 9/40\n",
            "257/257 [==============================] - 24s 93ms/step - loss: 1.6540 - accuracy: 0.4362 - val_loss: 1.8894 - val_accuracy: 0.3578\n",
            "Epoch 10/40\n",
            "257/257 [==============================] - 24s 93ms/step - loss: 1.6217 - accuracy: 0.4476 - val_loss: 1.9024 - val_accuracy: 0.3542\n",
            "Epoch 11/40\n",
            "257/257 [==============================] - 24s 95ms/step - loss: 1.5901 - accuracy: 0.4583 - val_loss: 1.9352 - val_accuracy: 0.3512\n",
            "Epoch 12/40\n",
            "257/257 [==============================] - 24s 94ms/step - loss: 1.5566 - accuracy: 0.4722 - val_loss: 1.9416 - val_accuracy: 0.3418\n",
            "Epoch 13/40\n",
            "257/257 [==============================] - 25s 95ms/step - loss: 1.5162 - accuracy: 0.4892 - val_loss: 1.9573 - val_accuracy: 0.3369\n",
            "Epoch 14/40\n",
            "257/257 [==============================] - 24s 94ms/step - loss: 1.4852 - accuracy: 0.5027 - val_loss: 2.0004 - val_accuracy: 0.3338\n",
            "Epoch 15/40\n",
            "257/257 [==============================] - 24s 93ms/step - loss: 1.4452 - accuracy: 0.5129 - val_loss: 2.0238 - val_accuracy: 0.3282\n",
            "Epoch 16/40\n",
            "257/257 [==============================] - 24s 94ms/step - loss: 1.4121 - accuracy: 0.5268 - val_loss: 2.0709 - val_accuracy: 0.3217\n",
            "Epoch 17/40\n",
            "257/257 [==============================] - 24s 94ms/step - loss: 1.3795 - accuracy: 0.5411 - val_loss: 2.1163 - val_accuracy: 0.3178\n",
            "Epoch 18/40\n",
            "257/257 [==============================] - 24s 93ms/step - loss: 1.3490 - accuracy: 0.5483 - val_loss: 2.1347 - val_accuracy: 0.3191\n",
            "Epoch 19/40\n",
            "257/257 [==============================] - 24s 94ms/step - loss: 1.3204 - accuracy: 0.5617 - val_loss: 2.1635 - val_accuracy: 0.3175\n",
            "Epoch 20/40\n",
            "257/257 [==============================] - 24s 94ms/step - loss: 1.2883 - accuracy: 0.5726 - val_loss: 2.1977 - val_accuracy: 0.3169\n",
            "Epoch 21/40\n",
            "257/257 [==============================] - 24s 94ms/step - loss: 1.2589 - accuracy: 0.5875 - val_loss: 2.2353 - val_accuracy: 0.3089\n",
            "Epoch 22/40\n",
            "257/257 [==============================] - 24s 95ms/step - loss: 1.2331 - accuracy: 0.5960 - val_loss: 2.2705 - val_accuracy: 0.3114\n",
            "Epoch 23/40\n",
            "257/257 [==============================] - 24s 94ms/step - loss: 1.2009 - accuracy: 0.6047 - val_loss: 2.3290 - val_accuracy: 0.3095\n",
            "Epoch 24/40\n",
            "257/257 [==============================] - 25s 96ms/step - loss: 1.1673 - accuracy: 0.6172 - val_loss: 2.3542 - val_accuracy: 0.3100\n",
            "Epoch 25/40\n",
            "257/257 [==============================] - 25s 96ms/step - loss: 1.1557 - accuracy: 0.6199 - val_loss: 2.3950 - val_accuracy: 0.2985\n",
            "Epoch 26/40\n",
            "257/257 [==============================] - 25s 96ms/step - loss: 1.1299 - accuracy: 0.6287 - val_loss: 2.4265 - val_accuracy: 0.3005\n",
            "Epoch 27/40\n",
            "257/257 [==============================] - 25s 97ms/step - loss: 1.1013 - accuracy: 0.6373 - val_loss: 2.4598 - val_accuracy: 0.2982\n",
            "Epoch 28/40\n",
            "257/257 [==============================] - 24s 94ms/step - loss: 1.0876 - accuracy: 0.6417 - val_loss: 2.4949 - val_accuracy: 0.2988\n",
            "Epoch 29/40\n",
            "257/257 [==============================] - 24s 94ms/step - loss: 1.0583 - accuracy: 0.6545 - val_loss: 2.5459 - val_accuracy: 0.2958\n",
            "Epoch 30/40\n",
            "257/257 [==============================] - 24s 95ms/step - loss: 1.0268 - accuracy: 0.6679 - val_loss: 2.6018 - val_accuracy: 0.2937\n",
            "Epoch 31/40\n",
            "257/257 [==============================] - 25s 98ms/step - loss: 1.0098 - accuracy: 0.6742 - val_loss: 2.6577 - val_accuracy: 0.2968\n",
            "Epoch 32/40\n",
            "257/257 [==============================] - 26s 100ms/step - loss: 0.9924 - accuracy: 0.6813 - val_loss: 2.7173 - val_accuracy: 0.2955\n",
            "Epoch 33/40\n",
            "257/257 [==============================] - 25s 99ms/step - loss: 0.9627 - accuracy: 0.6893 - val_loss: 2.7586 - val_accuracy: 0.2942\n",
            "Epoch 34/40\n",
            "257/257 [==============================] - 26s 100ms/step - loss: 0.9350 - accuracy: 0.6975 - val_loss: 2.7798 - val_accuracy: 0.2966\n",
            "Epoch 35/40\n",
            "257/257 [==============================] - 25s 98ms/step - loss: 0.9518 - accuracy: 0.6889 - val_loss: 2.8568 - val_accuracy: 0.2946\n",
            "Epoch 36/40\n",
            "257/257 [==============================] - 25s 98ms/step - loss: 0.9192 - accuracy: 0.7016 - val_loss: 2.8965 - val_accuracy: 0.2851\n",
            "Epoch 37/40\n",
            "257/257 [==============================] - 26s 100ms/step - loss: 0.9804 - accuracy: 0.6775 - val_loss: 2.8770 - val_accuracy: 0.2905\n",
            "Epoch 38/40\n",
            "257/257 [==============================] - 26s 100ms/step - loss: 0.8906 - accuracy: 0.7115 - val_loss: 2.9332 - val_accuracy: 0.2892\n",
            "Epoch 39/40\n",
            "257/257 [==============================] - 25s 98ms/step - loss: 0.8588 - accuracy: 0.7262 - val_loss: 3.0070 - val_accuracy: 0.2954\n",
            "Epoch 40/40\n",
            "257/257 [==============================] - 25s 96ms/step - loss: 0.8423 - accuracy: 0.7354 - val_loss: 3.0440 - val_accuracy: 0.2908\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 3.0725 - accuracy: 0.2834\n",
            "[3.0724921226501465, 0.28337499499320984]\n",
            "GLOVE_BI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pTYtBY-omOB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63b62ab7-9aff-43e9-f4d9-4f333a59633f"
      },
      "source": [
        "print(\"\\tLstm\\t\\t\\tBiLstm\\t\\t\\tRnn\")\r\n",
        "print(\"sg\",result_table[:3])\r\n",
        "print(\"cbow\",result_table[3:6])\r\n",
        "print(\"glove\",result_table[6:9])\r\n",
        "# print(history_sg_bi.history)\r\n",
        "# plt.title(\"Skip-Gram + Bi-LSTM accuracy, loss vs epochs Graph\")\r\n",
        "# plt.plot(history_sg_bi.history['loss'],c='b',label='loss')\r\n",
        "# plt.plot(history_sg_bi.history['accuracy'],c='r',label='accuracy')\r\n",
        "# plt.xlabel('epochs')\r\n",
        "# plt.legend()\r\n",
        "# # plt.yticks()\r\n",
        "# plt.show()\r\n",
        "# plt.title(\"GloVe + Bi-LSTM accuracy, loss vs epochs Graph\")\r\n",
        "# plt.plot(history_glove_bi.history['loss'],c='b',label='loss')\r\n",
        "# plt.plot(history_glove_bi.history['accuracy'],c='r',label='accuracy')\r\n",
        "# plt.xlabel('epochs')\r\n",
        "# plt.legend()\r\n",
        "# # plt.yticks()\r\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tLstm\t\t\tBiLstm\t\t\tRnn\n",
            "sg [0.3062500059604645, 0.2771250009536743, 0.23925000429153442]\n",
            "cbow [0.30524998903274536, 0.28349998593330383, 0.23549999296665192]\n",
            "glove [0.3086250126361847, 0.28337499499320984, 0.20524999499320984]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSSVKhXQomLY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}