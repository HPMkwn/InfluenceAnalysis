{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataPreprocess.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "OWyeiHlD2E6e",
        "2b-zUGCKE64a",
        "ifrEyo6lEtPm",
        "_ZEkjcA8Q0Os",
        "UATi1JgZc-FB"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harrymkwn/InfluenceAnalysis/blob/master/Processing_CrowdFlower_using_our_method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWyeiHlD2E6e"
      },
      "source": [
        "#Initialization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0gNX0av1Y0S"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import string\n",
        "\n",
        "from sklearn.utils import shuffle \n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMsIIWh-8qU5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5c73122-9b88-4385-fb57-e38812983e7f"
      },
      "source": [
        "!pip install emot\n",
        "from emot.emo_unicode import UNICODE_EMO, EMOTICONS"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting emot\n",
            "  Downloading https://files.pythonhosted.org/packages/49/07/20001ade19873de611b7b66a4d5e5aabbf190d65abea337d5deeaa2bc3de/emot-2.1-py3-none-any.whl\n",
            "Installing collected packages: emot\n",
            "Successfully installed emot-2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHSD9B6qMrvZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32f591e0-ad6f-494b-efc3-95a48ec8f174"
      },
      "source": [
        "from google.colab import  drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIk4mbPPjQ3a"
      },
      "source": [
        "pd.set_option('display.max_colwidth',1000)\n",
        "pd.set_option('display.max_rows',1000)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNG1AJUaE1U-"
      },
      "source": [
        "#Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOgwP_n-MnYt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c1cd5a6f-d080-4c25-e469-9a6c677073fe"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/InfluenceAnalysis/crowdFlower/crowdFlower.csv')\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>empty</td>\n",
              "      <td>@tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sadness</td>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin on your call...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sadness</td>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@dannycastillo We want to trade with someone who has Houston tickets, but no one will.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      emotion                                                                                        tweets\n",
              "0       empty  @tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[\n",
              "1     sadness                                  Layin n bed with a headache  ughhhh...waitin on your call...\n",
              "2     sadness                                                           Funeral ceremony...gloomy friday...\n",
              "3  enthusiasm                                                          wants to hang out with friends SOON!\n",
              "4     neutral        @dannycastillo We want to trade with someone who has Houston tickets, but no one will."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl_P-ZqMAHN_",
        "outputId": "11035071-9941-48c9-8d64-6b8411ab240e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df['emotion'].value_counts()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral       8638\n",
              "worry         8459\n",
              "happiness     5209\n",
              "sadness       5165\n",
              "love          3842\n",
              "surprise      2187\n",
              "fun           1776\n",
              "relief        1526\n",
              "hate          1323\n",
              "empty          827\n",
              "enthusiasm     759\n",
              "boredom        179\n",
              "anger          110\n",
              "Name: emotion, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b-zUGCKE64a"
      },
      "source": [
        "#Methods to convert Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btJO2NxvO4oj"
      },
      "source": [
        "def is_camel_case(s):\n",
        "    return s != s.lower() and s != s.upper() and (\"_\" and \" \") not in s"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwssN1N2Cymr"
      },
      "source": [
        "def camel_case_split(identifier):\n",
        "    matches = re.finditer('.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)', identifier)\n",
        "    return [m.group(0) for m in matches]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ8TclIe13ZO"
      },
      "source": [
        "def convert_emojis(tweet):\n",
        "  for emot in UNICODE_EMO:\n",
        "    # print(\"_\".join(UNICODE_EMO[emot].replace(\",\",\"\").replace(\":\",\"\").split()))\n",
        "    tweet = tweet.replace(emot, \" sbfs\".join(UNICODE_EMO[emot].replace(\",\",\"\").replace(\":\",\"\").split()))\n",
        "  \n",
        "  return tweet\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULaOwz-k_M1A"
      },
      "source": [
        " def convert_emoticons(tweet):\n",
        "  tweet = tweet\n",
        "  for emot in EMOTICONS:\n",
        "      tweet = re.sub(u'('+emot+')', \" \".join(EMOTICONS[emot].replace(\",\",\"\").split()), tweet)\n",
        "  return tweet"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulCl6iO4fuF2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7815418b-fbc1-45bf-c1ac-a749e2dffc3b"
      },
      "source": [
        "print(convert_emoticons(convert_emojis((\":'‑) :') 🙂 😊 😀 😁 \"))))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tears of happiness Tears of happiness slightly_smiling_face smiling_face_with_smiling_eyes grinning_face grinning_face_with_smiling_eyes \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJJJj4Rx_KCO"
      },
      "source": [
        "def clean_hashtags(tweet):\n",
        "  words_in_tweet = tweet.split(\" \")\n",
        "  temp = []\n",
        "  for i in words_in_tweet:\n",
        "    if \"#\" in i:\n",
        "      i = i.replace(\"#\",\"\")\n",
        "      if \"_\" in i:\n",
        "        i = i.replace(\"_\",\" \")\n",
        "        temp.append(i)\n",
        "      elif is_camel_case(i):\n",
        "        # print(\"camel case block\")\n",
        "        temp.append(\" \".join(camel_case_split(i)))\n",
        "      else:\n",
        "        temp.append(i)\n",
        "    else:\n",
        "      temp.append(i)\n",
        "  \n",
        "  return \" \".join(temp)\n",
        "\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXmWVMSPW8sL"
      },
      "source": [
        "def clean_mentions(tweet):\n",
        "    tweet = re.sub(r\"@[A-Za-z0-9_]+\",\"\", tweet)\n",
        "    return tweet"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqFtfhy8EwG_"
      },
      "source": [
        "def clean(tweet): \n",
        "            \n",
        "    # Special characters\n",
        "    tweet = re.sub(r\"\\x89Û_\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89ÛÒ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89ÛÓ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89ÛÏWhen\", \"When\", tweet)\n",
        "    tweet = re.sub(r\"\\x89ÛÏ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"China\\x89Ûªs\", \"China's\", tweet)\n",
        "    tweet = re.sub(r\"let\\x89Ûªs\", \"let's\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Û÷\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Ûª\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Û\\x9d\", \"\", tweet)\n",
        "    tweet = re.sub(r\"å_\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Û¢\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Û¢åÊ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"fromåÊwounds\", \"from wounds\", tweet)\n",
        "    tweet = re.sub(r\"åÊ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"åÈ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"JapÌ_n\", \"Japan\", tweet)    \n",
        "    tweet = re.sub(r\"Ì©\", \"e\", tweet)\n",
        "    tweet = re.sub(r\"å¨\", \"\", tweet)\n",
        "    tweet = re.sub(r\"SuruÌ¤\", \"Suruc\", tweet)\n",
        "    tweet = re.sub(r\"åÇ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"å£3million\", \"3 million\", tweet)\n",
        "    tweet = re.sub(r\"åÀ\", \"\", tweet)\n",
        "    \n",
        "    # Contractions\n",
        "    tweet = re.sub(r\"he's\", \"he is\", tweet)\n",
        "    tweet = re.sub(r\"there's\", \"there is\", tweet)\n",
        "    tweet = re.sub(r\"We're\", \"We are\", tweet)\n",
        "    tweet = re.sub(r\"That's\", \"That is\", tweet)\n",
        "    tweet = re.sub(r\"won't\", \"will not\", tweet)\n",
        "    tweet = re.sub(r\"they're\", \"they are\", tweet)\n",
        "    tweet = re.sub(r\"Can't\", \"Cannot\", tweet)\n",
        "    tweet = re.sub(r\"wasn't\", \"was not\", tweet)\n",
        "    tweet = re.sub(r\"don\\x89Ûªt\", \"do not\", tweet)\n",
        "    tweet = re.sub(r\"aren't\", \"are not\", tweet)\n",
        "    tweet = re.sub(r\"isn't\", \"is not\", tweet)\n",
        "    tweet = re.sub(r\"What's\", \"What is\", tweet)\n",
        "    tweet = re.sub(r\"haven't\", \"have not\", tweet)\n",
        "    tweet = re.sub(r\"hasn't\", \"has not\", tweet)\n",
        "    tweet = re.sub(r\"There's\", \"There is\", tweet)\n",
        "    tweet = re.sub(r\"He's\", \"He is\", tweet)\n",
        "    tweet = re.sub(r\"It's\", \"It is\", tweet)\n",
        "    tweet = re.sub(r\"You're\", \"You are\", tweet)\n",
        "    tweet = re.sub(r\"I'M\", \"I am\", tweet)\n",
        "    tweet = re.sub(r\"shouldn't\", \"should not\", tweet)\n",
        "    tweet = re.sub(r\"wouldn't\", \"would not\", tweet)\n",
        "    tweet = re.sub(r\"i'm\", \"I am\", tweet)\n",
        "    tweet = re.sub(r\"I\\x89Ûªm\", \"I am\", tweet)\n",
        "    tweet = re.sub(r\"I'm\", \"I am\", tweet)\n",
        "    tweet = re.sub(r\"Isn't\", \"is not\", tweet)\n",
        "    tweet = re.sub(r\"Here's\", \"Here is\", tweet)\n",
        "    tweet = re.sub(r\"you've\", \"you have\", tweet)\n",
        "    tweet = re.sub(r\"you\\x89Ûªve\", \"you have\", tweet)\n",
        "    tweet = re.sub(r\"we're\", \"we are\", tweet)\n",
        "    tweet = re.sub(r\"what's\", \"what is\", tweet)\n",
        "    tweet = re.sub(r\"couldn't\", \"could not\", tweet)\n",
        "    tweet = re.sub(r\"we've\", \"we have\", tweet)\n",
        "    tweet = re.sub(r\"it\\x89Ûªs\", \"it is\", tweet)\n",
        "    tweet = re.sub(r\"doesn\\x89Ûªt\", \"does not\", tweet)\n",
        "    tweet = re.sub(r\"It\\x89Ûªs\", \"It is\", tweet)\n",
        "    tweet = re.sub(r\"Here\\x89Ûªs\", \"Here is\", tweet)\n",
        "    tweet = re.sub(r\"who's\", \"who is\", tweet)\n",
        "    tweet = re.sub(r\"I\\x89Ûªve\", \"I have\", tweet)\n",
        "    tweet = re.sub(r\"y'all\", \"you all\", tweet)\n",
        "    tweet = re.sub(r\"can\\x89Ûªt\", \"cannot\", tweet)\n",
        "    tweet = re.sub(r\"would've\", \"would have\", tweet)\n",
        "    tweet = re.sub(r\"it'll\", \"it will\", tweet)\n",
        "    tweet = re.sub(r\"we'll\", \"we will\", tweet)\n",
        "    tweet = re.sub(r\"wouldn\\x89Ûªt\", \"would not\", tweet)\n",
        "    tweet = re.sub(r\"We've\", \"We have\", tweet)\n",
        "    tweet = re.sub(r\"he'll\", \"he will\", tweet)\n",
        "    tweet = re.sub(r\"Y'all\", \"You all\", tweet)\n",
        "    tweet = re.sub(r\"Weren't\", \"Were not\", tweet)\n",
        "    tweet = re.sub(r\"Didn't\", \"Did not\", tweet)\n",
        "    tweet = re.sub(r\"they'll\", \"they will\", tweet)\n",
        "    tweet = re.sub(r\"they'd\", \"they would\", tweet)\n",
        "    tweet = re.sub(r\"DON'T\", \"DO NOT\", tweet)\n",
        "    tweet = re.sub(r\"That\\x89Ûªs\", \"That is\", tweet)\n",
        "    tweet = re.sub(r\"they've\", \"they have\", tweet)\n",
        "    tweet = re.sub(r\"i'd\", \"I would\", tweet)\n",
        "    tweet = re.sub(r\"should've\", \"should have\", tweet)\n",
        "    tweet = re.sub(r\"You\\x89Ûªre\", \"You are\", tweet)\n",
        "    tweet = re.sub(r\"where's\", \"where is\", tweet)\n",
        "    tweet = re.sub(r\"Don\\x89Ûªt\", \"Do not\", tweet)\n",
        "    tweet = re.sub(r\"we'd\", \"we would\", tweet)\n",
        "    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n",
        "    tweet = re.sub(r\"weren't\", \"were not\", tweet)\n",
        "    tweet = re.sub(r\"They're\", \"They are\", tweet)\n",
        "    tweet = re.sub(r\"Can\\x89Ûªt\", \"Cannot\", tweet)\n",
        "    tweet = re.sub(r\"you\\x89Ûªll\", \"you will\", tweet)\n",
        "    tweet = re.sub(r\"I\\x89Ûªd\", \"I would\", tweet)\n",
        "    tweet = re.sub(r\"let's\", \"let us\", tweet)\n",
        "    tweet = re.sub(r\"it's\", \"it is\", tweet)\n",
        "    tweet = re.sub(r\"can't\", \"cannot\", tweet)\n",
        "    tweet = re.sub(r\"don't\", \"do not\", tweet)\n",
        "    tweet = re.sub(r\"you're\", \"you are\", tweet)\n",
        "    tweet = re.sub(r\"i've\", \"I have\", tweet)\n",
        "    tweet = re.sub(r\"that's\", \"that is\", tweet)\n",
        "    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n",
        "    tweet = re.sub(r\"doesn't\", \"does not\", tweet)\n",
        "    tweet = re.sub(r\"i'd\", \"I would\", tweet)\n",
        "    tweet = re.sub(r\"didn't\", \"did not\", tweet)\n",
        "    tweet = re.sub(r\"ain't\", \"am not\", tweet)\n",
        "    tweet = re.sub(r\"you'll\", \"you will\", tweet)\n",
        "    tweet = re.sub(r\"I've\", \"I have\", tweet)\n",
        "    tweet = re.sub(r\"Don't\", \"do not\", tweet)\n",
        "    tweet = re.sub(r\"I'll\", \"I will\", tweet)\n",
        "    tweet = re.sub(r\"I'd\", \"I would\", tweet)\n",
        "    tweet = re.sub(r\"Let's\", \"Let us\", tweet)\n",
        "    tweet = re.sub(r\"you'd\", \"You would\", tweet)\n",
        "    tweet = re.sub(r\"It's\", \"It is\", tweet)\n",
        "    tweet = re.sub(r\"Ain't\", \"am not\", tweet)\n",
        "    tweet = re.sub(r\"Haven't\", \"Have not\", tweet)\n",
        "    tweet = re.sub(r\"Could've\", \"Could have\", tweet)\n",
        "    tweet = re.sub(r\"youve\", \"you have\", tweet)  \n",
        "    tweet = re.sub(r\"donå«t\", \"do not\", tweet)   \n",
        "            \n",
        "    # Character entity references\n",
        "    tweet = re.sub(r\"&gt;\", \"greater than\", tweet)\n",
        "    tweet = re.sub(r\"&lt;\", \"less than\", tweet)\n",
        "    tweet = re.sub(r\"&amp;\", \"and\", tweet)\n",
        "    \n",
        "    # Typos, slang and informal abbreviations\n",
        "    tweet = re.sub(r\"w/e\", \"whatever\", tweet)\n",
        "    tweet = re.sub(r\"w/\", \"with\", tweet)\n",
        "    tweet = re.sub(r\"USAgov\", \"USA government\", tweet)\n",
        "    tweet = re.sub(r\"recentlu\", \"recently\", tweet)\n",
        "    tweet = re.sub(r\"Ph0tos\", \"Photos\", tweet)\n",
        "    tweet = re.sub(r\"amirite\", \"am I right\", tweet)\n",
        "    tweet = re.sub(r\"exp0sed\", \"exposed\", tweet)\n",
        "    tweet = re.sub(r\"<3\", \"love\", tweet)\n",
        "    tweet = re.sub(r\"amageddon\", \"armageddon\", tweet)\n",
        "    tweet = re.sub(r\"Trfc\", \"Traffic\", tweet)\n",
        "               \n",
        "    # Urls\n",
        "    tweet = re.sub(r\"https?:\\/\\/t.co\\/[A-Za-z0-9]+\", \"\", tweet)\n",
        "        \n",
        "    # Words with punctuations and special characters\n",
        "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\"\n",
        "    for p in punctuations:\n",
        "        tweet = tweet.replace(p, f' {p} ')\n",
        "        \n",
        "    # ... and ..\n",
        "    tweet = tweet.replace('...', ' ... ')\n",
        "    if '...' not in tweet:\n",
        "        tweet = tweet.replace('..', ' ... ')      \n",
        "        \n",
        "    # Acronyms\n",
        "    tweet = re.sub(r\"MH370\", \"Malaysia Airlines Flight 370\", tweet)\n",
        "    tweet = re.sub(r\"mÌ¼sica\", \"music\", tweet)\n",
        "    tweet = re.sub(r\"okwx\", \"Oklahoma City Weather\", tweet)\n",
        "    tweet = re.sub(r\"arwx\", \"Arkansas Weather\", tweet)    \n",
        "    tweet = re.sub(r\"gawx\", \"Georgia Weather\", tweet)  \n",
        "    tweet = re.sub(r\"scwx\", \"South Carolina Weather\", tweet)  \n",
        "    tweet = re.sub(r\"cawx\", \"California Weather\", tweet)\n",
        "    tweet = re.sub(r\"tnwx\", \"Tennessee Weather\", tweet)\n",
        "    tweet = re.sub(r\"azwx\", \"Arizona Weather\", tweet)  \n",
        "    tweet = re.sub(r\"alwx\", \"Alabama Weather\", tweet)\n",
        "    tweet = re.sub(r\"wordpressdotcom\", \"wordpress\", tweet)    \n",
        "    tweet = re.sub(r\"usNWSgov\", \"United States National Weather Service\", tweet)\n",
        "    tweet = re.sub(r\"Suruc\", \"Sanliurfa\", tweet)   \n",
        "\n",
        "\n",
        "    #fancy words\n",
        "    tweet = re.sub(r\"fu[* ]*k\", \"fuck\", tweet)\n",
        "    tweet = re.sub(r\"[o|O]+[h|H]+\", \"oh\", tweet)\n",
        "    tweet = re.sub(r\"[M|y]+[y|Y]+\", \"my\", tweet)\n",
        "    tweet = re.sub(r\"[G|g]+[o|O]+[d|D]+\", \"god\", tweet)\n",
        "    tweet = re.sub(r\"[h|H]+[i|I]+\", \"hi\", tweet)\n",
        "    tweet = re.sub(r\"[o|O]+[k|K]+\", \"ok\", tweet)\n",
        "    tweet = re.sub(r\"[g|G]+[o|O]+[d|D]+\", \"good\", tweet)\n",
        "    tweet = re.sub(r\"[m|M]+[o|O]+[r|R]+[n|N]+[i|I]+[n|N]+[g|G]+\", \"morning\", tweet)\n",
        "    tweet = re.sub(r\"[h|H]+[e|E]+[l|L]+[o|O]+\", \"hello\", tweet)\n",
        "    tweet = re.sub(r\"[b|B]+[y|Y]+[e|E]+\", \"bye\", tweet)\n",
        "    #design\n",
        "    tweet = re.sub(r\"[0-9]+[PM|AM]\", \"\", tweet)\n",
        "\n",
        "    return tweet"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dWfd1WDv2eM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19238af1-81a6-4edb-c0ac-a889ecd56cf2"
      },
      "source": [
        "print(clean(\"Hhhhheeeeeelllllllllllooooooooooooooooo dosto, goood morninggggggggggggggggG\"))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello dosto, good morning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yrGwSawdRmH"
      },
      "source": [
        "#Function to remove Punctuation\n",
        "def remove_punct(text):\n",
        "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation])# It will discard all punctuations\n",
        "    return text_nopunct\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHKBni-j224E"
      },
      "source": [
        "def convert_label(label):\n",
        "  if label == \"neutral\": \n",
        "    return 0\n",
        "  elif label == \"worry\" :\n",
        "    return 1\n",
        "  elif label == \"happiness\" :\n",
        "    return 2\n",
        "  elif label == \"sadness\" :\n",
        "    return 3\n",
        "  elif label == \"love\" :\n",
        "    return 4\n",
        "  elif label == \"surprise\" :\n",
        "    return 5\n",
        "  elif label == \"fun\" :\n",
        "    return 6\n",
        "  elif label == \"relief\" :\n",
        "    return 7\n",
        "  elif label == \"hate\" :\n",
        "    return 8\n",
        "  elif label == \"empty\" :\n",
        "    return 9\n",
        "  elif label == \"enthusiasm\" :\n",
        "    return 10\n",
        "  elif label == \"boredom\" :\n",
        "    return 11\n",
        "  elif label == \"anger\" :\n",
        "    return 12"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifrEyo6lEtPm"
      },
      "source": [
        "#Applying Methods to Data Frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6Km_c4E29bA"
      },
      "source": [
        "def apply_methods(df):\n",
        "\n",
        "  df['tweets'] = df['tweets'].apply(lambda tweet : \" \".join(convert_emojis(tweet).split(\"_\")))\n",
        "\n",
        "  df['tweets'] = df['tweets'].apply(lambda tweet : convert_emoticons(tweet))\n",
        "\n",
        "  df['tweets'] = df['tweets'].apply(lambda tweet : clean_hashtags(tweet))\n",
        "\n",
        "  df['tweets'] = df['tweets'].apply(lambda tweet : clean_mentions(tweet))\n",
        "\n",
        "  df['tweets'] = df['tweets'].apply(lambda tweet: clean(tweet))\n",
        "\n",
        "  df['tweets'] = df['tweets'].apply(lambda tweet: remove_punct(tweet))\n",
        "\n",
        "  df['emotion'] = df['emotion'].apply(lambda label: convert_label(label))\n",
        "\n",
        "  df.head()\n",
        "\n",
        "  return df"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRbW7upx3o5q"
      },
      "source": [
        "df = apply_methods(df)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju41nyzW5Nfp",
        "outputId": "2d63c3ae-47bf-42c0-e160-c1ab699fdeae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9</td>\n",
              "      <td>i know  i was listenin to bad habit earlier and i started freakin at his part</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>Layin n bed with a headache  ughhhh      waitin on your call</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Funeral ceremony      gloomy friday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>wants to hang out with friends SOON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>We want to trade with someone who has Houston tickets but no one will</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   emotion                                                                               tweets\n",
              "0        9   i know  i was listenin to bad habit earlier and i started freakin at his part     \n",
              "1        3                   Layin n bed with a headache  ughhhh      waitin on your call      \n",
              "2        3                                            Funeral ceremony      gloomy friday      \n",
              "3       10                                                wants to hang out with friends SOON  \n",
              "4        0              We want to trade with someone who has Houston tickets but no one will  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fcu3-G2sLRmi"
      },
      "source": [
        "# Save Clean Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LsiefCMBJbt"
      },
      "source": [
        "df.to_csv('/content/drive/MyDrive/InfluenceAnalysis/crowdFlower/crowdFlower_clean1.csv',index=None)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xHmdjAf53y2"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMPPIiNN5eos"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fI-2CUlq52xo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}