{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AllEmotionMod.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harrymkwn/InfluenceAnalysis/blob/master/AllEmotionMod.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkuKKcIUmM27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88fd8717-51e9-4087-9a27-bdc21441a2ac"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from gensim.models import Word2Vec\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import  drive\n",
        "drive.mount('/content/drive')\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('all')\n",
        "device_name = tf.test.gpu_device_name()\n",
        "print(device_name)\n",
        "df_train = pd.read_csv('/content/drive/MyDrive/InfluenceAnalysis/Newdata/train_clean.csv',names=['Tweet','Emotion'])\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/InfluenceAnalysis/Newdata/test_clean.csv',names=['Tweet','Emotion'])\n",
        "df_train = df_train.sample(frac=1)\n",
        "df_test = df_train.sample(frac=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Package alpino is already up-to-date!\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    |   Package comtrans is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Package crubadan is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Package dolch is already up-to-date!\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Package floresta is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Package indian is already up-to-date!\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    |   Package jeita is already up-to-date!\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Package kimmo is already up-to-date!\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    |   Package knbc is already up-to-date!\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    |   Package machado is already up-to-date!\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Package paradigms is already up-to-date!\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Package pil is already up-to-date!\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Package pl196x is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    |   Package propbank is already up-to-date!\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Package ptb is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Package qc is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Package rte is already up-to-date!\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    |   Package semcor is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Package smultron is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Package switchboard is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Package ycoe is already up-to-date!\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Package rslp is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Package porter_test is already up-to-date!\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n",
            "/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0zrtpGceAiE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "b55c8629-0abe-4acc-a090-0b3dd50a3a70"
      },
      "source": [
        "df_train.head(1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6628</th>\n",
              "      <td>vivek whn r u goin to europ</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8818</th>\n",
              "      <td>i miss my puppi</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3325</th>\n",
              "      <td>iamdiddi it is so sad that me and my roommat f...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11965</th>\n",
              "      <td>got an email from my aunti bout father day mot...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2582</th>\n",
              "      <td>jalanii aww wat i wa go to buy myself someth p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363</th>\n",
              "      <td>I am suppos to turn in a sentenc outlin for my...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1111</th>\n",
              "      <td>dam it keep rainin on me</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4552</th>\n",
              "      <td>no u guy jonathanrknight said california in an...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5499</th>\n",
              "      <td>brookeleeadam gut you wont be on live offic gi...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6143</th>\n",
              "      <td>kind of bum that I am go to miss mrosenbaum re...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Tweet Emotion\n",
              "6628                         vivek whn r u goin to europ       2\n",
              "8818                                     i miss my puppi       2\n",
              "3325   iamdiddi it is so sad that me and my roommat f...       2\n",
              "11965  got an email from my aunti bout father day mot...       1\n",
              "2582   jalanii aww wat i wa go to buy myself someth p...       0\n",
              "...                                                  ...     ...\n",
              "363    I am suppos to turn in a sentenc outlin for my...       2\n",
              "1111                            dam it keep rainin on me       2\n",
              "4552   no u guy jonathanrknight said california in an...       0\n",
              "5499   brookeleeadam gut you wont be on live offic gi...       2\n",
              "6143   kind of bum that I am go to miss mrosenbaum re...       2\n",
              "\n",
              "[1000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K68sxL_LfLy7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c12b0299-030c-49e2-e544-58d4fe4f002d"
      },
      "source": [
        "df_test.Emotion.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['2', '1', '0', '3', 'emotion'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9KFGTW2iP8J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fa86442-e3dc-4c8e-b410-ee33cacdbc84"
      },
      "source": [
        "df_train.nunique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tweet      12370\n",
              "Emotion        5\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yV6_xYSnZHt"
      },
      "source": [
        "category_dict = {'0':[1,0,0,0],'1':[0,1,0,0],'2':[0,0,1,0],'3':[0,0,0,1],'emotion':[1,0,0,0]}\n",
        "train_data_tweet = [x.lower().split() for x in df_train['Tweet']]\n",
        "train_data_cat = np.array([category_dict[x] for x in df_train['Emotion']])\n",
        "test_data_tweet = [x.lower().split() for x in df_test['Tweet']]\n",
        "test_data_cat = np.array([category_dict[x] for x in df_test['Emotion']])\n",
        "\n",
        "data_tweet = train_data_tweet + test_data_tweet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mIV-pI5C44j"
      },
      "source": [
        "# Parameters\n",
        "Min_count = 0\n",
        "Embedding_size = 100\n",
        "Window_size = 5\n",
        "Negative_sampling = 00"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUSBfiE0nTVv"
      },
      "source": [
        "w2v_sg = Word2Vec(min_count=Min_count,\n",
        "                     window=Window_size,\n",
        "                     size=Embedding_size,\n",
        "                     negative=Negative_sampling,sg=1)\n",
        "w2v_sg.build_vocab(data_tweet)\n",
        "w2v_sg.train(data_tweet, total_examples=w2v_sg.corpus_count, epochs=5)\n",
        "w2v_cbow = Word2Vec(min_count=Min_count,\n",
        "                     window=Window_size,\n",
        "                     size=Embedding_size,\n",
        "                     negative=Negative_sampling,sg=0)\n",
        "w2v_cbow.build_vocab(data_tweet)\n",
        "w2v_cbow.train(data_tweet, total_examples=w2v_cbow.corpus_count, epochs=5)\n",
        "w2v_sg.wv.init_sims(True)\n",
        "w2v_cbow.wv.init_sims(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVzquoxb6FQJ"
      },
      "source": [
        "vocab_sg = w2v_sg.wv.vocab\n",
        "vocab_sg = [x for x in vocab_sg]\n",
        "vocab_cbow = w2v_cbow.wv.vocab\n",
        "vocab_cbow = [x for x in vocab_cbow] \n",
        "vocab_glove = {}\n",
        "with open(\"/content/drive/My Drive/InfluenceAnalysis/glove/glove.twitter.27B.100d.txt\", 'r', encoding=\"utf-8\") as f:\n",
        "  for line in f:\n",
        "      values = line.split()\n",
        "      word = values[0]\n",
        "      vector = np.asarray(values[1:], \"float32\")\n",
        "      vocab_glove[word] = vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdgSI9FSmw60"
      },
      "source": [
        "batch_size = 500\r\n",
        "Max_input_size = max([len(x) for x in data_tweet])\r\n",
        "mul_factor=1.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Fue2npdFINi"
      },
      "source": [
        "X_train = train_data_tweet\n",
        "X_test = test_data_tweet\n",
        "y_train = train_data_cat\n",
        "y_test = test_data_cat\n",
        "X_train = [nltk.pos_tag(x) for x in X_train]\n",
        "X_test = [nltk.pos_tag(x) for x in X_test]\n",
        "result_table = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArwAlW-wmZxv"
      },
      "source": [
        "def vec_gen(w2v,vocab,data_tweet,data_cat,batch_size,Max_input_size,Embedding_size,mul_factor):\r\n",
        "  while True:\r\n",
        "    for k in range(int(len(data_tweet)/batch_size)):\r\n",
        "      res=[]\r\n",
        "      for x in data_tweet[k*(batch_size):(k+1)*(batch_size)]:\r\n",
        "        tweet = [(w2v.wv.word_vec(i[0]),i[1]) for i in x if i[0] in vocab]\r\n",
        "        l=len(tweet)\r\n",
        "        for i in range(l):\r\n",
        "          if tweet[i][1][:2]=='JJ' or tweet[i][1][:2]=='RB':\r\n",
        "            tweet[i]=((tweet[i][0])*mul_factor,tweet[i][1])\r\n",
        "        res+=[np.array([x[0] for x in tweet])]\r\n",
        "      temp = np.array([np.pad(z.flatten(),(0,Max_input_size*Embedding_size-len(z.flatten()))).reshape(Max_input_size,Embedding_size) for z in res])\r\n",
        "      tempres = data_cat[k*(batch_size):(k+1)*(batch_size)]\r\n",
        "      yield (temp,tempres)          \r\n",
        "      \r\n",
        "def glove_gen(vocab,data_tweet,data_cat,batch_size,Max_input_size,Embedding_size,mul_factor):\r\n",
        "  while True:\r\n",
        "    for k in range(int(len(data_tweet)/batch_size)):\r\n",
        "      res=[]\r\n",
        "      for x in data_tweet[k*(batch_size):(k+1)*(batch_size)]:\r\n",
        "        tweet = [(vocab[i[0]],i[1]) for i in x if i[0] in vocab.keys()]\r\n",
        "        l=len(tweet)\r\n",
        "        for i in range(l):\r\n",
        "          if tweet[i][1][:2]=='JJ' or tweet[i][1][:2]=='RB':\r\n",
        "            tweet[i]=((tweet[i][0])*mul_factor,tweet[i][1])\r\n",
        "        res+=[np.array([x[0] for x in tweet])]\r\n",
        "      temp = np.array([np.pad(z.flatten(),(0,Max_input_size*Embedding_size-len(z.flatten()))).reshape(Max_input_size,Embedding_size) for z in res])\r\n",
        "      tempres = data_cat[k*(batch_size):(k+1)*(batch_size)]\r\n",
        "      yield (temp,tempres)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0leTuTOb3naL"
      },
      "source": [
        "epochs = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GfgXfAFlD1J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a056ace6-24be-4b31-8265-239ab0e3c65e"
      },
      "source": [
        "model_sg = tf.keras.Sequential()\n",
        "model_sg.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\n",
        "model_sg.add(tf.keras.layers.LSTM(50))\n",
        "model_sg.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
        "model_sg.compile(loss='categorical_crossentropy',optimizer='adam', \n",
        "                           metrics=['accuracy'])\n",
        "history_sg_lstm = model_sg.fit_generator(generator = vec_gen(w2v_sg,vocab_sg,X_train,y_train,batch_size,Max_input_size,Embedding_size,mul_factor),steps_per_epoch=int(len(X_train)/batch_size),epochs=epochs)\n",
        "history = model_sg.evaluate(x = vec_gen(w2v_sg,vocab_sg,X_test,y_test,batch_size,Max_input_size,Embedding_size,mul_factor),steps=int(len(y_test)/batch_size))\n",
        "print(history)\n",
        "\n",
        "result_table+=[history[1]]\n",
        "print(\"SG_LSTM\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-13-24e7db92a97b>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/50\n",
            " 2/24 [=>............................] - ETA: 0s - loss: 1.3841 - accuracy: 0.4410WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0205s vs `on_train_batch_end` time: 0.0965s). Check your callbacks.\n",
            "24/24 [==============================] - 5s 229ms/step - loss: 1.2434 - accuracy: 0.5723\n",
            "Epoch 2/50\n",
            "24/24 [==============================] - 6s 235ms/step - loss: 1.0211 - accuracy: 0.5845\n",
            "Epoch 3/50\n",
            "24/24 [==============================] - 6s 234ms/step - loss: 0.9859 - accuracy: 0.5845\n",
            "Epoch 4/50\n",
            "24/24 [==============================] - 6s 235ms/step - loss: 0.9838 - accuracy: 0.5845\n",
            "Epoch 5/50\n",
            "24/24 [==============================] - 6s 236ms/step - loss: 0.9797 - accuracy: 0.5845\n",
            "Epoch 6/50\n",
            "24/24 [==============================] - 6s 232ms/step - loss: 0.9754 - accuracy: 0.5845\n",
            "Epoch 7/50\n",
            "24/24 [==============================] - 6s 238ms/step - loss: 0.9707 - accuracy: 0.5845\n",
            "Epoch 8/50\n",
            "24/24 [==============================] - 6s 231ms/step - loss: 0.9666 - accuracy: 0.5845\n",
            "Epoch 9/50\n",
            "24/24 [==============================] - 6s 234ms/step - loss: 0.9643 - accuracy: 0.5845\n",
            "Epoch 10/50\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.9621 - accuracy: 0.5845\n",
            "Epoch 11/50\n",
            "24/24 [==============================] - 6s 235ms/step - loss: 0.9594 - accuracy: 0.5846\n",
            "Epoch 12/50\n",
            "24/24 [==============================] - 6s 235ms/step - loss: 0.9566 - accuracy: 0.5846\n",
            "Epoch 13/50\n",
            "24/24 [==============================] - 6s 233ms/step - loss: 0.9526 - accuracy: 0.5862\n",
            "Epoch 14/50\n",
            "24/24 [==============================] - 6s 232ms/step - loss: 0.9480 - accuracy: 0.5871\n",
            "Epoch 15/50\n",
            "24/24 [==============================] - 6s 236ms/step - loss: 0.9415 - accuracy: 0.5872\n",
            "Epoch 16/50\n",
            "24/24 [==============================] - 6s 234ms/step - loss: 0.9332 - accuracy: 0.5869\n",
            "Epoch 17/50\n",
            "24/24 [==============================] - 6s 234ms/step - loss: 0.9229 - accuracy: 0.5913\n",
            "Epoch 18/50\n",
            "24/24 [==============================] - 6s 236ms/step - loss: 0.9091 - accuracy: 0.6007\n",
            "Epoch 19/50\n",
            "24/24 [==============================] - 6s 234ms/step - loss: 0.9026 - accuracy: 0.6002\n",
            "Epoch 20/50\n",
            "24/24 [==============================] - 6s 233ms/step - loss: 0.8937 - accuracy: 0.6058\n",
            "Epoch 21/50\n",
            "24/24 [==============================] - 6s 235ms/step - loss: 0.8834 - accuracy: 0.6150\n",
            "Epoch 22/50\n",
            "24/24 [==============================] - 6s 232ms/step - loss: 0.8726 - accuracy: 0.6217\n",
            "Epoch 23/50\n",
            "24/24 [==============================] - 6s 238ms/step - loss: 0.8638 - accuracy: 0.6265\n",
            "Epoch 24/50\n",
            "24/24 [==============================] - 6s 241ms/step - loss: 0.8555 - accuracy: 0.6292\n",
            "Epoch 25/50\n",
            "24/24 [==============================] - 6s 237ms/step - loss: 0.8468 - accuracy: 0.6343\n",
            "Epoch 26/50\n",
            "24/24 [==============================] - 6s 234ms/step - loss: 0.8381 - accuracy: 0.6418\n",
            "Epoch 27/50\n",
            "24/24 [==============================] - 6s 236ms/step - loss: 0.8299 - accuracy: 0.6457\n",
            "Epoch 28/50\n",
            "24/24 [==============================] - 6s 235ms/step - loss: 0.8220 - accuracy: 0.6503\n",
            "Epoch 29/50\n",
            "24/24 [==============================] - 6s 238ms/step - loss: 0.8143 - accuracy: 0.6529\n",
            "Epoch 30/50\n",
            "24/24 [==============================] - 6s 235ms/step - loss: 0.8068 - accuracy: 0.6574\n",
            "Epoch 31/50\n",
            "24/24 [==============================] - 6s 251ms/step - loss: 0.8003 - accuracy: 0.6612\n",
            "Epoch 32/50\n",
            "24/24 [==============================] - 6s 251ms/step - loss: 0.7963 - accuracy: 0.6638\n",
            "Epoch 33/50\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.8065 - accuracy: 0.6588\n",
            "Epoch 34/50\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.8174 - accuracy: 0.6517\n",
            "Epoch 35/50\n",
            "24/24 [==============================] - 6s 231ms/step - loss: 0.8121 - accuracy: 0.6562\n",
            "Epoch 36/50\n",
            "24/24 [==============================] - 6s 231ms/step - loss: 0.8020 - accuracy: 0.6615\n",
            "Epoch 37/50\n",
            "24/24 [==============================] - 6s 237ms/step - loss: 0.7900 - accuracy: 0.6708\n",
            "Epoch 38/50\n",
            "24/24 [==============================] - 6s 239ms/step - loss: 0.7820 - accuracy: 0.6743\n",
            "Epoch 39/50\n",
            "24/24 [==============================] - 6s 236ms/step - loss: 0.7747 - accuracy: 0.6767\n",
            "Epoch 40/50\n",
            "24/24 [==============================] - 6s 231ms/step - loss: 0.7683 - accuracy: 0.6790\n",
            "Epoch 41/50\n",
            "24/24 [==============================] - 6s 235ms/step - loss: 0.7625 - accuracy: 0.6820\n",
            "Epoch 42/50\n",
            "24/24 [==============================] - 5s 229ms/step - loss: 0.7562 - accuracy: 0.6844\n",
            "Epoch 43/50\n",
            "24/24 [==============================] - 6s 232ms/step - loss: 0.7502 - accuracy: 0.6881\n",
            "Epoch 44/50\n",
            "24/24 [==============================] - 6s 235ms/step - loss: 0.7427 - accuracy: 0.6940\n",
            "Epoch 45/50\n",
            "24/24 [==============================] - 6s 231ms/step - loss: 0.7366 - accuracy: 0.6975\n",
            "Epoch 46/50\n",
            "24/24 [==============================] - 6s 232ms/step - loss: 0.7332 - accuracy: 0.6994\n",
            "Epoch 47/50\n",
            "24/24 [==============================] - 6s 231ms/step - loss: 0.7366 - accuracy: 0.6958\n",
            "Epoch 48/50\n",
            "24/24 [==============================] - 6s 230ms/step - loss: 0.7612 - accuracy: 0.6818\n",
            "Epoch 49/50\n",
            "24/24 [==============================] - 6s 233ms/step - loss: 0.7516 - accuracy: 0.6900\n",
            "Epoch 50/50\n",
            "24/24 [==============================] - 6s 237ms/step - loss: 0.7319 - accuracy: 0.7023\n",
            "24/24 [==============================] - 6s 241ms/step - loss: 0.7655 - accuracy: 0.6852\n",
            "[0.7654877305030823, 0.6852499842643738]\n",
            "SG_LSTM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJHtKjzc1SA8",
        "outputId": "d15c9c8b-7724-4432-f538-e2e1c5e96171"
      },
      "source": [
        "model_sg_bi = tf.keras.Sequential()\r\n",
        "model_sg_bi.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_sg_bi.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50),merge_mode='concat'))\r\n",
        "model_sg_bi.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_sg_bi.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy'])\r\n",
        "history_sg_bi = model_sg_bi.fit_generator(generator = vec_gen(w2v_sg,vocab_sg,X_train,y_train,batch_size,Max_input_size,Embedding_size,mul_factor),steps_per_epoch=int(len(X_train)/batch_size),epochs=epochs)\r\n",
        "history = model_sg_bi.evaluate(x = vec_gen(w2v_sg,vocab_sg,X_test,y_test,batch_size,Max_input_size,Embedding_size,mul_factor),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table+=[history[1]]\r\n",
        "print(\"SG_BI\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "24/24 [==============================] - 6s 234ms/step - loss: 1.2051 - accuracy: 0.5346\n",
            "Epoch 2/50\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.9903 - accuracy: 0.5845\n",
            "Epoch 3/50\n",
            "24/24 [==============================] - 6s 238ms/step - loss: 0.9801 - accuracy: 0.5845\n",
            "Epoch 4/50\n",
            "24/24 [==============================] - 6s 234ms/step - loss: 0.9760 - accuracy: 0.5845\n",
            "Epoch 5/50\n",
            "24/24 [==============================] - 6s 237ms/step - loss: 0.9710 - accuracy: 0.5846\n",
            "Epoch 6/50\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.9648 - accuracy: 0.5846\n",
            "Epoch 7/50\n",
            "24/24 [==============================] - 6s 238ms/step - loss: 0.9587 - accuracy: 0.5847\n",
            "Epoch 8/50\n",
            "24/24 [==============================] - 6s 234ms/step - loss: 0.9524 - accuracy: 0.5848\n",
            "Epoch 9/50\n",
            "24/24 [==============================] - 6s 237ms/step - loss: 0.9472 - accuracy: 0.5851\n",
            "Epoch 10/50\n",
            "24/24 [==============================] - 6s 231ms/step - loss: 0.9433 - accuracy: 0.5848\n",
            "Epoch 11/50\n",
            "24/24 [==============================] - 6s 232ms/step - loss: 0.9396 - accuracy: 0.5856\n",
            "Epoch 12/50\n",
            "24/24 [==============================] - 5s 229ms/step - loss: 0.9366 - accuracy: 0.5866\n",
            "Epoch 13/50\n",
            "24/24 [==============================] - 6s 231ms/step - loss: 0.9350 - accuracy: 0.5875\n",
            "Epoch 14/50\n",
            "24/24 [==============================] - 6s 236ms/step - loss: 0.9348 - accuracy: 0.5882\n",
            "Epoch 15/50\n",
            "24/24 [==============================] - 6s 237ms/step - loss: 0.9313 - accuracy: 0.5893\n",
            "Epoch 16/50\n",
            "24/24 [==============================] - 6s 232ms/step - loss: 0.9242 - accuracy: 0.5913\n",
            "Epoch 17/50\n",
            "24/24 [==============================] - 6s 232ms/step - loss: 0.9177 - accuracy: 0.5931\n",
            "Epoch 18/50\n",
            "24/24 [==============================] - 6s 235ms/step - loss: 0.9135 - accuracy: 0.5951\n",
            "Epoch 19/50\n",
            "24/24 [==============================] - 6s 234ms/step - loss: 0.9084 - accuracy: 0.5970\n",
            "Epoch 20/50\n",
            "24/24 [==============================] - 6s 233ms/step - loss: 0.9028 - accuracy: 0.6012\n",
            "Epoch 21/50\n",
            "24/24 [==============================] - 6s 232ms/step - loss: 0.8970 - accuracy: 0.6043\n",
            "Epoch 22/50\n",
            "24/24 [==============================] - 6s 232ms/step - loss: 0.8908 - accuracy: 0.6071\n",
            "Epoch 23/50\n",
            "24/24 [==============================] - 6s 234ms/step - loss: 0.8840 - accuracy: 0.6118\n",
            "Epoch 24/50\n",
            "24/24 [==============================] - 6s 230ms/step - loss: 0.8766 - accuracy: 0.6138\n",
            "Epoch 25/50\n",
            "24/24 [==============================] - 6s 233ms/step - loss: 0.8719 - accuracy: 0.6169\n",
            "Epoch 26/50\n",
            "24/24 [==============================] - 6s 235ms/step - loss: 0.8719 - accuracy: 0.6159\n",
            "Epoch 27/50\n",
            "24/24 [==============================] - 6s 234ms/step - loss: 0.8586 - accuracy: 0.6187\n",
            "Epoch 28/50\n",
            "24/24 [==============================] - 6s 237ms/step - loss: 0.8515 - accuracy: 0.6235\n",
            "Epoch 29/50\n",
            "24/24 [==============================] - 6s 238ms/step - loss: 0.8418 - accuracy: 0.6300\n",
            "Epoch 30/50\n",
            "24/24 [==============================] - 6s 231ms/step - loss: 0.8346 - accuracy: 0.6328\n",
            "Epoch 31/50\n",
            "24/24 [==============================] - 6s 231ms/step - loss: 0.8267 - accuracy: 0.6383\n",
            "Epoch 32/50\n",
            "24/24 [==============================] - 6s 235ms/step - loss: 0.8198 - accuracy: 0.6433\n",
            "Epoch 33/50\n",
            "24/24 [==============================] - 6s 239ms/step - loss: 0.8091 - accuracy: 0.6446\n",
            "Epoch 34/50\n",
            "24/24 [==============================] - 6s 249ms/step - loss: 0.7970 - accuracy: 0.6526\n",
            "Epoch 35/50\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.7877 - accuracy: 0.6593\n",
            "Epoch 36/50\n",
            "24/24 [==============================] - 6s 230ms/step - loss: 0.7904 - accuracy: 0.6583\n",
            "Epoch 37/50\n",
            "24/24 [==============================] - 6s 232ms/step - loss: 0.8093 - accuracy: 0.6486\n",
            "Epoch 38/50\n",
            "24/24 [==============================] - 6s 234ms/step - loss: 0.8168 - accuracy: 0.6459\n",
            "Epoch 39/50\n",
            "24/24 [==============================] - 6s 233ms/step - loss: 0.7935 - accuracy: 0.6587\n",
            "Epoch 40/50\n",
            "24/24 [==============================] - 6s 230ms/step - loss: 0.7818 - accuracy: 0.6628\n",
            "Epoch 41/50\n",
            "24/24 [==============================] - 6s 232ms/step - loss: 0.7779 - accuracy: 0.6614\n",
            "Epoch 42/50\n",
            "24/24 [==============================] - 6s 239ms/step - loss: 0.7599 - accuracy: 0.6690\n",
            "Epoch 43/50\n",
            "24/24 [==============================] - 6s 235ms/step - loss: 0.7521 - accuracy: 0.6795\n",
            "Epoch 44/50\n",
            "24/24 [==============================] - 6s 231ms/step - loss: 0.7526 - accuracy: 0.6753\n",
            "Epoch 45/50\n",
            "24/24 [==============================] - 5s 229ms/step - loss: 0.7534 - accuracy: 0.6756\n",
            "Epoch 46/50\n",
            "24/24 [==============================] - 6s 232ms/step - loss: 0.7585 - accuracy: 0.6727\n",
            "Epoch 47/50\n",
            "24/24 [==============================] - 6s 233ms/step - loss: 0.7381 - accuracy: 0.6833\n",
            "Epoch 48/50\n",
            "24/24 [==============================] - 6s 233ms/step - loss: 0.7161 - accuracy: 0.6962\n",
            "Epoch 49/50\n",
            "24/24 [==============================] - 5s 227ms/step - loss: 0.6988 - accuracy: 0.7039\n",
            "Epoch 50/50\n",
            "24/24 [==============================] - 6s 231ms/step - loss: 0.6875 - accuracy: 0.7106\n",
            "24/24 [==============================] - 6s 235ms/step - loss: 0.7104 - accuracy: 0.7021\n",
            "[0.710440456867218, 0.7020833492279053]\n",
            "SG_BI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opfhhYPH1VoL",
        "outputId": "d151a498-6e25-4ac2-8931-838213cc0197"
      },
      "source": [
        "model_sg_rnn = tf.keras.Sequential()\r\n",
        "model_sg_rnn.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_sg_rnn.add(tf.keras.layers.SimpleRNN(50))\r\n",
        "model_sg_rnn.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_sg_rnn.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy'])\r\n",
        "history_sg_rnn = model_sg_rnn.fit_generator(generator = vec_gen(w2v_sg,vocab_sg,X_train,y_train,batch_size,Max_input_size,Embedding_size,mul_factor),steps_per_epoch=int(len(X_train)/batch_size),epochs=epochs)\r\n",
        "history = model_sg_rnn.evaluate(x = vec_gen(w2v_sg,vocab_sg,X_test,y_test,batch_size,Max_input_size,Embedding_size,mul_factor),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table+=[history[1]]\r\n",
        "print(\"SG_RNN\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 1.1231 - accuracy: 0.5298\n",
            "Epoch 2/50\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.9963 - accuracy: 0.5837\n",
            "Epoch 3/50\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.9887 - accuracy: 0.5844\n",
            "Epoch 4/50\n",
            "24/24 [==============================] - 6s 246ms/step - loss: 0.9879 - accuracy: 0.5844\n",
            "Epoch 5/50\n",
            "24/24 [==============================] - 6s 249ms/step - loss: 0.9878 - accuracy: 0.5844\n",
            "Epoch 6/50\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.9879 - accuracy: 0.5844\n",
            "Epoch 7/50\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.9880 - accuracy: 0.5844\n",
            "Epoch 8/50\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.9880 - accuracy: 0.5844\n",
            "Epoch 9/50\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.9880 - accuracy: 0.5844\n",
            "Epoch 10/50\n",
            "24/24 [==============================] - 6s 241ms/step - loss: 0.9879 - accuracy: 0.5844\n",
            "Epoch 11/50\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.9879 - accuracy: 0.5844\n",
            "Epoch 12/50\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.9879 - accuracy: 0.5844\n",
            "Epoch 13/50\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.9879 - accuracy: 0.5844\n",
            "Epoch 14/50\n",
            "24/24 [==============================] - 6s 238ms/step - loss: 0.9879 - accuracy: 0.5844\n",
            "Epoch 15/50\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.9879 - accuracy: 0.5844\n",
            "Epoch 16/50\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.9879 - accuracy: 0.5844\n",
            "Epoch 17/50\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.9877 - accuracy: 0.5844\n",
            "Epoch 18/50\n",
            "24/24 [==============================] - 6s 246ms/step - loss: 0.9878 - accuracy: 0.5844\n",
            "Epoch 19/50\n",
            "24/24 [==============================] - 6s 245ms/step - loss: 0.9878 - accuracy: 0.5844\n",
            "Epoch 20/50\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.9878 - accuracy: 0.5844\n",
            "Epoch 21/50\n",
            "24/24 [==============================] - 6s 239ms/step - loss: 0.9879 - accuracy: 0.5845\n",
            "Epoch 22/50\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.9874 - accuracy: 0.5845\n",
            "Epoch 23/50\n",
            "24/24 [==============================] - 6s 248ms/step - loss: 0.9873 - accuracy: 0.5845\n",
            "Epoch 24/50\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.9873 - accuracy: 0.5845\n",
            "Epoch 25/50\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.9873 - accuracy: 0.5845\n",
            "Epoch 26/50\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.9872 - accuracy: 0.5845\n",
            "Epoch 27/50\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.9872 - accuracy: 0.5845\n",
            "Epoch 28/50\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.9872 - accuracy: 0.5845\n",
            "Epoch 29/50\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.9871 - accuracy: 0.5845\n",
            "Epoch 30/50\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.9871 - accuracy: 0.5845\n",
            "Epoch 31/50\n",
            "24/24 [==============================] - 6s 241ms/step - loss: 0.9870 - accuracy: 0.5845\n",
            "Epoch 32/50\n",
            "24/24 [==============================] - 6s 250ms/step - loss: 0.9870 - accuracy: 0.5845\n",
            "Epoch 33/50\n",
            "24/24 [==============================] - 6s 246ms/step - loss: 0.9869 - accuracy: 0.5845\n",
            "Epoch 34/50\n",
            "24/24 [==============================] - 6s 241ms/step - loss: 0.9868 - accuracy: 0.5845\n",
            "Epoch 35/50\n",
            "24/24 [==============================] - 6s 256ms/step - loss: 0.9867 - accuracy: 0.5845\n",
            "Epoch 36/50\n",
            "24/24 [==============================] - 6s 261ms/step - loss: 0.9866 - accuracy: 0.5845\n",
            "Epoch 37/50\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.9863 - accuracy: 0.5845\n",
            "Epoch 38/50\n",
            "24/24 [==============================] - 6s 241ms/step - loss: 0.9860 - accuracy: 0.5845\n",
            "Epoch 39/50\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.9854 - accuracy: 0.5846\n",
            "Epoch 40/50\n",
            "24/24 [==============================] - 6s 249ms/step - loss: 0.9846 - accuracy: 0.5846\n",
            "Epoch 41/50\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.9833 - accuracy: 0.5847\n",
            "Epoch 42/50\n",
            "24/24 [==============================] - 6s 245ms/step - loss: 0.9816 - accuracy: 0.5850\n",
            "Epoch 43/50\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.9794 - accuracy: 0.5852\n",
            "Epoch 44/50\n",
            "24/24 [==============================] - 6s 247ms/step - loss: 0.9769 - accuracy: 0.5857\n",
            "Epoch 45/50\n",
            "24/24 [==============================] - 6s 246ms/step - loss: 0.9736 - accuracy: 0.5860\n",
            "Epoch 46/50\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.9699 - accuracy: 0.5865\n",
            "Epoch 47/50\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.9658 - accuracy: 0.5867\n",
            "Epoch 48/50\n",
            "24/24 [==============================] - 6s 234ms/step - loss: 0.9612 - accuracy: 0.5882\n",
            "Epoch 49/50\n",
            "24/24 [==============================] - 6s 236ms/step - loss: 0.9563 - accuracy: 0.5891\n",
            "Epoch 50/50\n",
            "24/24 [==============================] - 6s 233ms/step - loss: 0.9529 - accuracy: 0.5927\n",
            "24/24 [==============================] - 5s 225ms/step - loss: 0.9587 - accuracy: 0.5857\n",
            "[0.9586917161941528, 0.5857499837875366]\n",
            "SG_RNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YumD1M9Y1Xxr",
        "outputId": "0a62f67f-6857-427a-c817-b2a1c6a3d55c"
      },
      "source": [
        "model_cbow = tf.keras.Sequential()\r\n",
        "model_cbow.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_cbow.add(tf.keras.layers.LSTM(50))\r\n",
        "model_cbow.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_cbow.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy'])\r\n",
        "history_cbow_lstm = model_cbow.fit_generator(generator = vec_gen(w2v_cbow,vocab_cbow,X_train,y_train,batch_size,Max_input_size,Embedding_size,mul_factor),steps_per_epoch=int(len(X_train)/batch_size),epochs=epochs)\r\n",
        "history = model_cbow.evaluate(x = vec_gen(w2v_cbow,vocab_cbow,X_test,y_test,batch_size,Max_input_size,Embedding_size,mul_factor),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table+=[history[1]]\r\n",
        "print(\"CBOW_LSTM\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "24/24 [==============================] - 6s 234ms/step - loss: 1.2140 - accuracy: 0.5712\n",
            "Epoch 2/50\n",
            "24/24 [==============================] - 6s 231ms/step - loss: 0.9914 - accuracy: 0.5845\n",
            "Epoch 3/50\n",
            "24/24 [==============================] - 6s 237ms/step - loss: 0.9832 - accuracy: 0.5845\n",
            "Epoch 4/50\n",
            "24/24 [==============================] - 5s 228ms/step - loss: 0.9798 - accuracy: 0.5845\n",
            "Epoch 5/50\n",
            "24/24 [==============================] - 6s 234ms/step - loss: 0.9758 - accuracy: 0.5845\n",
            "Epoch 6/50\n",
            "24/24 [==============================] - 6s 232ms/step - loss: 0.9718 - accuracy: 0.5845\n",
            "Epoch 7/50\n",
            "24/24 [==============================] - 6s 231ms/step - loss: 0.9672 - accuracy: 0.5845\n",
            "Epoch 8/50\n",
            "24/24 [==============================] - 6s 238ms/step - loss: 0.9639 - accuracy: 0.5845\n",
            "Epoch 9/50\n",
            "24/24 [==============================] - 6s 235ms/step - loss: 0.9618 - accuracy: 0.5847\n",
            "Epoch 10/50\n",
            "24/24 [==============================] - 6s 229ms/step - loss: 0.9592 - accuracy: 0.5846\n",
            "Epoch 11/50\n",
            "24/24 [==============================] - 6s 231ms/step - loss: 0.9557 - accuracy: 0.5876\n",
            "Epoch 12/50\n",
            "24/24 [==============================] - 6s 231ms/step - loss: 0.9512 - accuracy: 0.5870\n",
            "Epoch 13/50\n",
            "24/24 [==============================] - 6s 238ms/step - loss: 0.9460 - accuracy: 0.5870\n",
            "Epoch 14/50\n",
            "24/24 [==============================] - 6s 236ms/step - loss: 0.9397 - accuracy: 0.5897\n",
            "Epoch 15/50\n",
            "24/24 [==============================] - 6s 235ms/step - loss: 0.9313 - accuracy: 0.5918\n",
            "Epoch 16/50\n",
            "24/24 [==============================] - 6s 246ms/step - loss: 0.9195 - accuracy: 0.5974\n",
            "Epoch 17/50\n",
            "24/24 [==============================] - 6s 241ms/step - loss: 0.9113 - accuracy: 0.5991\n",
            "Epoch 18/50\n",
            "24/24 [==============================] - 6s 241ms/step - loss: 0.9033 - accuracy: 0.6048\n",
            "Epoch 19/50\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.8940 - accuracy: 0.6117\n",
            "Epoch 20/50\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.8817 - accuracy: 0.6205\n",
            "Epoch 21/50\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.8739 - accuracy: 0.6220\n",
            "Epoch 22/50\n",
            "24/24 [==============================] - 6s 249ms/step - loss: 0.8639 - accuracy: 0.6269\n",
            "Epoch 23/50\n",
            "24/24 [==============================] - 6s 248ms/step - loss: 0.8546 - accuracy: 0.6316\n",
            "Epoch 24/50\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.8472 - accuracy: 0.6380\n",
            "Epoch 25/50\n",
            "24/24 [==============================] - 6s 238ms/step - loss: 0.8395 - accuracy: 0.6415\n",
            "Epoch 26/50\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.8313 - accuracy: 0.6448\n",
            "Epoch 27/50\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.8235 - accuracy: 0.6501\n",
            "Epoch 28/50\n",
            "24/24 [==============================] - 6s 239ms/step - loss: 0.8160 - accuracy: 0.6546\n",
            "Epoch 29/50\n",
            "24/24 [==============================] - 6s 239ms/step - loss: 0.8098 - accuracy: 0.6587\n",
            "Epoch 30/50\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.8107 - accuracy: 0.6577\n",
            "Epoch 31/50\n",
            "24/24 [==============================] - 6s 241ms/step - loss: 0.8044 - accuracy: 0.6620\n",
            "Epoch 32/50\n",
            "24/24 [==============================] - 6s 236ms/step - loss: 0.7895 - accuracy: 0.6695\n",
            "Epoch 33/50\n",
            "24/24 [==============================] - 6s 239ms/step - loss: 0.7802 - accuracy: 0.6750\n",
            "Epoch 34/50\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.7723 - accuracy: 0.6833\n",
            "Epoch 35/50\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.7657 - accuracy: 0.6893\n",
            "Epoch 36/50\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.7597 - accuracy: 0.6925\n",
            "Epoch 37/50\n",
            "24/24 [==============================] - 6s 254ms/step - loss: 0.7561 - accuracy: 0.6954\n",
            "Epoch 38/50\n",
            "24/24 [==============================] - 6s 249ms/step - loss: 0.7609 - accuracy: 0.6927\n",
            "Epoch 39/50\n",
            "24/24 [==============================] - 6s 237ms/step - loss: 0.8001 - accuracy: 0.6692\n",
            "Epoch 40/50\n",
            "24/24 [==============================] - 6s 233ms/step - loss: 0.8026 - accuracy: 0.6667\n",
            "Epoch 41/50\n",
            "24/24 [==============================] - 6s 238ms/step - loss: 0.7840 - accuracy: 0.6759\n",
            "Epoch 42/50\n",
            "24/24 [==============================] - 6s 237ms/step - loss: 0.7718 - accuracy: 0.6828\n",
            "Epoch 43/50\n",
            "24/24 [==============================] - 6s 236ms/step - loss: 0.7638 - accuracy: 0.6883\n",
            "Epoch 44/50\n",
            "24/24 [==============================] - 6s 236ms/step - loss: 0.7563 - accuracy: 0.6927\n",
            "Epoch 45/50\n",
            "24/24 [==============================] - 6s 237ms/step - loss: 0.7511 - accuracy: 0.6966\n",
            "Epoch 46/50\n",
            "24/24 [==============================] - 6s 238ms/step - loss: 0.7464 - accuracy: 0.7016\n",
            "Epoch 47/50\n",
            "24/24 [==============================] - 6s 237ms/step - loss: 0.7404 - accuracy: 0.7049\n",
            "Epoch 48/50\n",
            "24/24 [==============================] - 6s 241ms/step - loss: 0.7304 - accuracy: 0.7093\n",
            "Epoch 49/50\n",
            "24/24 [==============================] - 6s 241ms/step - loss: 0.7191 - accuracy: 0.7165\n",
            "Epoch 50/50\n",
            "24/24 [==============================] - 6s 239ms/step - loss: 0.7107 - accuracy: 0.7224\n",
            " 2/24 [=>............................] - ETA: 2s - loss: 0.7336 - accuracy: 0.7270WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0765s vs `on_test_batch_end` time: 0.1891s). Check your callbacks.\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.7201 - accuracy: 0.7178\n",
            "[0.7200543880462646, 0.7177500128746033]\n",
            "CBOW_LSTM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01yVMiF41ZtT",
        "outputId": "b6e4869f-1de6-48b1-98e1-96d071a62e5b"
      },
      "source": [
        "model_cbow_bi = tf.keras.Sequential()\r\n",
        "model_cbow_bi.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_cbow_bi.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50),merge_mode='concat'))\r\n",
        "model_cbow_bi.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_cbow_bi.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy'])\r\n",
        "history_cbow_bi = model_cbow_bi.fit_generator(generator = vec_gen(w2v_cbow,vocab_cbow,X_train,y_train,batch_size,Max_input_size,Embedding_size,mul_factor),steps_per_epoch=int(len(X_train)/batch_size),epochs=epochs)\r\n",
        "history = model_cbow_bi.evaluate(x = vec_gen(w2v_cbow,vocab_cbow,X_test,y_test,batch_size,Max_input_size,Embedding_size,mul_factor),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table+=[history[1]]\r\n",
        "print(\"CBOW_BI\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "24/24 [==============================] - 6s 237ms/step - loss: 1.1908 - accuracy: 0.5572\n",
            "Epoch 2/50\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.9883 - accuracy: 0.5845\n",
            "Epoch 3/50\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.9768 - accuracy: 0.5845\n",
            "Epoch 4/50\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.9709 - accuracy: 0.5845\n",
            "Epoch 5/50\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.9647 - accuracy: 0.5847\n",
            "Epoch 6/50\n",
            "24/24 [==============================] - 6s 237ms/step - loss: 0.9594 - accuracy: 0.5848\n",
            "Epoch 7/50\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.9544 - accuracy: 0.5849\n",
            "Epoch 8/50\n",
            "24/24 [==============================] - 6s 246ms/step - loss: 0.9495 - accuracy: 0.5863\n",
            "Epoch 9/50\n",
            "24/24 [==============================] - 6s 241ms/step - loss: 0.9449 - accuracy: 0.5867\n",
            "Epoch 10/50\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.9404 - accuracy: 0.5878\n",
            "Epoch 11/50\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.9359 - accuracy: 0.5895\n",
            "Epoch 12/50\n",
            "24/24 [==============================] - 6s 252ms/step - loss: 0.9316 - accuracy: 0.5918\n",
            "Epoch 13/50\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.9274 - accuracy: 0.5926\n",
            "Epoch 14/50\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.9231 - accuracy: 0.5932\n",
            "Epoch 15/50\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.9187 - accuracy: 0.5950\n",
            "Epoch 16/50\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.9141 - accuracy: 0.5972\n",
            "Epoch 17/50\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.9092 - accuracy: 0.5993\n",
            "Epoch 18/50\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.9037 - accuracy: 0.6017\n",
            "Epoch 19/50\n",
            "24/24 [==============================] - 6s 241ms/step - loss: 0.8976 - accuracy: 0.6053\n",
            "Epoch 20/50\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.8911 - accuracy: 0.6081\n",
            "Epoch 21/50\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.8832 - accuracy: 0.6123\n",
            "Epoch 22/50\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.8748 - accuracy: 0.6169\n",
            "Epoch 23/50\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.8662 - accuracy: 0.6211\n",
            "Epoch 24/50\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.8585 - accuracy: 0.6241\n",
            "Epoch 25/50\n",
            "24/24 [==============================] - 6s 248ms/step - loss: 0.8497 - accuracy: 0.6313\n",
            "Epoch 26/50\n",
            "24/24 [==============================] - 6s 249ms/step - loss: 0.8410 - accuracy: 0.6347\n",
            "Epoch 27/50\n",
            "24/24 [==============================] - 6s 245ms/step - loss: 0.8387 - accuracy: 0.6392\n",
            "Epoch 28/50\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.8257 - accuracy: 0.6460\n",
            "Epoch 29/50\n",
            "24/24 [==============================] - 6s 241ms/step - loss: 0.8184 - accuracy: 0.6482\n",
            "Epoch 30/50\n",
            "24/24 [==============================] - 6s 245ms/step - loss: 0.8248 - accuracy: 0.6432\n",
            "Epoch 31/50\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.8126 - accuracy: 0.6485\n",
            "Epoch 32/50\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.8039 - accuracy: 0.6558\n",
            "Epoch 33/50\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.7942 - accuracy: 0.6613\n",
            "Epoch 34/50\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.7778 - accuracy: 0.6702\n",
            "Epoch 35/50\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.7647 - accuracy: 0.6755\n",
            "Epoch 36/50\n",
            "24/24 [==============================] - 6s 250ms/step - loss: 0.7476 - accuracy: 0.6868\n",
            "Epoch 37/50\n",
            "24/24 [==============================] - 6s 252ms/step - loss: 0.7339 - accuracy: 0.6933\n",
            "Epoch 38/50\n",
            "24/24 [==============================] - 6s 256ms/step - loss: 0.7196 - accuracy: 0.7010\n",
            "Epoch 39/50\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.7098 - accuracy: 0.7068\n",
            "Epoch 40/50\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.6942 - accuracy: 0.7148\n",
            "Epoch 41/50\n",
            "24/24 [==============================] - 6s 246ms/step - loss: 0.6812 - accuracy: 0.7227\n",
            "Epoch 42/50\n",
            "24/24 [==============================] - 6s 245ms/step - loss: 0.6908 - accuracy: 0.7165\n",
            "Epoch 43/50\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.7095 - accuracy: 0.6989\n",
            "Epoch 44/50\n",
            "24/24 [==============================] - 6s 245ms/step - loss: 0.6801 - accuracy: 0.7178\n",
            "Epoch 45/50\n",
            "24/24 [==============================] - 6s 247ms/step - loss: 0.6842 - accuracy: 0.7132\n",
            "Epoch 46/50\n",
            "24/24 [==============================] - 6s 243ms/step - loss: 0.6764 - accuracy: 0.7223\n",
            "Epoch 47/50\n",
            "24/24 [==============================] - 6s 242ms/step - loss: 0.6576 - accuracy: 0.7305\n",
            "Epoch 48/50\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.6469 - accuracy: 0.7383\n",
            "Epoch 49/50\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.6231 - accuracy: 0.7498\n",
            "Epoch 50/50\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.6019 - accuracy: 0.7635\n",
            "24/24 [==============================] - 6s 240ms/step - loss: 0.6214 - accuracy: 0.7507\n",
            "[0.6213938593864441, 0.7506666779518127]\n",
            "CBOW_BI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_G3Ff5r1bSD",
        "outputId": "e8ee64da-75c6-4b4c-8e39-1882378ea59c"
      },
      "source": [
        "model_cbow_rnn = tf.keras.Sequential()\r\n",
        "model_cbow_rnn.add(tf.keras.Input(shape=(Max_input_size,Embedding_size)))\r\n",
        "model_cbow_rnn.add(tf.keras.layers.SimpleRNN(50))\r\n",
        "model_cbow_rnn.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_cbow_rnn.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy'])\r\n",
        "history_cbow_rnn = model_cbow_rnn.fit_generator(generator = vec_gen(w2v_cbow,vocab_cbow,X_train,y_train,batch_size,Max_input_size,Embedding_size,mul_factor),steps_per_epoch=int(len(X_train)/batch_size),epochs=epochs)\r\n",
        "history = model_cbow_rnn.evaluate(x = vec_gen(w2v_cbow,vocab_cbow,X_test,y_test,batch_size,Max_input_size,Embedding_size,mul_factor),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table+=[history[1]]\r\n",
        "print(\"CBOW_RNN\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 1.1009 - accuracy: 0.5318\n",
            "Epoch 2/50\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 0.9902 - accuracy: 0.5842\n",
            "Epoch 3/50\n",
            "24/24 [==============================] - 6s 253ms/step - loss: 0.9887 - accuracy: 0.5844\n",
            "Epoch 4/50\n",
            "24/24 [==============================] - 6s 256ms/step - loss: 0.9880 - accuracy: 0.5845\n",
            "Epoch 5/50\n",
            "24/24 [==============================] - 6s 253ms/step - loss: 0.9881 - accuracy: 0.5844\n",
            "Epoch 6/50\n",
            "24/24 [==============================] - 6s 251ms/step - loss: 0.9877 - accuracy: 0.5845\n",
            "Epoch 7/50\n",
            "24/24 [==============================] - 6s 254ms/step - loss: 0.9877 - accuracy: 0.5846\n",
            "Epoch 8/50\n",
            "24/24 [==============================] - 6s 254ms/step - loss: 0.9876 - accuracy: 0.5845\n",
            "Epoch 9/50\n",
            "24/24 [==============================] - 6s 257ms/step - loss: 0.9875 - accuracy: 0.5846\n",
            "Epoch 10/50\n",
            "24/24 [==============================] - 6s 252ms/step - loss: 0.9877 - accuracy: 0.5845\n",
            "Epoch 11/50\n",
            "24/24 [==============================] - 6s 257ms/step - loss: 0.9874 - accuracy: 0.5845\n",
            "Epoch 12/50\n",
            "24/24 [==============================] - 6s 256ms/step - loss: 0.9874 - accuracy: 0.5845\n",
            "Epoch 13/50\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 0.9875 - accuracy: 0.5845\n",
            "Epoch 14/50\n",
            "24/24 [==============================] - 6s 262ms/step - loss: 0.9874 - accuracy: 0.5845\n",
            "Epoch 15/50\n",
            "24/24 [==============================] - 6s 257ms/step - loss: 0.9873 - accuracy: 0.5845\n",
            "Epoch 16/50\n",
            "24/24 [==============================] - 6s 254ms/step - loss: 0.9873 - accuracy: 0.5846\n",
            "Epoch 17/50\n",
            "24/24 [==============================] - 6s 255ms/step - loss: 0.9871 - accuracy: 0.5845\n",
            "Epoch 18/50\n",
            "24/24 [==============================] - 6s 253ms/step - loss: 0.9870 - accuracy: 0.5847\n",
            "Epoch 19/50\n",
            "24/24 [==============================] - 6s 255ms/step - loss: 0.9870 - accuracy: 0.5845\n",
            "Epoch 20/50\n",
            "24/24 [==============================] - 6s 250ms/step - loss: 0.9869 - accuracy: 0.5846\n",
            "Epoch 21/50\n",
            "24/24 [==============================] - 6s 253ms/step - loss: 0.9867 - accuracy: 0.5846\n",
            "Epoch 22/50\n",
            "24/24 [==============================] - 6s 252ms/step - loss: 0.9865 - accuracy: 0.5847\n",
            "Epoch 23/50\n",
            "24/24 [==============================] - 6s 250ms/step - loss: 0.9862 - accuracy: 0.5847\n",
            "Epoch 24/50\n",
            "24/24 [==============================] - 6s 254ms/step - loss: 0.9859 - accuracy: 0.5847\n",
            "Epoch 25/50\n",
            "24/24 [==============================] - 6s 251ms/step - loss: 0.9855 - accuracy: 0.5846\n",
            "Epoch 26/50\n",
            "24/24 [==============================] - 6s 257ms/step - loss: 0.9848 - accuracy: 0.5847\n",
            "Epoch 27/50\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.9839 - accuracy: 0.5847\n",
            "Epoch 28/50\n",
            "24/24 [==============================] - 6s 254ms/step - loss: 0.9830 - accuracy: 0.5846\n",
            "Epoch 29/50\n",
            "24/24 [==============================] - 6s 251ms/step - loss: 0.9818 - accuracy: 0.5847\n",
            "Epoch 30/50\n",
            "24/24 [==============================] - 6s 252ms/step - loss: 0.9807 - accuracy: 0.5847\n",
            "Epoch 31/50\n",
            "24/24 [==============================] - 6s 255ms/step - loss: 0.9796 - accuracy: 0.5847\n",
            "Epoch 32/50\n",
            "24/24 [==============================] - 6s 253ms/step - loss: 0.9789 - accuracy: 0.5846\n",
            "Epoch 33/50\n",
            "24/24 [==============================] - 6s 257ms/step - loss: 0.9781 - accuracy: 0.5847\n",
            "Epoch 34/50\n",
            "24/24 [==============================] - 6s 254ms/step - loss: 0.9776 - accuracy: 0.5850\n",
            "Epoch 35/50\n",
            "24/24 [==============================] - 6s 267ms/step - loss: 0.9774 - accuracy: 0.5848\n",
            "Epoch 36/50\n",
            "24/24 [==============================] - 6s 251ms/step - loss: 0.9758 - accuracy: 0.5853\n",
            "Epoch 37/50\n",
            "24/24 [==============================] - 6s 262ms/step - loss: 0.9727 - accuracy: 0.5857\n",
            "Epoch 38/50\n",
            "24/24 [==============================] - 6s 264ms/step - loss: 0.9696 - accuracy: 0.5863\n",
            "Epoch 39/50\n",
            "24/24 [==============================] - 6s 252ms/step - loss: 0.9677 - accuracy: 0.5857\n",
            "Epoch 40/50\n",
            "24/24 [==============================] - 6s 255ms/step - loss: 0.9707 - accuracy: 0.5857\n",
            "Epoch 41/50\n",
            "24/24 [==============================] - 6s 250ms/step - loss: 0.9757 - accuracy: 0.5869\n",
            "Epoch 42/50\n",
            "24/24 [==============================] - 6s 250ms/step - loss: 0.9635 - accuracy: 0.5860\n",
            "Epoch 43/50\n",
            "24/24 [==============================] - 6s 252ms/step - loss: 0.9625 - accuracy: 0.5872\n",
            "Epoch 44/50\n",
            "24/24 [==============================] - 6s 253ms/step - loss: 0.9551 - accuracy: 0.5876\n",
            "Epoch 45/50\n",
            "24/24 [==============================] - 6s 253ms/step - loss: 0.9439 - accuracy: 0.5885\n",
            "Epoch 46/50\n",
            "24/24 [==============================] - 6s 252ms/step - loss: 0.9375 - accuracy: 0.5922\n",
            "Epoch 47/50\n",
            "24/24 [==============================] - 6s 253ms/step - loss: 0.9302 - accuracy: 0.5940\n",
            "Epoch 48/50\n",
            "24/24 [==============================] - 6s 248ms/step - loss: 0.9185 - accuracy: 0.5958\n",
            "Epoch 49/50\n",
            "24/24 [==============================] - 6s 251ms/step - loss: 0.9098 - accuracy: 0.6010\n",
            "Epoch 50/50\n",
            "24/24 [==============================] - 6s 254ms/step - loss: 0.8956 - accuracy: 0.6037\n",
            " 2/24 [=>............................] - ETA: 3s - loss: 0.9163 - accuracy: 0.5870WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0436s vs `on_test_batch_end` time: 0.2184s). Check your callbacks.\n",
            "24/24 [==============================] - 6s 244ms/step - loss: 0.8962 - accuracy: 0.5956\n",
            "[0.8962037563323975, 0.5955833196640015]\n",
            "CBOW_RNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEglKIfExKKI"
      },
      "source": [
        "epochs=50\r\n",
        "Embedding_size=100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czoFmEwK1dWT",
        "outputId": "8ba05c03-af94-41b4-ad04-c3a5615a10bc"
      },
      "source": [
        "model_glove = tf.keras.Sequential()\r\n",
        "model_glove.add(tf.keras.Input(shape=(Max_input_size,100)))\r\n",
        "model_glove.add(tf.keras.layers.LSTM(50))\r\n",
        "model_glove.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_glove.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy'])\r\n",
        "history_glove_lstm = model_glove.fit_generator(generator = glove_gen(vocab_glove,X_train,y_train,batch_size,Max_input_size,Embedding_size,mul_factor),steps_per_epoch=int(len(X_train)/batch_size),epochs=epochs)\r\n",
        "history = model_glove.evaluate(x = glove_gen(vocab_glove,X_test,y_test,batch_size,Max_input_size,Embedding_size,mul_factor),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table+=[history[1]]\r\n",
        "print(\"GLOVE_LSTM\")\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 1.2085 - accuracy: 0.5832\n",
            "Epoch 2/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 1.0015 - accuracy: 0.5845\n",
            "Epoch 3/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.9809 - accuracy: 0.5846\n",
            "Epoch 4/50\n",
            "24/24 [==============================] - 1s 41ms/step - loss: 0.9736 - accuracy: 0.5846\n",
            "Epoch 5/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.9678 - accuracy: 0.5838\n",
            "Epoch 6/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.9573 - accuracy: 0.5900\n",
            "Epoch 7/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.9374 - accuracy: 0.5969\n",
            "Epoch 8/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.9120 - accuracy: 0.6047\n",
            "Epoch 9/50\n",
            "24/24 [==============================] - 1s 43ms/step - loss: 0.8966 - accuracy: 0.6076\n",
            "Epoch 10/50\n",
            "24/24 [==============================] - 1s 43ms/step - loss: 0.8831 - accuracy: 0.6125\n",
            "Epoch 11/50\n",
            "24/24 [==============================] - 1s 41ms/step - loss: 0.8722 - accuracy: 0.6191\n",
            "Epoch 12/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.8614 - accuracy: 0.6265\n",
            "Epoch 13/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.8506 - accuracy: 0.6337\n",
            "Epoch 14/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.8398 - accuracy: 0.6406\n",
            "Epoch 15/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.8279 - accuracy: 0.6483\n",
            "Epoch 16/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.8152 - accuracy: 0.6557\n",
            "Epoch 17/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.8027 - accuracy: 0.6672\n",
            "Epoch 18/50\n",
            "24/24 [==============================] - 1s 43ms/step - loss: 0.7918 - accuracy: 0.6747\n",
            "Epoch 19/50\n",
            "24/24 [==============================] - 1s 43ms/step - loss: 0.7778 - accuracy: 0.6844\n",
            "Epoch 20/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.7644 - accuracy: 0.6924\n",
            "Epoch 21/50\n",
            "24/24 [==============================] - 1s 43ms/step - loss: 0.7646 - accuracy: 0.6928\n",
            "Epoch 22/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.7463 - accuracy: 0.7072\n",
            "Epoch 23/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.7519 - accuracy: 0.7057\n",
            "Epoch 24/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.7591 - accuracy: 0.6959\n",
            "Epoch 25/50\n",
            "24/24 [==============================] - 1s 41ms/step - loss: 0.7360 - accuracy: 0.7116\n",
            "Epoch 26/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.7031 - accuracy: 0.7337\n",
            "Epoch 27/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.6855 - accuracy: 0.7469\n",
            "Epoch 28/50\n",
            "24/24 [==============================] - 1s 43ms/step - loss: 0.6658 - accuracy: 0.7602\n",
            "Epoch 29/50\n",
            "24/24 [==============================] - 1s 44ms/step - loss: 0.6595 - accuracy: 0.7631\n",
            "Epoch 30/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.6911 - accuracy: 0.7371\n",
            "Epoch 31/50\n",
            "24/24 [==============================] - 1s 43ms/step - loss: 0.6792 - accuracy: 0.7501\n",
            "Epoch 32/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.7205 - accuracy: 0.7253\n",
            "Epoch 33/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.7435 - accuracy: 0.7102\n",
            "Epoch 34/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.7099 - accuracy: 0.7261\n",
            "Epoch 35/50\n",
            "24/24 [==============================] - 1s 43ms/step - loss: 0.7308 - accuracy: 0.7214\n",
            "Epoch 36/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.6961 - accuracy: 0.7355\n",
            "Epoch 37/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.6710 - accuracy: 0.7524\n",
            "Epoch 38/50\n",
            "24/24 [==============================] - 1s 43ms/step - loss: 0.6853 - accuracy: 0.7401\n",
            "Epoch 39/50\n",
            "24/24 [==============================] - 1s 41ms/step - loss: 0.6684 - accuracy: 0.7505\n",
            "Epoch 40/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.6183 - accuracy: 0.7794\n",
            "Epoch 41/50\n",
            "24/24 [==============================] - 1s 41ms/step - loss: 0.6133 - accuracy: 0.7853\n",
            "Epoch 42/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.6106 - accuracy: 0.7854\n",
            "Epoch 43/50\n",
            "24/24 [==============================] - 1s 43ms/step - loss: 0.6205 - accuracy: 0.7793\n",
            "Epoch 44/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.6387 - accuracy: 0.7698\n",
            "Epoch 45/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.6828 - accuracy: 0.7430\n",
            "Epoch 46/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.6142 - accuracy: 0.7765\n",
            "Epoch 47/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.5967 - accuracy: 0.7897\n",
            "Epoch 48/50\n",
            "24/24 [==============================] - 1s 43ms/step - loss: 0.5938 - accuracy: 0.7917\n",
            "Epoch 49/50\n",
            "24/24 [==============================] - 1s 41ms/step - loss: 0.5899 - accuracy: 0.7917\n",
            "Epoch 50/50\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 0.6237 - accuracy: 0.7732\n",
            "24/24 [==============================] - 1s 44ms/step - loss: 0.6366 - accuracy: 0.7626\n",
            "[0.6366119384765625, 0.762583315372467]\n",
            "GLOVE_LSTM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKM9PEwm1fkb",
        "outputId": "5b57d88b-6533-4bb9-abe0-c353c4432f2f"
      },
      "source": [
        "model_glove_bi = tf.keras.Sequential()\r\n",
        "model_glove_bi.add(tf.keras.Input(shape=(Max_input_size,100)))\r\n",
        "model_glove_bi.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50),merge_mode='concat'))\r\n",
        "model_glove_bi.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_glove_bi.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy'])\r\n",
        "history_glove_bi = model_glove_bi.fit_generator(generator = glove_gen(vocab_glove,X_train,y_train,batch_size,Max_input_size,Embedding_size,mul_factor),steps_per_epoch=int(len(X_train)/batch_size),epochs=epochs)\r\n",
        "history = model_glove_bi.evaluate(x = glove_gen(vocab_glove,X_test,y_test,batch_size,Max_input_size,Embedding_size,mul_factor),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table+=[history[1]]\r\n",
        "print(\"GLOVE_BI\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "24/24 [==============================] - 1s 44ms/step - loss: 1.0573 - accuracy: 0.5770\n",
            "Epoch 2/50\n",
            "24/24 [==============================] - 1s 46ms/step - loss: 0.9627 - accuracy: 0.5851\n",
            "Epoch 3/50\n",
            "24/24 [==============================] - 1s 45ms/step - loss: 0.9385 - accuracy: 0.5872\n",
            "Epoch 4/50\n",
            "24/24 [==============================] - 1s 47ms/step - loss: 0.9131 - accuracy: 0.5982\n",
            "Epoch 5/50\n",
            "24/24 [==============================] - 1s 46ms/step - loss: 0.8974 - accuracy: 0.6068\n",
            "Epoch 6/50\n",
            "24/24 [==============================] - 1s 45ms/step - loss: 0.8838 - accuracy: 0.6122\n",
            "Epoch 7/50\n",
            "24/24 [==============================] - 1s 46ms/step - loss: 0.8728 - accuracy: 0.6177\n",
            "Epoch 8/50\n",
            "24/24 [==============================] - 1s 46ms/step - loss: 0.8627 - accuracy: 0.6230\n",
            "Epoch 9/50\n",
            "24/24 [==============================] - 1s 46ms/step - loss: 0.8530 - accuracy: 0.6288\n",
            "Epoch 10/50\n",
            "24/24 [==============================] - 1s 45ms/step - loss: 0.8428 - accuracy: 0.6369\n",
            "Epoch 11/50\n",
            "24/24 [==============================] - 1s 46ms/step - loss: 0.8311 - accuracy: 0.6447\n",
            "Epoch 12/50\n",
            "24/24 [==============================] - 1s 45ms/step - loss: 0.8165 - accuracy: 0.6518\n",
            "Epoch 13/50\n",
            "24/24 [==============================] - 1s 46ms/step - loss: 0.7998 - accuracy: 0.6614\n",
            "Epoch 14/50\n",
            "24/24 [==============================] - 1s 46ms/step - loss: 0.7812 - accuracy: 0.6711\n",
            "Epoch 15/50\n",
            "24/24 [==============================] - 1s 45ms/step - loss: 0.7610 - accuracy: 0.6823\n",
            "Epoch 16/50\n",
            "24/24 [==============================] - 1s 45ms/step - loss: 0.7387 - accuracy: 0.6972\n",
            "Epoch 17/50\n",
            "24/24 [==============================] - 1s 45ms/step - loss: 0.7197 - accuracy: 0.7064\n",
            "Epoch 18/50\n",
            "24/24 [==============================] - 1s 46ms/step - loss: 0.7279 - accuracy: 0.7027\n",
            "Epoch 19/50\n",
            "24/24 [==============================] - 1s 45ms/step - loss: 0.7118 - accuracy: 0.7083\n",
            "Epoch 20/50\n",
            "24/24 [==============================] - 1s 45ms/step - loss: 0.6908 - accuracy: 0.7258\n",
            "Epoch 21/50\n",
            "24/24 [==============================] - 1s 46ms/step - loss: 0.6635 - accuracy: 0.7347\n",
            "Epoch 22/50\n",
            "24/24 [==============================] - 1s 46ms/step - loss: 0.6420 - accuracy: 0.7454\n",
            "Epoch 23/50\n",
            "24/24 [==============================] - 1s 46ms/step - loss: 0.6268 - accuracy: 0.7573\n",
            "Epoch 24/50\n",
            "24/24 [==============================] - 1s 46ms/step - loss: 0.6230 - accuracy: 0.7563\n",
            "Epoch 25/50\n",
            "24/24 [==============================] - 1s 46ms/step - loss: 0.6460 - accuracy: 0.7393\n",
            "Epoch 26/50\n",
            "24/24 [==============================] - 1s 45ms/step - loss: 0.6468 - accuracy: 0.7422\n",
            "Epoch 27/50\n",
            "24/24 [==============================] - 1s 46ms/step - loss: 0.6711 - accuracy: 0.7304\n",
            "Epoch 28/50\n",
            "24/24 [==============================] - 1s 48ms/step - loss: 0.6032 - accuracy: 0.7653\n",
            "Epoch 29/50\n",
            "24/24 [==============================] - 1s 47ms/step - loss: 0.6184 - accuracy: 0.7547\n",
            "Epoch 30/50\n",
            "24/24 [==============================] - 1s 47ms/step - loss: 0.5616 - accuracy: 0.7860\n",
            "Epoch 31/50\n",
            "24/24 [==============================] - 1s 46ms/step - loss: 0.5318 - accuracy: 0.8013\n",
            "Epoch 32/50\n",
            "24/24 [==============================] - 1s 47ms/step - loss: 0.5084 - accuracy: 0.8120\n",
            "Epoch 33/50\n",
            "24/24 [==============================] - 1s 47ms/step - loss: 0.4886 - accuracy: 0.8193\n",
            "Epoch 34/50\n",
            "24/24 [==============================] - 1s 46ms/step - loss: 0.4851 - accuracy: 0.8198\n",
            "Epoch 35/50\n",
            "24/24 [==============================] - 1s 47ms/step - loss: 0.5203 - accuracy: 0.8000\n",
            "Epoch 36/50\n",
            "24/24 [==============================] - 1s 49ms/step - loss: 0.4915 - accuracy: 0.8149\n",
            "Epoch 37/50\n",
            "24/24 [==============================] - 1s 46ms/step - loss: 0.4643 - accuracy: 0.8295\n",
            "Epoch 38/50\n",
            "24/24 [==============================] - 1s 47ms/step - loss: 0.4586 - accuracy: 0.8319\n",
            "Epoch 39/50\n",
            "24/24 [==============================] - 1s 45ms/step - loss: 0.4662 - accuracy: 0.8288\n",
            "Epoch 40/50\n",
            "24/24 [==============================] - 1s 47ms/step - loss: 0.4733 - accuracy: 0.8189\n",
            "Epoch 41/50\n",
            "24/24 [==============================] - 1s 46ms/step - loss: 0.4654 - accuracy: 0.8253\n",
            "Epoch 42/50\n",
            "24/24 [==============================] - 1s 49ms/step - loss: 0.4683 - accuracy: 0.8209\n",
            "Epoch 43/50\n",
            "24/24 [==============================] - 1s 47ms/step - loss: 0.4693 - accuracy: 0.8246\n",
            "Epoch 44/50\n",
            "24/24 [==============================] - 1s 51ms/step - loss: 0.4901 - accuracy: 0.8129\n",
            "Epoch 45/50\n",
            "24/24 [==============================] - 1s 47ms/step - loss: 0.5174 - accuracy: 0.8010\n",
            "Epoch 46/50\n",
            "24/24 [==============================] - 1s 47ms/step - loss: 0.4780 - accuracy: 0.8143\n",
            "Epoch 47/50\n",
            "24/24 [==============================] - 1s 48ms/step - loss: 0.4662 - accuracy: 0.8186\n",
            "Epoch 48/50\n",
            "24/24 [==============================] - 1s 49ms/step - loss: 0.4615 - accuracy: 0.8228\n",
            "Epoch 49/50\n",
            "24/24 [==============================] - 1s 49ms/step - loss: 0.4446 - accuracy: 0.8328\n",
            "Epoch 50/50\n",
            "24/24 [==============================] - 1s 50ms/step - loss: 0.4252 - accuracy: 0.8407\n",
            "24/24 [==============================] - 1s 45ms/step - loss: 0.5260 - accuracy: 0.7920\n",
            "[0.5259690880775452, 0.7919999957084656]\n",
            "GLOVE_BI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQBa5s4s1hNU",
        "outputId": "8a92780d-c6cc-42ee-86ef-1bdec3521410"
      },
      "source": [
        "model_glove_rnn = tf.keras.Sequential()\r\n",
        "model_glove_rnn.add(tf.keras.Input(shape=(Max_input_size,100)))\r\n",
        "model_glove_rnn.add(tf.keras.layers.SimpleRNN(50))\r\n",
        "model_glove_rnn.add(tf.keras.layers.Dense(4, activation='softmax'))\r\n",
        "model_glove_rnn.compile(loss='categorical_crossentropy',optimizer='adam', \r\n",
        "                           metrics=['accuracy'])\r\n",
        "history_glove_rnn = model_glove_rnn.fit_generator(generator = glove_gen(vocab_glove,X_train,y_train,batch_size,Max_input_size,Embedding_size,mul_factor),steps_per_epoch=int(len(X_train)/batch_size),epochs=epochs)\r\n",
        "history = model_glove_rnn.evaluate(x = glove_gen(vocab_glove,X_test,y_test,batch_size,Max_input_size,Embedding_size,mul_factor),steps=int(len(y_test)/batch_size))\r\n",
        "print(history)\r\n",
        "\r\n",
        "result_table+=[history[1]]\r\n",
        "print(\"GLOVE_RNN\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "24/24 [==============================] - 2s 64ms/step - loss: 1.1293 - accuracy: 0.5365\n",
            "Epoch 2/50\n",
            "24/24 [==============================] - 1s 60ms/step - loss: 0.9940 - accuracy: 0.5842\n",
            "Epoch 3/50\n",
            "24/24 [==============================] - 1s 61ms/step - loss: 0.9816 - accuracy: 0.5844\n",
            "Epoch 4/50\n",
            "24/24 [==============================] - 1s 60ms/step - loss: 0.9763 - accuracy: 0.5859\n",
            "Epoch 5/50\n",
            "24/24 [==============================] - 1s 60ms/step - loss: 0.9698 - accuracy: 0.5874\n",
            "Epoch 6/50\n",
            "24/24 [==============================] - 1s 62ms/step - loss: 0.9669 - accuracy: 0.5897\n",
            "Epoch 7/50\n",
            "24/24 [==============================] - 1s 62ms/step - loss: 0.9616 - accuracy: 0.5939\n",
            "Epoch 8/50\n",
            "24/24 [==============================] - 1s 61ms/step - loss: 0.9575 - accuracy: 0.5960\n",
            "Epoch 9/50\n",
            "24/24 [==============================] - 1s 62ms/step - loss: 0.9515 - accuracy: 0.5988\n",
            "Epoch 10/50\n",
            "24/24 [==============================] - 1s 61ms/step - loss: 0.9468 - accuracy: 0.6019\n",
            "Epoch 11/50\n",
            "24/24 [==============================] - 1s 62ms/step - loss: 0.9431 - accuracy: 0.6036\n",
            "Epoch 12/50\n",
            "24/24 [==============================] - 2s 63ms/step - loss: 0.9393 - accuracy: 0.6058\n",
            "Epoch 13/50\n",
            "24/24 [==============================] - 2s 63ms/step - loss: 0.9356 - accuracy: 0.6081\n",
            "Epoch 14/50\n",
            "24/24 [==============================] - 2s 63ms/step - loss: 0.9330 - accuracy: 0.6090\n",
            "Epoch 15/50\n",
            "24/24 [==============================] - 1s 62ms/step - loss: 0.9298 - accuracy: 0.6104\n",
            "Epoch 16/50\n",
            "24/24 [==============================] - 2s 63ms/step - loss: 0.9234 - accuracy: 0.6144\n",
            "Epoch 17/50\n",
            "24/24 [==============================] - 2s 64ms/step - loss: 0.9170 - accuracy: 0.6189\n",
            "Epoch 18/50\n",
            "24/24 [==============================] - 2s 63ms/step - loss: 0.9107 - accuracy: 0.6212\n",
            "Epoch 19/50\n",
            "24/24 [==============================] - 1s 61ms/step - loss: 0.9021 - accuracy: 0.6267\n",
            "Epoch 20/50\n",
            "24/24 [==============================] - 2s 64ms/step - loss: 0.8976 - accuracy: 0.6298\n",
            "Epoch 21/50\n",
            "24/24 [==============================] - 1s 62ms/step - loss: 0.9081 - accuracy: 0.6197\n",
            "Epoch 22/50\n",
            "24/24 [==============================] - 1s 61ms/step - loss: 0.8878 - accuracy: 0.6348\n",
            "Epoch 23/50\n",
            "24/24 [==============================] - 1s 60ms/step - loss: 0.8889 - accuracy: 0.6323\n",
            "Epoch 24/50\n",
            "24/24 [==============================] - 1s 61ms/step - loss: 0.8833 - accuracy: 0.6358\n",
            "Epoch 25/50\n",
            "24/24 [==============================] - 2s 63ms/step - loss: 0.8697 - accuracy: 0.6436\n",
            "Epoch 26/50\n",
            "24/24 [==============================] - 1s 62ms/step - loss: 0.8634 - accuracy: 0.6478\n",
            "Epoch 27/50\n",
            "24/24 [==============================] - 1s 62ms/step - loss: 0.8578 - accuracy: 0.6522\n",
            "Epoch 28/50\n",
            "24/24 [==============================] - 1s 61ms/step - loss: 0.8512 - accuracy: 0.6544\n",
            "Epoch 29/50\n",
            "24/24 [==============================] - 1s 59ms/step - loss: 0.8528 - accuracy: 0.6533\n",
            "Epoch 30/50\n",
            "24/24 [==============================] - 1s 59ms/step - loss: 0.8614 - accuracy: 0.6503\n",
            "Epoch 31/50\n",
            "24/24 [==============================] - 1s 60ms/step - loss: 0.8575 - accuracy: 0.6513\n",
            "Epoch 32/50\n",
            "24/24 [==============================] - 1s 60ms/step - loss: 0.8688 - accuracy: 0.6410\n",
            "Epoch 33/50\n",
            "24/24 [==============================] - 1s 62ms/step - loss: 0.8610 - accuracy: 0.6471\n",
            "Epoch 34/50\n",
            "24/24 [==============================] - 1s 60ms/step - loss: 0.8630 - accuracy: 0.6510\n",
            "Epoch 35/50\n",
            "24/24 [==============================] - 1s 60ms/step - loss: 0.8524 - accuracy: 0.6499\n",
            "Epoch 36/50\n",
            "24/24 [==============================] - 1s 61ms/step - loss: 0.8462 - accuracy: 0.6542\n",
            "Epoch 37/50\n",
            "24/24 [==============================] - 1s 62ms/step - loss: 0.8386 - accuracy: 0.6589\n",
            "Epoch 38/50\n",
            "24/24 [==============================] - 1s 60ms/step - loss: 0.8268 - accuracy: 0.6657\n",
            "Epoch 39/50\n",
            "24/24 [==============================] - 1s 60ms/step - loss: 0.8186 - accuracy: 0.6693\n",
            "Epoch 40/50\n",
            "24/24 [==============================] - 1s 59ms/step - loss: 0.8074 - accuracy: 0.6743\n",
            "Epoch 41/50\n",
            "24/24 [==============================] - 1s 59ms/step - loss: 0.8075 - accuracy: 0.6718\n",
            "Epoch 42/50\n",
            "24/24 [==============================] - 1s 60ms/step - loss: 0.8130 - accuracy: 0.6683\n",
            "Epoch 43/50\n",
            "24/24 [==============================] - 1s 59ms/step - loss: 0.8234 - accuracy: 0.6640\n",
            "Epoch 44/50\n",
            "24/24 [==============================] - 1s 60ms/step - loss: 0.8024 - accuracy: 0.6745\n",
            "Epoch 45/50\n",
            "24/24 [==============================] - 1s 61ms/step - loss: 0.8087 - accuracy: 0.6737\n",
            "Epoch 46/50\n",
            "24/24 [==============================] - 1s 60ms/step - loss: 0.8073 - accuracy: 0.6737\n",
            "Epoch 47/50\n",
            "24/24 [==============================] - 1s 60ms/step - loss: 0.8238 - accuracy: 0.6681\n",
            "Epoch 48/50\n",
            "24/24 [==============================] - 1s 60ms/step - loss: 0.8519 - accuracy: 0.6532\n",
            "Epoch 49/50\n",
            "24/24 [==============================] - 1s 61ms/step - loss: 0.8102 - accuracy: 0.6704\n",
            "Epoch 50/50\n",
            "24/24 [==============================] - 1s 61ms/step - loss: 0.8267 - accuracy: 0.6633\n",
            "24/24 [==============================] - 1s 43ms/step - loss: 0.8083 - accuracy: 0.6758\n",
            "[0.808293879032135, 0.6758333444595337]\n",
            "GLOVE_RNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "WZqN_SaM3hs9",
        "outputId": "b2eda199-69be-496b-9a8c-3be2f0d85249"
      },
      "source": [
        "print(\"\\tLstm\\t\\t\\tBiLstm\\t\\t\\tRnn\")\r\n",
        "print(\"sg\",result_table[:3])\r\n",
        "print(\"cbow\",result_table[3:6])\r\n",
        "print(\"glove\",result_table[6:9])\r\n",
        "print(history_sg_bi.history)\r\n",
        "plt.title(\"Skip-Gram + Bi-LSTM accuracy, loss vs epochs Graph\")\r\n",
        "plt.plot(history_sg_bi.history['loss'],c='b',label='loss')\r\n",
        "plt.plot(history_sg_bi.history['accuracy'],c='r',label='accuracy')\r\n",
        "plt.xlabel('epochs')\r\n",
        "plt.legend()\r\n",
        "# plt.yticks()\r\n",
        "plt.show()\r\n",
        "plt.title(\"GloVe + Bi-LSTM accuracy, loss vs epochs Graph\")\r\n",
        "plt.plot(history_glove_bi.history['loss'],c='b',label='loss')\r\n",
        "plt.plot(history_glove_bi.history['accuracy'],c='r',label='accuracy')\r\n",
        "plt.xlabel('epochs')\r\n",
        "plt.legend()\r\n",
        "# plt.yticks()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tLstm\t\t\tBiLstm\t\t\tRnn\n",
            "sg [0.6852499842643738, 0.7020833492279053, 0.5857499837875366]\n",
            "cbow [0.7177500128746033, 0.7506666779518127, 0.5955833196640015]\n",
            "glove [0.762583315372467, 0.7919999957084656, 0.6758333444595337]\n",
            "{'loss': [1.2051223516464233, 0.9903011322021484, 0.9800624251365662, 0.9760096669197083, 0.9709927439689636, 0.9647576212882996, 0.9587016701698303, 0.952382504940033, 0.9472473859786987, 0.9433058500289917, 0.9396315813064575, 0.9366110563278198, 0.9349943995475769, 0.9348272085189819, 0.9313245415687561, 0.9242314696311951, 0.9177142977714539, 0.9134690761566162, 0.9083897471427917, 0.902794599533081, 0.8970194458961487, 0.8908019065856934, 0.8839716911315918, 0.87664794921875, 0.8719397783279419, 0.8718796372413635, 0.8585988879203796, 0.8515133261680603, 0.8418104648590088, 0.8345919847488403, 0.8267427682876587, 0.8197890520095825, 0.8090539574623108, 0.7970016002655029, 0.7876979112625122, 0.790432870388031, 0.8092682361602783, 0.8168262243270874, 0.7934706211090088, 0.7818470001220703, 0.7778764367103577, 0.7598692774772644, 0.7521138787269592, 0.7526408433914185, 0.7534236907958984, 0.7585479617118835, 0.7380800843238831, 0.7160838842391968, 0.6988399028778076, 0.6874510645866394], 'accuracy': [0.534583330154419, 0.5845000147819519, 0.5845000147819519, 0.5845000147819519, 0.5845833420753479, 0.5845833420753479, 0.5846666693687439, 0.5848333239555359, 0.5850833058357239, 0.5848333239555359, 0.5855833292007446, 0.5865833163261414, 0.5874999761581421, 0.5881666541099548, 0.5892500281333923, 0.5913333296775818, 0.5930833220481873, 0.5950833559036255, 0.597000002861023, 0.6011666655540466, 0.6043333411216736, 0.6070833206176758, 0.6117500066757202, 0.6138333082199097, 0.6169166564941406, 0.6159166693687439, 0.6187499761581421, 0.6234999895095825, 0.6299999952316284, 0.6328333616256714, 0.6383333206176758, 0.6433333158493042, 0.6445833444595337, 0.6525833606719971, 0.659333348274231, 0.6583333611488342, 0.6485833525657654, 0.6459166407585144, 0.6587499976158142, 0.6627500057220459, 0.6614166498184204, 0.6690000295639038, 0.6794999837875366, 0.6753333210945129, 0.6755833625793457, 0.6727499961853027, 0.6833333373069763, 0.6961666941642761, 0.7039166688919067, 0.7105833292007446]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}